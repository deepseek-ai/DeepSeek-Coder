{"name": "HumanEval_23_strlen", "language": "lua", "prompt": "-- Return length of given string\n-- >>> strlen('')\n-- 0\n-- >>> strlen('abc')\n-- 3\nlocal function strlen(string)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_23_strlen.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = strlen\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('x'), 1)\n    lu.assertEquals(candidate('asdasnakj'), 9)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_23_strlen", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = strlen\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('x'), 1)\n    lu.assertEquals(candidate('asdasnakj'), 9)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_89_encrypt", "language": "lua", "prompt": "-- Create a function encrypt that takes a string as an argument and\n-- returns a string encrypted with the alphabet being rotated. \n-- The alphabet should be rotated in a manner such that the letters \n-- shift down by two multiplied to two places.\n-- For example:\n-- >>> encrypt('hi')\n-- 'lm'\n-- >>> encrypt('asdfghjkl')\n-- 'ewhjklnop'\n-- >>> encrypt('gf')\n-- 'kj'\n-- >>> encrypt('et')\n-- 'ix'\nlocal function encrypt(s)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_89_encrypt.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = encrypt\n    lu.assertEquals(candidate('hi'), 'lm')\n    lu.assertEquals(candidate('asdfghjkl'), 'ewhjklnop')\n    lu.assertEquals(candidate('gf'), 'kj')\n    lu.assertEquals(candidate('et'), 'ix')\n    lu.assertEquals(candidate('faewfawefaewg'), 'jeiajeaijeiak')\n    lu.assertEquals(candidate('hellomyfriend'), 'lippsqcjvmirh')\n    lu.assertEquals(candidate('dxzdlmnilfuhmilufhlihufnmlimnufhlimnufhfucufh'), 'hbdhpqrmpjylqmpyjlpmlyjrqpmqryjlpmqryjljygyjl')\n    lu.assertEquals(candidate('a'), 'e')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_89_encrypt", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = encrypt\n    lu.assertEquals(candidate('hi'), 'lm')\n    lu.assertEquals(candidate('asdfghjkl'), 'ewhjklnop')\n    lu.assertEquals(candidate('gf'), 'kj')\n    lu.assertEquals(candidate('et'), 'ix')\n    lu.assertEquals(candidate('faewfawefaewg'), 'jeiajeaijeiak')\n    lu.assertEquals(candidate('hellomyfriend'), 'lippsqcjvmirh')\n    lu.assertEquals(candidate('dxzdlmnilfuhmilufhlihufnmlimnufhlimnufhfucufh'), 'hbdhpqrmpjylqmpyjlpmlyjrqpmqryjlpmqryjljygyjl')\n    lu.assertEquals(candidate('a'), 'e')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_95_check_dict_case", "language": "lua", "prompt": "-- Given a table, return true if all keys are strings in lower \n-- case or all keys are strings in upper case, else return false.\n-- The function should return false is the given table is empty.\n-- Examples:\n-- >>> check_dict_case({['a'] = 'apple', ['b'] = 'banana'})\n-- true\n-- >>> check_dict_case({['a'] = 'apple', ['A'] = 'banana', ['B'] = 'banana'})\n-- false\n-- >>> check_dict_case({['a'] = 'apple', [8] = 'banana', ['a'] = 'apple'})\n-- false\n-- >>> check_dict_case({['Name'] = 'John', ['Age'] = '36', ['City'] = 'Houston'})\n-- false\n-- >>> check_dict_case({['STATE'] = 'NC', ['ZIP'] = '12345'})\n-- true\nlocal function check_dict_case(dict)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_95_check_dict_case.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = check_dict_case\n    lu.assertEquals(candidate({['p'] = 'pineapple', ['b'] = 'banana'}), true)\n    lu.assertEquals(candidate({['p'] = 'pineapple', ['A'] = 'banana', ['B'] = 'banana'}), false)\n    lu.assertEquals(candidate({['p'] = 'pineapple', ['5'] = 'banana', ['a'] = 'apple'}), false)\n    lu.assertEquals(candidate({['Name'] = 'John', ['Age'] = '36', ['City'] = 'Houston'}), false)\n    lu.assertEquals(candidate({['STATE'] = 'NC', ['ZIP'] = '12345'}), true)\n    lu.assertEquals(candidate({['fruit'] = 'Orange', ['taste'] = 'Sweet'}), true)\n    lu.assertEquals(candidate({}), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_95_check_dict_case", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = check_dict_case\n    lu.assertEquals(candidate({['p'] = 'pineapple', ['b'] = 'banana'}), true)\n    lu.assertEquals(candidate({['p'] = 'pineapple', ['A'] = 'banana', ['B'] = 'banana'}), false)\n    lu.assertEquals(candidate({['p'] = 'pineapple', ['5'] = 'banana', ['a'] = 'apple'}), false)\n    lu.assertEquals(candidate({['Name'] = 'John', ['Age'] = '36', ['City'] = 'Houston'}), false)\n    lu.assertEquals(candidate({['STATE'] = 'NC', ['ZIP'] = '12345'}), true)\n    lu.assertEquals(candidate({['fruit'] = 'Orange', ['taste'] = 'Sweet'}), true)\n    lu.assertEquals(candidate({}), false)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_85_add", "language": "lua", "prompt": "-- Given a non-empty table of integers lst. add the even elements that are at odd indices..\n-- Examples:\n-- >>> add({4, 2, 6, 7})\n-- 2\nlocal function add(lst)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_85_add.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = add\n    lu.assertEquals(candidate({4, 88}), 88)\n    lu.assertEquals(candidate({4, 5, 6, 7, 2, 122}), 122)\n    lu.assertEquals(candidate({4, 0, 6, 7}), 0)\n    lu.assertEquals(candidate({4, 4, 6, 8}), 12)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_85_add", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = add\n    lu.assertEquals(candidate({4, 88}), 88)\n    lu.assertEquals(candidate({4, 5, 6, 7, 2, 122}), 122)\n    lu.assertEquals(candidate({4, 0, 6, 7}), 0)\n    lu.assertEquals(candidate({4, 4, 6, 8}), 12)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_140_fix_spaces", "language": "lua", "prompt": "-- Given a string text, replace all spaces in it with underscores, \n-- and if a string has more than 2 consecutive spaces, \n-- then replace all consecutive spaces with - \n-- >>> fix_spaces(' Example')\n-- 'Example'\n-- >>> fix_spaces(' Example 1')\n-- 'Example_1'\n-- >>> fix_spaces(' Example 2')\n-- '_Example_2'\n-- >>> fix_spaces(' Example 3')\n-- '_Example-3'\nlocal function fix_spaces(text)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_140_fix_spaces.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fix_spaces\n    lu.assertEquals(candidate('Example'), 'Example')\n    lu.assertEquals(candidate('Mudasir Hanif '), 'Mudasir_Hanif_')\n    lu.assertEquals(candidate('Yellow Yellow  Dirty  Fellow'), 'Yellow_Yellow__Dirty__Fellow')\n    lu.assertEquals(candidate('Exa   mple'), 'Exa-mple')\n    lu.assertEquals(candidate('   Exa 1 2 2 mple'), '-Exa_1_2_2_mple')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_140_fix_spaces", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fix_spaces\n    lu.assertEquals(candidate('Example'), 'Example')\n    lu.assertEquals(candidate('Mudasir Hanif '), 'Mudasir_Hanif_')\n    lu.assertEquals(candidate('Yellow Yellow  Dirty  Fellow'), 'Yellow_Yellow__Dirty__Fellow')\n    lu.assertEquals(candidate('Exa   mple'), 'Exa-mple')\n    lu.assertEquals(candidate('   Exa 1 2 2 mple'), '-Exa_1_2_2_mple')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_63_fibfib", "language": "lua", "prompt": "-- The FibFib number sequence is a sequence similar to the Fibbonacci sequnece that's defined as follows:\n-- fibfib(0) == 0\n-- fibfib(1) == 0\n-- fibfib(2) == 1\n-- fibfib(n) == fibfib(n-1) + fibfib(n-2) + fibfib(n-3).\n-- Please write a function to efficiently compute the n-th element of the fibfib number sequence.\n-- >>> fibfib(1)\n-- 0\n-- >>> fibfib(5)\n-- 4\n-- >>> fibfib(8)\n-- 24\nlocal function fibfib(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_63_fibfib.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fibfib\n    lu.assertEquals(candidate(2), 1)\n    lu.assertEquals(candidate(1), 0)\n    lu.assertEquals(candidate(5), 4)\n    lu.assertEquals(candidate(8), 24)\n    lu.assertEquals(candidate(10), 81)\n    lu.assertEquals(candidate(12), 274)\n    lu.assertEquals(candidate(14), 927)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_63_fibfib", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fibfib\n    lu.assertEquals(candidate(2), 1)\n    lu.assertEquals(candidate(1), 0)\n    lu.assertEquals(candidate(5), 4)\n    lu.assertEquals(candidate(8), 24)\n    lu.assertEquals(candidate(10), 81)\n    lu.assertEquals(candidate(12), 274)\n    lu.assertEquals(candidate(14), 927)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_151_double_the_difference", "language": "lua", "prompt": "-- Given a table of numbers, return the sum of squares of the numbers\n-- in the table that are odd. Ignore numbers that are negative or not integers.\n-- >>> double_the_difference({1, 3, 2, 0})\n-- 10\n-- >>> double_the_difference({-1, -2, 0})\n-- 0\n-- >>> double_the_difference({9, -2})\n-- 81\n-- >>> double_the_difference({0})\n-- 0\n-- If the input table is empty, return 0.\nlocal function double_the_difference(lst)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_151_double_the_difference.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = double_the_difference\n    lu.assertEquals(candidate({}), 0)\n    lu.assertEquals(candidate({5.0, 4.0}), 25)\n    lu.assertEquals(candidate({0.1, 0.2, 0.3}), 0)\n    lu.assertEquals(candidate({-10.0, -20.0, -30.0}), 0)\n    lu.assertEquals(candidate({-1.0, -2.0, 8.0}), 0)\n    lu.assertEquals(candidate({0.2, 3.0, 5.0}), 34)\n    lu.assertEquals(candidate({-9.0, -7.0, -5.0, -3.0, -1.0, 1.0, 3.0, 5.0, 7.0, 9.0}), 165)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_151_double_the_difference", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = double_the_difference\n    lu.assertEquals(candidate({}), 0)\n    lu.assertEquals(candidate({5.0, 4.0}), 25)\n    lu.assertEquals(candidate({0.1, 0.2, 0.3}), 0)\n    lu.assertEquals(candidate({-10.0, -20.0, -30.0}), 0)\n    lu.assertEquals(candidate({-1.0, -2.0, 8.0}), 0)\n    lu.assertEquals(candidate({0.2, 3.0, 5.0}), 34)\n    lu.assertEquals(candidate({-9.0, -7.0, -5.0, -3.0, -1.0, 1.0, 3.0, 5.0, 7.0, 9.0}), 165)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_22_filter_integers", "language": "lua", "prompt": "-- Filter given table of any luathon values only for integers\n-- >>> filter_integers({'a', 3.14, 5})\n-- {5}\n-- >>> filter_integers({1, 2, 3, 'abc', {}, {}})\n-- {1, 2, 3}\nlocal function filter_integers(values)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_22_filter_integers.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = filter_integers\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({4, {}, {}, 23.2, 9, 'adasd'}), {4, 9})\n    lu.assertEquals(candidate({3, 'c', 3, 3, 'a', 'b'}), {3, 3, 3})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_22_filter_integers", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = filter_integers\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({4, {}, {}, 23.2, 9, 'adasd'}), {4, 9})\n    lu.assertEquals(candidate({3, 'c', 3, 3, 'a', 'b'}), {3, 3, 3})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_41_car_race_collision", "language": "lua", "prompt": "-- Imagine a road that's a perfectly straight infinitely long line.\n-- n cars are driving left to right;  simultaneously, a different set of n cars\n-- are driving right to left.   The two sets of cars start out being very far from\n-- each other.  All cars move in the same speed.  Two cars are said to collide\n-- when a car that's moving left to right hits a car that's moving right to left.\n-- However, the cars are infinitely sturdy and strong; as a result, they continue moving\n-- in their trajectory as if they did not collide.\n-- This function outputs the number of such collisions.\nlocal function car_race_collision(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_41_car_race_collision.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = car_race_collision\n    lu.assertEquals(candidate(2), 4)\n    lu.assertEquals(candidate(3), 9)\n    lu.assertEquals(candidate(4), 16)\n    lu.assertEquals(candidate(8), 64)\n    lu.assertEquals(candidate(10), 100)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_41_car_race_collision", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = car_race_collision\n    lu.assertEquals(candidate(2), 4)\n    lu.assertEquals(candidate(3), 9)\n    lu.assertEquals(candidate(4), 16)\n    lu.assertEquals(candidate(8), 64)\n    lu.assertEquals(candidate(10), 100)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_17_parse_music", "language": "lua", "prompt": "-- Input to this function is a string representing musical notes in a special ASCII format.\n-- Your task is to parse this string and return table of integers corresponding to how many beats does each\n-- not last.\n-- Here is a legend:\n-- 'o' - whole note, lasts four beats\n-- 'o|' - half note, lasts two beats\n-- '.|' - quater note, lasts one beat\n-- >>> parse_music('o o| .| o| o| .| .| .| .| o o')\n-- {4, 2, 1, 2, 2, 1, 1, 1, 1, 4, 4}\nlocal function parse_music(music_string)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_17_parse_music.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_music\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate('o o o o'), {4, 4, 4, 4})\n    lu.assertEquals(candidate('.| .| .| .|'), {1, 1, 1, 1})\n    lu.assertEquals(candidate('o| o| .| .| o o o o'), {2, 2, 1, 1, 4, 4, 4, 4})\n    lu.assertEquals(candidate('o| .| o| .| o o| o o|'), {2, 1, 2, 1, 4, 2, 4, 2})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_17_parse_music", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_music\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate('o o o o'), {4, 4, 4, 4})\n    lu.assertEquals(candidate('.| .| .| .|'), {1, 1, 1, 1})\n    lu.assertEquals(candidate('o| o| .| .| o o o o'), {2, 2, 1, 1, 4, 4, 4, 4})\n    lu.assertEquals(candidate('o| .| o| .| o o| o o|'), {2, 1, 2, 1, 4, 2, 4, 2})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_79_decimal_to_binary", "language": "lua", "prompt": "-- You will be given a number in decimal form and your task is to convert it to\n-- binary format. The function should return a string, with each character representing a binary\n-- number. Each character in the string will be '0' or '1'.\n-- There will be an extra couple of characters 'db' at the beginning and at the end of the string.\n-- The extra characters are there to help with the format.\n-- Examples:\n-- >>> decimal_to_binary(15)\n-- 'db1111db'\n-- >>> decimal_to_binary(32)\n-- 'db100000db'\nlocal function decimal_to_binary(decimal)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_79_decimal_to_binary.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = decimal_to_binary\n    lu.assertEquals(candidate(0), 'db0db')\n    lu.assertEquals(candidate(32), 'db100000db')\n    lu.assertEquals(candidate(103), 'db1100111db')\n    lu.assertEquals(candidate(15), 'db1111db')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_79_decimal_to_binary", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = decimal_to_binary\n    lu.assertEquals(candidate(0), 'db0db')\n    lu.assertEquals(candidate(32), 'db100000db')\n    lu.assertEquals(candidate(103), 'db1100111db')\n    lu.assertEquals(candidate(15), 'db1111db')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_14_all_prefixes", "language": "lua", "prompt": "-- Return table of all prefixes from shortest to longest of the input string\n-- >>> all_prefixes('abc')\n-- {'a', 'ab', 'abc'}\nlocal function all_prefixes(string)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_14_all_prefixes.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = all_prefixes\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate('asdfgh'), {'a', 'as', 'asd', 'asdf', 'asdfg', 'asdfgh'})\n    lu.assertEquals(candidate('WWW'), {'W', 'WW', 'WWW'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_14_all_prefixes", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = all_prefixes\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate('asdfgh'), {'a', 'as', 'asd', 'asdf', 'asdfg', 'asdfgh'})\n    lu.assertEquals(candidate('WWW'), {'W', 'WW', 'WWW'})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_53_add", "language": "lua", "prompt": "-- Add two numbers x and y\n-- >>> add(2, 3)\n-- 5\n-- >>> add(5, 7)\n-- 12\nlocal function add(x, y)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_53_add.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = add\n    lu.assertEquals(candidate(0, 1), 1)\n    lu.assertEquals(candidate(1, 0), 1)\n    lu.assertEquals(candidate(2, 3), 5)\n    lu.assertEquals(candidate(5, 7), 12)\n    lu.assertEquals(candidate(7, 5), 12)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_53_add", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = add\n    lu.assertEquals(candidate(0, 1), 1)\n    lu.assertEquals(candidate(1, 0), 1)\n    lu.assertEquals(candidate(2, 3), 5)\n    lu.assertEquals(candidate(5, 7), 12)\n    lu.assertEquals(candidate(7, 5), 12)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_159_eat", "language": "lua", "prompt": "-- You're a hungry rabbit, and you already have eaten a certain number of carrots,\n-- but now you need to eat more carrots to complete the day's meals.\n-- you should return a table of [ total number of eaten carrots after your meals,\n-- the number of carrots left after your meals ]\n-- if there are not enough remaining carrots, you will eat all remaining carrots, but will still be hungry.\n-- Example:\n-- >>> eat(5, 6, 10)\n-- {11, 4}\n-- >>> eat(4, 8, 9)\n-- {12, 1}\n-- >>> eat(1, 10, 10)\n-- {11, 0}\n-- >>> eat(2, 11, 5)\n-- {7, 0}\n-- Variables:\n-- @number : integer\n-- the number of carrots that you have eaten.\n-- @need : integer\n-- the number of carrots that you need to eat.\n-- @remaining : integer\n-- the number of remaining carrots thet exist in stock\n-- Constrain:\n-- * 0 <= number <= 1000\n-- * 0 <= need <= 1000\n-- * 0 <= remaining <= 1000\n-- Have fun :)\nlocal function eat(number, need, remaining)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_159_eat.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = eat\n    lu.assertEquals(candidate(5, 6, 10), {11, 4})\n    lu.assertEquals(candidate(4, 8, 9), {12, 1})\n    lu.assertEquals(candidate(1, 10, 10), {11, 0})\n    lu.assertEquals(candidate(2, 11, 5), {7, 0})\n    lu.assertEquals(candidate(4, 5, 7), {9, 2})\n    lu.assertEquals(candidate(4, 5, 1), {5, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_159_eat", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = eat\n    lu.assertEquals(candidate(5, 6, 10), {11, 4})\n    lu.assertEquals(candidate(4, 8, 9), {12, 1})\n    lu.assertEquals(candidate(1, 10, 10), {11, 0})\n    lu.assertEquals(candidate(2, 11, 5), {7, 0})\n    lu.assertEquals(candidate(4, 5, 7), {9, 2})\n    lu.assertEquals(candidate(4, 5, 1), {5, 0})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_115_max_fill", "language": "lua", "prompt": "-- You are given a rectangular grid of wells. Each row represents a single well,\n-- and each 1 in a row represents a single unit of water.\n-- Each well has a corresponding bucket that can be used to extract water from it, \n-- and all buckets have the same capacity.\n-- Your task is to use the buckets to empty the wells.\n-- Output the number of times you need to lower the buckets.\n-- Example 1:\n-- >>> max_fill({{0, 0, 1, 0}, {0, 1, 0, 0}, {1, 1, 1, 1}}, 1)\n-- 6\n-- Example 2:\n-- >>> max_fill({{0, 0, 1, 1}, {0, 0, 0, 0}, {1, 1, 1, 1}, {0, 1, 1, 1}}, 2)\n-- 5\n-- Example 3:\n-- >>> max_fill({{0, 0, 0}, {0, 0, 0}}, 5)\n-- 0\n-- Constraints:\n-- * all wells have the same length\n-- * 1 <= grid.length <= 10^2\n-- * 1 <= grid[:,1].length <= 10^2\n-- * grid[i][j] -> 0 | 1\n-- * 1 <= capacity <= 10\nlocal function max_fill(grid, capacity)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_115_max_fill.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = max_fill\n    lu.assertEquals(candidate({{0, 0, 1, 0}, {0, 1, 0, 0}, {1, 1, 1, 1}}, 1), 6)\n    lu.assertEquals(candidate({{0, 0, 1, 1}, {0, 0, 0, 0}, {1, 1, 1, 1}, {0, 1, 1, 1}}, 2), 5)\n    lu.assertEquals(candidate({{0, 0, 0}, {0, 0, 0}}, 5), 0)\n    lu.assertEquals(candidate({{1, 1, 1, 1}, {1, 1, 1, 1}}, 2), 4)\n    lu.assertEquals(candidate({{1, 1, 1, 1}, {1, 1, 1, 1}}, 9), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_115_max_fill", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = max_fill\n    lu.assertEquals(candidate({{0, 0, 1, 0}, {0, 1, 0, 0}, {1, 1, 1, 1}}, 1), 6)\n    lu.assertEquals(candidate({{0, 0, 1, 1}, {0, 0, 0, 0}, {1, 1, 1, 1}, {0, 1, 1, 1}}, 2), 5)\n    lu.assertEquals(candidate({{0, 0, 0}, {0, 0, 0}}, 5), 0)\n    lu.assertEquals(candidate({{1, 1, 1, 1}, {1, 1, 1, 1}}, 2), 4)\n    lu.assertEquals(candidate({{1, 1, 1, 1}, {1, 1, 1, 1}}, 9), 2)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_160_do_algebra", "language": "lua", "prompt": "-- Given two tables operator, and operand. The first table has basic algebra operations, and \n-- the second table is a table of integers. Use the two given tables to build the algebric \n-- expression and return the evaluation of this expression.\n-- The basic algebra operations:\n-- Addition ( + ) \n-- Subtraction ( - ) \n-- Multiplication ( * ) \n-- Floor division ( // ) \n-- Exponentiation ( ** ) \n-- Example:\n-- operator['+', '*', '-']\n-- table = [2, 3, 4, 5]\n-- result = 2 + 3 * 4 - 5\n-- => result = 9\n-- Note:\n-- The length of operator table is equal to the length of operand table minus one.\n-- Operand is a table of of non-negative integers.\n-- Operator table has at least one operator, and operand table has at least two operands.\nlocal function do_algebra(operator, operand)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_160_do_algebra.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = do_algebra\n    lu.assertEquals(candidate({'**', '*', '+'}, {2, 3, 4, 5}), 37)\n    lu.assertEquals(candidate({'+', '*', '-'}, {2, 3, 4, 5}), 9)\n    lu.assertEquals(candidate({'//', '*'}, {7, 3, 4}), 8)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_160_do_algebra", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = do_algebra\n    lu.assertEquals(candidate({'**', '*', '+'}, {2, 3, 4, 5}), 37)\n    lu.assertEquals(candidate({'+', '*', '-'}, {2, 3, 4, 5}), 9)\n    lu.assertEquals(candidate({'//', '*'}, {7, 3, 4}), 8)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_27_flip_case", "language": "lua", "prompt": "-- For a given string, flip lowercase characters to uppercase and uppercase to lowercase.\n-- >>> flip_case('Hello')\n-- 'hELLO'\nlocal function flip_case(string)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_27_flip_case.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = flip_case\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('Hello!'), 'hELLO!')\n    lu.assertEquals(candidate('These violent delights have violent ends'), 'tHESE VIOLENT DELIGHTS HAVE VIOLENT ENDS')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_27_flip_case", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = flip_case\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('Hello!'), 'hELLO!')\n    lu.assertEquals(candidate('These violent delights have violent ends'), 'tHESE VIOLENT DELIGHTS HAVE VIOLENT ENDS')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_105_by_length", "language": "lua", "prompt": "-- Given a table of integers, sort the integers that are between 1 and 9 inclusive,\n-- reverse the resulting table, and then replace each digit by its corresponding name from\n-- \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\".\n-- For example:\n-- >>> by_length({2, 1, 1, 4, 5, 8, 2, 3})\n-- {'Eight', 'Five', 'Four', 'Three', 'Two', 'Two', 'One', 'One'}\n-- If the table is empty, return an empty table:\n-- >>> by_length({})\n-- {}\n-- If the table has any strange number ignore it:\n-- >>> by_length({1, -1, 55})\n-- {'One'}\nlocal function by_length(arr)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_105_by_length.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = by_length\n    lu.assertEquals(candidate({2, 1, 1, 4, 5, 8, 2, 3}), {'Eight', 'Five', 'Four', 'Three', 'Two', 'Two', 'One', 'One'})\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({1, -1, 55}), {'One'})\n    lu.assertEquals(candidate({1, -1, 3, 2}), {'Three', 'Two', 'One'})\n    lu.assertEquals(candidate({9, 4, 8}), {'Nine', 'Eight', 'Four'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_105_by_length", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = by_length\n    lu.assertEquals(candidate({2, 1, 1, 4, 5, 8, 2, 3}), {'Eight', 'Five', 'Four', 'Three', 'Two', 'Two', 'One', 'One'})\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({1, -1, 55}), {'One'})\n    lu.assertEquals(candidate({1, -1, 3, 2}), {'Three', 'Two', 'One'})\n    lu.assertEquals(candidate({9, 4, 8}), {'Nine', 'Eight', 'Four'})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_25_factorize", "language": "lua", "prompt": "-- Return table of prime factors of given integer in the order from smallest to largest.\n-- Each of the factors should be tableed number of times corresponding to how many times it appeares in factorization.\n-- Input number should be equal to the product of all factors\n-- >>> factorize(8)\n-- {2, 2, 2}\n-- >>> factorize(25)\n-- {5, 5}\n-- >>> factorize(70)\n-- {2, 5, 7}\nlocal function factorize(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_25_factorize.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = factorize\n    lu.assertEquals(candidate(2), {2})\n    lu.assertEquals(candidate(4), {2, 2})\n    lu.assertEquals(candidate(8), {2, 2, 2})\n    lu.assertEquals(candidate(57), {3, 19})\n    lu.assertEquals(candidate(3249), {3, 3, 19, 19})\n    lu.assertEquals(candidate(185193), {3, 3, 3, 19, 19, 19})\n    lu.assertEquals(candidate(20577), {3, 19, 19, 19})\n    lu.assertEquals(candidate(18), {2, 3, 3})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_25_factorize", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = factorize\n    lu.assertEquals(candidate(2), {2})\n    lu.assertEquals(candidate(4), {2, 2})\n    lu.assertEquals(candidate(8), {2, 2, 2})\n    lu.assertEquals(candidate(57), {3, 19})\n    lu.assertEquals(candidate(3249), {3, 3, 19, 19})\n    lu.assertEquals(candidate(185193), {3, 3, 3, 19, 19, 19})\n    lu.assertEquals(candidate(20577), {3, 19, 19, 19})\n    lu.assertEquals(candidate(18), {2, 3, 3})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_96_count_up_to", "language": "lua", "prompt": "-- Implement a function that takes an non-negative integer and returns a table of the first n\n-- integers that are prime numbers and less than n.\n-- for example:\n-- >>> count_up_to(5)\n-- {2, 3}\n-- >>> count_up_to(11)\n-- {2, 3, 5, 7}\n-- >>> count_up_to(0)\n-- {}\n-- >>> count_up_to(20)\n-- {2, 3, 5, 7, 11, 13, 17, 19}\n-- >>> count_up_to(1)\n-- {}\n-- >>> count_up_to(18)\n-- {2, 3, 5, 7, 11, 13, 17}\nlocal function count_up_to(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_96_count_up_to.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = count_up_to\n    lu.assertEquals(candidate(5), {2, 3})\n    lu.assertEquals(candidate(6), {2, 3, 5})\n    lu.assertEquals(candidate(7), {2, 3, 5})\n    lu.assertEquals(candidate(10), {2, 3, 5, 7})\n    lu.assertEquals(candidate(0), {})\n    lu.assertEquals(candidate(22), {2, 3, 5, 7, 11, 13, 17, 19})\n    lu.assertEquals(candidate(1), {})\n    lu.assertEquals(candidate(18), {2, 3, 5, 7, 11, 13, 17})\n    lu.assertEquals(candidate(47), {2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43})\n    lu.assertEquals(candidate(101), {2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_96_count_up_to", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = count_up_to\n    lu.assertEquals(candidate(5), {2, 3})\n    lu.assertEquals(candidate(6), {2, 3, 5})\n    lu.assertEquals(candidate(7), {2, 3, 5})\n    lu.assertEquals(candidate(10), {2, 3, 5, 7})\n    lu.assertEquals(candidate(0), {})\n    lu.assertEquals(candidate(22), {2, 3, 5, 7, 11, 13, 17, 19})\n    lu.assertEquals(candidate(1), {})\n    lu.assertEquals(candidate(18), {2, 3, 5, 7, 11, 13, 17})\n    lu.assertEquals(candidate(47), {2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43})\n    lu.assertEquals(candidate(101), {2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_34_unique", "language": "lua", "prompt": "-- Return sorted unique elements in a table\n-- >>> unique({5, 3, 5, 2, 3, 3, 9, 0, 123})\n-- {0, 2, 3, 5, 9, 123}\nlocal function unique(l)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_34_unique.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = unique\n    lu.assertEquals(candidate({5, 3, 5, 2, 3, 3, 9, 0, 123}), {0, 2, 3, 5, 9, 123})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_34_unique", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = unique\n    lu.assertEquals(candidate({5, 3, 5, 2, 3, 3, 9, 0, 123}), {0, 2, 3, 5, 9, 123})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_74_total_match", "language": "lua", "prompt": "-- Write a function that accepts two tables of strings and returns the table that has \n-- total number of chars in the all strings of the table less than the other table.\n-- if the two tables have the same number of chars, return the first table.\n-- Examples\n-- >>> total_match({}, {})\n-- {}\n-- >>> total_match({'hi', 'admin'}, {'hI', 'Hi'})\n-- {'hI', 'Hi'}\n-- >>> total_match({'hi', 'admin'}, {'hi', 'hi', 'admin', 'project'})\n-- {'hi', 'admin'}\n-- >>> total_match({'hi', 'admin'}, {'hI', 'hi', 'hi'})\n-- {'hI', 'hi', 'hi'}\n-- >>> total_match({'4'}, {'1', '2', '3', '4', '5'})\n-- {'4'}\nlocal function total_match(lst1, lst2)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_74_total_match.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = total_match\n    lu.assertEquals(candidate({}, {}), {})\n    lu.assertEquals(candidate({'hi', 'admin'}, {'hi', 'hi'}), {'hi', 'hi'})\n    lu.assertEquals(candidate({'hi', 'admin'}, {'hi', 'hi', 'admin', 'project'}), {'hi', 'admin'})\n    lu.assertEquals(candidate({'4'}, {'1', '2', '3', '4', '5'}), {'4'})\n    lu.assertEquals(candidate({'hi', 'admin'}, {'hI', 'Hi'}), {'hI', 'Hi'})\n    lu.assertEquals(candidate({'hi', 'admin'}, {'hI', 'hi', 'hi'}), {'hI', 'hi', 'hi'})\n    lu.assertEquals(candidate({'hi', 'admin'}, {'hI', 'hi', 'hii'}), {'hi', 'admin'})\n    lu.assertEquals(candidate({}, {'this'}), {})\n    lu.assertEquals(candidate({'this'}, {}), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_74_total_match", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = total_match\n    lu.assertEquals(candidate({}, {}), {})\n    lu.assertEquals(candidate({'hi', 'admin'}, {'hi', 'hi'}), {'hi', 'hi'})\n    lu.assertEquals(candidate({'hi', 'admin'}, {'hi', 'hi', 'admin', 'project'}), {'hi', 'admin'})\n    lu.assertEquals(candidate({'4'}, {'1', '2', '3', '4', '5'}), {'4'})\n    lu.assertEquals(candidate({'hi', 'admin'}, {'hI', 'Hi'}), {'hI', 'Hi'})\n    lu.assertEquals(candidate({'hi', 'admin'}, {'hI', 'hi', 'hi'}), {'hI', 'hi', 'hi'})\n    lu.assertEquals(candidate({'hi', 'admin'}, {'hI', 'hi', 'hii'}), {'hi', 'admin'})\n    lu.assertEquals(candidate({}, {'this'}), {})\n    lu.assertEquals(candidate({'this'}, {}), {})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_35_max_element", "language": "lua", "prompt": "-- Return maximum element in the table.\n-- >>> max_element({1, 2, 3})\n-- 3\n-- >>> max_element({5, 3, -5, 2, -3, 3, 9, 0, 123, 1, -10})\n-- 123\nlocal function max_element(l)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_35_max_element.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = max_element\n    lu.assertEquals(candidate({1, 2, 3}), 3)\n    lu.assertEquals(candidate({5, 3, -5, 2, -3, 3, 9, 0, 124, 1, -10}), 124)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_35_max_element", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = max_element\n    lu.assertEquals(candidate({1, 2, 3}), 3)\n    lu.assertEquals(candidate({5, 3, -5, 2, -3, 3, 9, 0, 124, 1, -10}), 124)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_132_is_nested", "language": "lua", "prompt": "-- Create a function that takes a string as input which contains only square brackets.\n-- The function should return true if and only if there is a valid subsequence of brackets \n-- where at least one bracket in the subsequence is nested.\n-- >>> is_nested('[[]]')\n-- true\n-- >>> is_nested('[]]]]]]][[[[[]')\n-- false\n-- >>> is_nested('[][]')\n-- false\n-- >>> is_nested('[]')\n-- false\n-- >>> is_nested('[[][]]')\n-- true\n-- >>> is_nested('[[]][[')\n-- true\nlocal function is_nested(string)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_132_is_nested.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_nested\n    lu.assertEquals(candidate('[[]]'), true)\n    lu.assertEquals(candidate('[]]]]]]][[[[[]'), false)\n    lu.assertEquals(candidate('[][]'), false)\n    lu.assertEquals(candidate('[]'), false)\n    lu.assertEquals(candidate('[[[[]]]]'), true)\n    lu.assertEquals(candidate('[]]]]]]]]]]'), false)\n    lu.assertEquals(candidate('[][][[]]'), true)\n    lu.assertEquals(candidate('[[]'), false)\n    lu.assertEquals(candidate('[]]'), false)\n    lu.assertEquals(candidate('[[]][['), true)\n    lu.assertEquals(candidate('[[][]]'), true)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('[[[[[[[['), false)\n    lu.assertEquals(candidate(']]]]]]]]'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_132_is_nested", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_nested\n    lu.assertEquals(candidate('[[]]'), true)\n    lu.assertEquals(candidate('[]]]]]]][[[[[]'), false)\n    lu.assertEquals(candidate('[][]'), false)\n    lu.assertEquals(candidate('[]'), false)\n    lu.assertEquals(candidate('[[[[]]]]'), true)\n    lu.assertEquals(candidate('[]]]]]]]]]]'), false)\n    lu.assertEquals(candidate('[][][[]]'), true)\n    lu.assertEquals(candidate('[[]'), false)\n    lu.assertEquals(candidate('[]]'), false)\n    lu.assertEquals(candidate('[[]][['), true)\n    lu.assertEquals(candidate('[[][]]'), true)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('[[[[[[[['), false)\n    lu.assertEquals(candidate(']]]]]]]]'), false)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_103_rounded_avg", "language": "lua", "prompt": "-- You are given two positive integers n and m, and your task is to compute the\n-- average of the integers from n through m (including n and m). \n-- Round the answer to the nearest integer and convert that to binary.\n-- If n is greater than m, return -1.\n-- Example:\n-- >>> rounded_avg(1, 5)\n-- '0b11'\n-- >>> rounded_avg(7, 5)\n-- -1\n-- >>> rounded_avg(10, 20)\n-- '0b1111'\n-- >>> rounded_avg(20, 33)\n-- '0b11010'\nlocal function rounded_avg(n, m)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_103_rounded_avg.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = rounded_avg\n    lu.assertEquals(candidate(1, 5), '0b11')\n    lu.assertEquals(candidate(7, 13), '0b1010')\n    lu.assertEquals(candidate(964, 977), '0b1111001010')\n    lu.assertEquals(candidate(996, 997), '0b1111100100')\n    lu.assertEquals(candidate(560, 851), '0b1011000010')\n    lu.assertEquals(candidate(185, 546), '0b101101110')\n    lu.assertEquals(candidate(362, 496), '0b110101101')\n    lu.assertEquals(candidate(350, 902), '0b1001110010')\n    lu.assertEquals(candidate(197, 233), '0b11010111')\n    lu.assertEquals(candidate(7, 5), -1)\n    lu.assertEquals(candidate(5, 1), -1)\n    lu.assertEquals(candidate(5, 5), '0b101')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_103_rounded_avg", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = rounded_avg\n    lu.assertEquals(candidate(1, 5), '0b11')\n    lu.assertEquals(candidate(7, 13), '0b1010')\n    lu.assertEquals(candidate(964, 977), '0b1111001010')\n    lu.assertEquals(candidate(996, 997), '0b1111100100')\n    lu.assertEquals(candidate(560, 851), '0b1011000010')\n    lu.assertEquals(candidate(185, 546), '0b101101110')\n    lu.assertEquals(candidate(362, 496), '0b110101101')\n    lu.assertEquals(candidate(350, 902), '0b1001110010')\n    lu.assertEquals(candidate(197, 233), '0b11010111')\n    lu.assertEquals(candidate(7, 5), -1)\n    lu.assertEquals(candidate(5, 1), -1)\n    lu.assertEquals(candidate(5, 5), '0b101')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_113_odd_count", "language": "lua", "prompt": "-- Given a table of strings, where each string consists of only digits, return a table.\n-- Each element i of the output should be \"the number of odd elements in the\n-- string i of the input.\" where all the i's should be replaced by the number\n-- of odd digits in the i'th string of the input.\n-- >>> odd_count({'1234567'})\n-- {'the number of odd elements 4n the str4ng 4 of the 4nput.'}\n-- >>> odd_count({'3', '11111111'})\n-- {'the number of odd elements 1n the str1ng 1 of the 1nput.', 'the number of odd elements 8n the str8ng 8 of the 8nput.'}\nlocal function odd_count(lst)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_113_odd_count.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = odd_count\n    lu.assertEquals(candidate({'1234567'}), {'the number of odd elements 4n the str4ng 4 of the 4nput.'})\n    lu.assertEquals(candidate({'3', '11111111'}), {'the number of odd elements 1n the str1ng 1 of the 1nput.', 'the number of odd elements 8n the str8ng 8 of the 8nput.'})\n    lu.assertEquals(candidate({'271', '137', '314'}), {'the number of odd elements 2n the str2ng 2 of the 2nput.', 'the number of odd elements 3n the str3ng 3 of the 3nput.', 'the number of odd elements 2n the str2ng 2 of the 2nput.'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_113_odd_count", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = odd_count\n    lu.assertEquals(candidate({'1234567'}), {'the number of odd elements 4n the str4ng 4 of the 4nput.'})\n    lu.assertEquals(candidate({'3', '11111111'}), {'the number of odd elements 1n the str1ng 1 of the 1nput.', 'the number of odd elements 8n the str8ng 8 of the 8nput.'})\n    lu.assertEquals(candidate({'271', '137', '314'}), {'the number of odd elements 2n the str2ng 2 of the 2nput.', 'the number of odd elements 3n the str3ng 3 of the 3nput.', 'the number of odd elements 2n the str2ng 2 of the 2nput.'})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_109_move_one_ball", "language": "lua", "prompt": "-- We have a table 'arr' of N integers arr[1], arr[2], ..., arr[N].The\n-- numbers in the table will be randomly ordered. Your task is to determine if\n-- it is possible to get a table sorted in non-decreasing order by performing \n-- the following operation on the given table:\n-- You are allowed to perform right shift operation any number of times.\n-- One right shift operation means shifting all elements of the table by one\n-- position in the right direction. The last element of the table will be moved to\n-- the starting position in the table i.e. 0th index. \n-- If it is possible to obtain the sorted table by performing the above operation\n-- then return true else return false.\n-- If the given table is empty then return true.\n-- Note: The given table is guaranteed to have unique elements.\n-- For Example:\n-- >>> move_one_ball({3, 4, 5, 1, 2})\n-- true\n-- Explanation: By performin 2 right shift operations, non-decreasing order can\n-- be achieved for the given table.\n-- >>> move_one_ball({3, 5, 4, 1, 2})\n-- false\n-- Explanation:It is not possible to get non-decreasing order for the given\n-- table by performing any number of right shift operations.\nlocal function move_one_ball(arr)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_109_move_one_ball.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = move_one_ball\n    lu.assertEquals(candidate({3, 4, 5, 1, 2}), true)\n    lu.assertEquals(candidate({3, 5, 10, 1, 2}), true)\n    lu.assertEquals(candidate({4, 3, 1, 2}), false)\n    lu.assertEquals(candidate({3, 5, 4, 1, 2}), false)\n    lu.assertEquals(candidate({}), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_109_move_one_ball", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = move_one_ball\n    lu.assertEquals(candidate({3, 4, 5, 1, 2}), true)\n    lu.assertEquals(candidate({3, 5, 10, 1, 2}), true)\n    lu.assertEquals(candidate({4, 3, 1, 2}), false)\n    lu.assertEquals(candidate({3, 5, 4, 1, 2}), false)\n    lu.assertEquals(candidate({}), true)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_107_even_odd_palindrome", "language": "lua", "prompt": "-- Given a positive integer n, return a table that has the number of even and odd\n-- integer palindromes that fall within the range(1, n), inclusive.\n-- Example 1:\n-- >>> even_odd_palindrome(3)\n-- {1, 2}\n-- Explanation:\n-- Integer palindrome are 1, 2, 3. one of them is even, and two of them are odd.\n-- Example 2:\n-- >>> even_odd_palindrome(12)\n-- {4, 6}\n-- Explanation:\n-- Integer palindrome are 1, 2, 3, 4, 5, 6, 7, 8, 9, 11. four of them are even, and 6 of them are odd.\n-- Note:\n-- 1. 1 <= n <= 10^3\n-- 2. returned table has the number of even and odd integer palindromes respectively.\nlocal function even_odd_palindrome(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_107_even_odd_palindrome.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = even_odd_palindrome\n    lu.assertEquals(candidate(123), {8, 13})\n    lu.assertEquals(candidate(12), {4, 6})\n    lu.assertEquals(candidate(3), {1, 2})\n    lu.assertEquals(candidate(63), {6, 8})\n    lu.assertEquals(candidate(25), {5, 6})\n    lu.assertEquals(candidate(19), {4, 6})\n    lu.assertEquals(candidate(9), {4, 5})\n    lu.assertEquals(candidate(1), {0, 1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_107_even_odd_palindrome", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = even_odd_palindrome\n    lu.assertEquals(candidate(123), {8, 13})\n    lu.assertEquals(candidate(12), {4, 6})\n    lu.assertEquals(candidate(3), {1, 2})\n    lu.assertEquals(candidate(63), {6, 8})\n    lu.assertEquals(candidate(25), {5, 6})\n    lu.assertEquals(candidate(19), {4, 6})\n    lu.assertEquals(candidate(9), {4, 5})\n    lu.assertEquals(candidate(1), {0, 1})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_138_is_equal_to_sum_even", "language": "lua", "prompt": "-- Evaluate whether the given number n can be written as the sum of exactly 4 positive even numbers\n-- Example\n-- >>> is_equal_to_sum_even(4)\n-- false\n-- >>> is_equal_to_sum_even(6)\n-- false\n-- >>> is_equal_to_sum_even(8)\n-- true\nlocal function is_equal_to_sum_even(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_138_is_equal_to_sum_even.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_equal_to_sum_even\n    lu.assertEquals(candidate(4), false)\n    lu.assertEquals(candidate(6), false)\n    lu.assertEquals(candidate(8), true)\n    lu.assertEquals(candidate(10), true)\n    lu.assertEquals(candidate(11), false)\n    lu.assertEquals(candidate(12), true)\n    lu.assertEquals(candidate(13), false)\n    lu.assertEquals(candidate(16), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_138_is_equal_to_sum_even", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_equal_to_sum_even\n    lu.assertEquals(candidate(4), false)\n    lu.assertEquals(candidate(6), false)\n    lu.assertEquals(candidate(8), true)\n    lu.assertEquals(candidate(10), true)\n    lu.assertEquals(candidate(11), false)\n    lu.assertEquals(candidate(12), true)\n    lu.assertEquals(candidate(13), false)\n    lu.assertEquals(candidate(16), true)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_62_derivative", "language": "lua", "prompt": "-- xs represent coefficients of a polynomial.\n-- xs[0] + xs[1] * x + xs[2] * x^2 + ....\n-- Return derivative of this polynomial in the same form.\n-- >>> derivative({3, 1, 2, 4, 5})\n-- {1, 4, 12, 20}\n-- >>> derivative({1, 2, 3})\n-- {2, 6}\nlocal function derivative(xs)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_62_derivative.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = derivative\n    lu.assertEquals(candidate({3, 1, 2, 4, 5}), {1, 4, 12, 20})\n    lu.assertEquals(candidate({1, 2, 3}), {2, 6})\n    lu.assertEquals(candidate({3, 2, 1}), {2, 2})\n    lu.assertEquals(candidate({3, 2, 1, 0, 4}), {2, 2, 0, 16})\n    lu.assertEquals(candidate({1}), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_62_derivative", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = derivative\n    lu.assertEquals(candidate({3, 1, 2, 4, 5}), {1, 4, 12, 20})\n    lu.assertEquals(candidate({1, 2, 3}), {2, 6})\n    lu.assertEquals(candidate({3, 2, 1}), {2, 2})\n    lu.assertEquals(candidate({3, 2, 1, 0, 4}), {2, 2, 0, 16})\n    lu.assertEquals(candidate({1}), {})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_126_is_sorted", "language": "lua", "prompt": "-- Given a table of numbers, return whether or not they are sorted\n-- in ascending order. If table has more than 1 duplicate of the same\n-- number, return false. Assume no negative numbers and only integers.\n-- Examples\n-- >>> is_sorted({5})\n-- true\n-- >>> is_sorted({1, 2, 3, 4, 5})\n-- true\n-- >>> is_sorted({1, 3, 2, 4, 5})\n-- false\n-- >>> is_sorted({1, 2, 3, 4, 5, 6})\n-- true\n-- >>> is_sorted({1, 2, 3, 4, 5, 6, 7})\n-- true\n-- >>> is_sorted({1, 3, 2, 4, 5, 6, 7})\n-- false\n-- >>> is_sorted({1, 2, 2, 3, 3, 4})\n-- true\n-- >>> is_sorted({1, 2, 2, 2, 3, 4})\n-- false\nlocal function is_sorted(lst)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_126_is_sorted.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_sorted\n    lu.assertEquals(candidate({5}), true)\n    lu.assertEquals(candidate({1, 2, 3, 4, 5}), true)\n    lu.assertEquals(candidate({1, 3, 2, 4, 5}), false)\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6}), true)\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6, 7}), true)\n    lu.assertEquals(candidate({1, 3, 2, 4, 5, 6, 7}), false)\n    lu.assertEquals(candidate({}), true)\n    lu.assertEquals(candidate({1}), true)\n    lu.assertEquals(candidate({3, 2, 1}), false)\n    lu.assertEquals(candidate({1, 2, 2, 2, 3, 4}), false)\n    lu.assertEquals(candidate({1, 2, 3, 3, 3, 4}), false)\n    lu.assertEquals(candidate({1, 2, 2, 3, 3, 4}), true)\n    lu.assertEquals(candidate({1, 2, 3, 4}), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_126_is_sorted", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_sorted\n    lu.assertEquals(candidate({5}), true)\n    lu.assertEquals(candidate({1, 2, 3, 4, 5}), true)\n    lu.assertEquals(candidate({1, 3, 2, 4, 5}), false)\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6}), true)\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6, 7}), true)\n    lu.assertEquals(candidate({1, 3, 2, 4, 5, 6, 7}), false)\n    lu.assertEquals(candidate({}), true)\n    lu.assertEquals(candidate({1}), true)\n    lu.assertEquals(candidate({3, 2, 1}), false)\n    lu.assertEquals(candidate({1, 2, 2, 2, 3, 4}), false)\n    lu.assertEquals(candidate({1, 2, 3, 3, 3, 4}), false)\n    lu.assertEquals(candidate({1, 2, 2, 3, 3, 4}), true)\n    lu.assertEquals(candidate({1, 2, 3, 4}), true)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_161_solve", "language": "lua", "prompt": "-- You are given a string s.\n-- if s[i] is a letter, reverse its case from lower to upper or vise versa, \n-- otherwise keep it as it is.\n-- If the string contains no letters, reverse the string.\n-- The function should return the resulted string.\n-- Examples\n-- >>> solve('1234')\n-- '4321'\n-- >>> solve('ab')\n-- 'AB'\n-- >>> solve('#a@C')\n-- '#A@c'\nlocal function solve(s)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_161_solve.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = solve\n    lu.assertEquals(candidate('AsDf'), 'aSdF')\n    lu.assertEquals(candidate('1234'), '4321')\n    lu.assertEquals(candidate('ab'), 'AB')\n    lu.assertEquals(candidate('#a@C'), '#A@c')\n    lu.assertEquals(candidate('#AsdfW^45'), '#aSDFw^45')\n    lu.assertEquals(candidate('#6@2'), '2@6#')\n    lu.assertEquals(candidate('#$a^D'), '#$A^d')\n    lu.assertEquals(candidate('#ccc'), '#CCC')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_161_solve", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = solve\n    lu.assertEquals(candidate('AsDf'), 'aSdF')\n    lu.assertEquals(candidate('1234'), '4321')\n    lu.assertEquals(candidate('ab'), 'AB')\n    lu.assertEquals(candidate('#a@C'), '#A@c')\n    lu.assertEquals(candidate('#AsdfW^45'), '#aSDFw^45')\n    lu.assertEquals(candidate('#6@2'), '2@6#')\n    lu.assertEquals(candidate('#$a^D'), '#$A^d')\n    lu.assertEquals(candidate('#ccc'), '#CCC')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_130_tri", "language": "lua", "prompt": "-- Everyone knows Fibonacci sequence, it was studied deeply by mathematicians in \n-- the last couple centuries. However, what people don't know is Tribonacci sequence.\n-- Tribonacci sequence is defined by the recurrence:\n-- tri(1) = 3\n-- tri(n) = 1 + n / 2, if n is even.\n-- tri(n) =  tri(n - 1) + tri(n - 2) + tri(n + 1), if n is odd.\n-- For example:\n-- tri(2) = 1 + (2 / 2) = 2\n-- tri(4) = 3\n-- tri(3) = tri(2) + tri(1) + tri(4)\n-- = 2 + 3 + 3 = 8 \n-- You are given a non-negative integer number n, you have to a return a table of the \n-- first n + 1 numbers of the Tribonacci sequence.\n-- Examples:\n-- >>> tri(3)\n-- {1, 3, 2, 8}\nlocal function tri(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_130_tri.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = tri\n    lu.assertEquals(candidate(3), {1, 3, 2, 8})\n    lu.assertEquals(candidate(4), {1, 3, 2, 8, 3})\n    lu.assertEquals(candidate(5), {1, 3, 2, 8, 3, 15})\n    lu.assertEquals(candidate(6), {1, 3, 2, 8, 3, 15, 4})\n    lu.assertEquals(candidate(7), {1, 3, 2, 8, 3, 15, 4, 24})\n    lu.assertEquals(candidate(8), {1, 3, 2, 8, 3, 15, 4, 24, 5})\n    lu.assertEquals(candidate(9), {1, 3, 2, 8, 3, 15, 4, 24, 5, 35})\n    lu.assertEquals(candidate(20), {1, 3, 2, 8, 3, 15, 4, 24, 5, 35, 6, 48, 7, 63, 8, 80, 9, 99, 10, 120, 11})\n    lu.assertEquals(candidate(0), {1})\n    lu.assertEquals(candidate(1), {1, 3})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_130_tri", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = tri\n    lu.assertEquals(candidate(3), {1, 3, 2, 8})\n    lu.assertEquals(candidate(4), {1, 3, 2, 8, 3})\n    lu.assertEquals(candidate(5), {1, 3, 2, 8, 3, 15})\n    lu.assertEquals(candidate(6), {1, 3, 2, 8, 3, 15, 4})\n    lu.assertEquals(candidate(7), {1, 3, 2, 8, 3, 15, 4, 24})\n    lu.assertEquals(candidate(8), {1, 3, 2, 8, 3, 15, 4, 24, 5})\n    lu.assertEquals(candidate(9), {1, 3, 2, 8, 3, 15, 4, 24, 5, 35})\n    lu.assertEquals(candidate(20), {1, 3, 2, 8, 3, 15, 4, 24, 5, 35, 6, 48, 7, 63, 8, 80, 9, 99, 10, 120, 11})\n    lu.assertEquals(candidate(0), {1})\n    lu.assertEquals(candidate(1), {1, 3})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_36_fizz_buzz", "language": "lua", "prompt": "-- Return the number of times the digit 7 appears in integers less than n which are divisible by 11 or 13.\n-- >>> fizz_buzz(50)\n-- 0\n-- >>> fizz_buzz(78)\n-- 2\n-- >>> fizz_buzz(79)\n-- 3\nlocal function fizz_buzz(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_36_fizz_buzz.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fizz_buzz\n    lu.assertEquals(candidate(50), 0)\n    lu.assertEquals(candidate(78), 2)\n    lu.assertEquals(candidate(79), 3)\n    lu.assertEquals(candidate(100), 3)\n    lu.assertEquals(candidate(200), 6)\n    lu.assertEquals(candidate(4000), 192)\n    lu.assertEquals(candidate(10000), 639)\n    lu.assertEquals(candidate(100000), 8026)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_36_fizz_buzz", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fizz_buzz\n    lu.assertEquals(candidate(50), 0)\n    lu.assertEquals(candidate(78), 2)\n    lu.assertEquals(candidate(79), 3)\n    lu.assertEquals(candidate(100), 3)\n    lu.assertEquals(candidate(200), 6)\n    lu.assertEquals(candidate(4000), 192)\n    lu.assertEquals(candidate(10000), 639)\n    lu.assertEquals(candidate(100000), 8026)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_29_filter_by_prefix", "language": "lua", "prompt": "-- Filter an input table of strings only for ones that start with a given prefix.\n-- >>> filter_by_prefix({}, 'a')\n-- {}\n-- >>> filter_by_prefix({'abc', 'bcd', 'cde', 'array'}, 'a')\n-- {'abc', 'array'}\nlocal function filter_by_prefix(strings, prefix)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_29_filter_by_prefix.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = filter_by_prefix\n    lu.assertEquals(candidate({}, 'john'), {})\n    lu.assertEquals(candidate({'xxx', 'asd', 'xxy', 'john doe', 'xxxAAA', 'xxx'}, 'xxx'), {'xxx', 'xxxAAA', 'xxx'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_29_filter_by_prefix", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = filter_by_prefix\n    lu.assertEquals(candidate({}, 'john'), {})\n    lu.assertEquals(candidate({'xxx', 'asd', 'xxy', 'john doe', 'xxxAAA', 'xxx'}, 'xxx'), {'xxx', 'xxxAAA', 'xxx'})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_84_solve", "language": "lua", "prompt": "-- Given a positive integer N, return the total sum of its digits in binary.\n-- Example\n-- >>> solve(1000)\n-- '1'\n-- >>> solve(150)\n-- '110'\n-- >>> solve(147)\n-- '1100'\n-- Variables:\n-- @N integer\n-- Constraints: 0 \u2264 N \u2264 10000.\n-- Output:\n-- a string of binary number\nlocal function solve(N)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_84_solve.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = solve\n    lu.assertEquals(candidate(1000), '1')\n    lu.assertEquals(candidate(150), '110')\n    lu.assertEquals(candidate(147), '1100')\n    lu.assertEquals(candidate(333), '1001')\n    lu.assertEquals(candidate(963), '10010')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_84_solve", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = solve\n    lu.assertEquals(candidate(1000), '1')\n    lu.assertEquals(candidate(150), '110')\n    lu.assertEquals(candidate(147), '1100')\n    lu.assertEquals(candidate(333), '1001')\n    lu.assertEquals(candidate(963), '10010')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_129_minPath", "language": "lua", "prompt": "-- Given a grid with N rows and N columns (N >= 2) and a positive integer k, \n-- each cell of the grid contains a value. Every integer in the range [1, N * N]\n-- inclusive appears exactly once on the cells of the grid.\n-- You have to find the minimum path of length k in the grid. You can start\n-- from any cell, and in each step you can move to any of the neighbor cells,\n-- in other words, you can go to cells which share an edge with you current\n-- cell.\n-- Please note that a path of length k means visiting exactly k cells (not\n-- necessarily distinct).\n-- You CANNOT go off the grid.\n-- A path A (of length k) is considered less than a path B (of length k) if\n-- after making the ordered tables of the values on the cells that A and B go\n-- through (let's call them lst_A and lst_B), lst_A is lexicographically less\n-- than lst_B, in other words, there exist an integer index i (1 <= i <= k)\n-- such that lst_A[i] < lst_B[i] and for any j (1 <= j < i) we have\n-- lst_A[j] = lst_B[j].\n-- It is guaranteed that the answer is unique.\n-- Return an ordered table of the values on the cells that the minimum path go through.\n-- Examples:    \n-- >>> minPath({{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}, 3)\n-- {1, 2, 1}\n-- >>> minPath({{5, 9, 3}, {4, 1, 6}, {7, 8, 2}}, 1)\n-- {1}\nlocal function minPath(grid, k)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_129_minPath.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = minPath\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}, 3), {1, 2, 1})\n    lu.assertEquals(candidate({{5, 9, 3}, {4, 1, 6}, {7, 8, 2}}, 1), {1})\n    lu.assertEquals(candidate({{1, 2, 3, 4}, {5, 6, 7, 8}, {9, 10, 11, 12}, {13, 14, 15, 16}}, 4), {1, 2, 1, 2})\n    lu.assertEquals(candidate({{6, 4, 13, 10}, {5, 7, 12, 1}, {3, 16, 11, 15}, {8, 14, 9, 2}}, 7), {1, 10, 1, 10, 1, 10, 1})\n    lu.assertEquals(candidate({{8, 14, 9, 2}, {6, 4, 13, 15}, {5, 7, 1, 12}, {3, 10, 11, 16}}, 5), {1, 7, 1, 7, 1})\n    lu.assertEquals(candidate({{11, 8, 7, 2}, {5, 16, 14, 4}, {9, 3, 15, 6}, {12, 13, 10, 1}}, 9), {1, 6, 1, 6, 1, 6, 1, 6, 1})\n    lu.assertEquals(candidate({{12, 13, 10, 1}, {9, 3, 15, 6}, {5, 16, 14, 4}, {11, 8, 7, 2}}, 12), {1, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6})\n    lu.assertEquals(candidate({{2, 7, 4}, {3, 1, 5}, {6, 8, 9}}, 8), {1, 3, 1, 3, 1, 3, 1, 3})\n    lu.assertEquals(candidate({{6, 1, 5}, {3, 8, 9}, {2, 7, 4}}, 8), {1, 5, 1, 5, 1, 5, 1, 5})\n    lu.assertEquals(candidate({{1, 2}, {3, 4}}, 10), {1, 2, 1, 2, 1, 2, 1, 2, 1, 2})\n    lu.assertEquals(candidate({{1, 3}, {3, 2}}, 10), {1, 3, 1, 3, 1, 3, 1, 3, 1, 3})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_129_minPath", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = minPath\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}, 3), {1, 2, 1})\n    lu.assertEquals(candidate({{5, 9, 3}, {4, 1, 6}, {7, 8, 2}}, 1), {1})\n    lu.assertEquals(candidate({{1, 2, 3, 4}, {5, 6, 7, 8}, {9, 10, 11, 12}, {13, 14, 15, 16}}, 4), {1, 2, 1, 2})\n    lu.assertEquals(candidate({{6, 4, 13, 10}, {5, 7, 12, 1}, {3, 16, 11, 15}, {8, 14, 9, 2}}, 7), {1, 10, 1, 10, 1, 10, 1})\n    lu.assertEquals(candidate({{8, 14, 9, 2}, {6, 4, 13, 15}, {5, 7, 1, 12}, {3, 10, 11, 16}}, 5), {1, 7, 1, 7, 1})\n    lu.assertEquals(candidate({{11, 8, 7, 2}, {5, 16, 14, 4}, {9, 3, 15, 6}, {12, 13, 10, 1}}, 9), {1, 6, 1, 6, 1, 6, 1, 6, 1})\n    lu.assertEquals(candidate({{12, 13, 10, 1}, {9, 3, 15, 6}, {5, 16, 14, 4}, {11, 8, 7, 2}}, 12), {1, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6})\n    lu.assertEquals(candidate({{2, 7, 4}, {3, 1, 5}, {6, 8, 9}}, 8), {1, 3, 1, 3, 1, 3, 1, 3})\n    lu.assertEquals(candidate({{6, 1, 5}, {3, 8, 9}, {2, 7, 4}}, 8), {1, 5, 1, 5, 1, 5, 1, 5})\n    lu.assertEquals(candidate({{1, 2}, {3, 4}}, 10), {1, 2, 1, 2, 1, 2, 1, 2, 1, 2})\n    lu.assertEquals(candidate({{1, 3}, {3, 2}}, 10), {1, 3, 1, 3, 1, 3, 1, 3, 1, 3})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_98_count_upper", "language": "lua", "prompt": "-- Given a string s, count the number of uppercase vowels in even indices.\n-- For example:\n-- >>> count_upper('aBCdEf')\n-- 1\n-- >>> count_upper('abcdefg')\n-- 0\n-- >>> count_upper('dBBE')\n-- 0\nlocal function count_upper(s)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_98_count_upper.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = count_upper\n    lu.assertEquals(candidate('aBCdEf'), 1)\n    lu.assertEquals(candidate('abcdefg'), 0)\n    lu.assertEquals(candidate('dBBE'), 0)\n    lu.assertEquals(candidate('B'), 0)\n    lu.assertEquals(candidate('U'), 1)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('EEEE'), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_98_count_upper", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = count_upper\n    lu.assertEquals(candidate('aBCdEf'), 1)\n    lu.assertEquals(candidate('abcdefg'), 0)\n    lu.assertEquals(candidate('dBBE'), 0)\n    lu.assertEquals(candidate('B'), 0)\n    lu.assertEquals(candidate('U'), 1)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('EEEE'), 2)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_120_maximum", "language": "lua", "prompt": "-- Given a table arr of integers and a positive integer k, return a sorted table \n-- of length k with the maximum k numbers in arr.\n-- Example 1:\n-- >>> maximum({-3, -4, 5}, 3)\n-- {-4, -3, 5}\n-- Example 2:\n-- >>> maximum({4, -4, 4}, 2)\n-- {4, 4}\n-- Example 3:\n-- >>> maximum({-3, 2, 1, 2, -1, -2, 1}, 1)\n-- {2}\n-- Note:\n-- 1. The length of the table will be in the range of [1, 1000].\n-- 2. The elements in the table will be in the range of [-1000, 1000].\n-- 3. 0 <= k <= len(arr)\nlocal function maximum(arr, k)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_120_maximum.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = maximum\n    lu.assertEquals(candidate({-3, -4, 5}, 3), {-4, -3, 5})\n    lu.assertEquals(candidate({4, -4, 4}, 2), {4, 4})\n    lu.assertEquals(candidate({-3, 2, 1, 2, -1, -2, 1}, 1), {2})\n    lu.assertEquals(candidate({123, -123, 20, 0, 1, 2, -3}, 3), {2, 20, 123})\n    lu.assertEquals(candidate({-123, 20, 0, 1, 2, -3}, 4), {0, 1, 2, 20})\n    lu.assertEquals(candidate({5, 15, 0, 3, -13, -8, 0}, 7), {-13, -8, 0, 0, 3, 5, 15})\n    lu.assertEquals(candidate({-1, 0, 2, 5, 3, -10}, 2), {3, 5})\n    lu.assertEquals(candidate({1, 0, 5, -7}, 1), {5})\n    lu.assertEquals(candidate({4, -4}, 2), {-4, 4})\n    lu.assertEquals(candidate({-10, 10}, 2), {-10, 10})\n    lu.assertEquals(candidate({1, 2, 3, -23, 243, -400, 0}, 0), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_120_maximum", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = maximum\n    lu.assertEquals(candidate({-3, -4, 5}, 3), {-4, -3, 5})\n    lu.assertEquals(candidate({4, -4, 4}, 2), {4, 4})\n    lu.assertEquals(candidate({-3, 2, 1, 2, -1, -2, 1}, 1), {2})\n    lu.assertEquals(candidate({123, -123, 20, 0, 1, 2, -3}, 3), {2, 20, 123})\n    lu.assertEquals(candidate({-123, 20, 0, 1, 2, -3}, 4), {0, 1, 2, 20})\n    lu.assertEquals(candidate({5, 15, 0, 3, -13, -8, 0}, 7), {-13, -8, 0, 0, 3, 5, 15})\n    lu.assertEquals(candidate({-1, 0, 2, 5, 3, -10}, 2), {3, 5})\n    lu.assertEquals(candidate({1, 0, 5, -7}, 1), {5})\n    lu.assertEquals(candidate({4, -4}, 2), {-4, 4})\n    lu.assertEquals(candidate({-10, 10}, 2), {-10, 10})\n    lu.assertEquals(candidate({1, 2, 3, -23, 243, -400, 0}, 0), {})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_24_largest_divisor", "language": "lua", "prompt": "-- For a given number n, find the largest number that divides n evenly, smaller than n\n-- >>> largest_divisor(15)\n-- 5\nlocal function largest_divisor(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_24_largest_divisor.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = largest_divisor\n    lu.assertEquals(candidate(3), 1)\n    lu.assertEquals(candidate(7), 1)\n    lu.assertEquals(candidate(10), 5)\n    lu.assertEquals(candidate(100), 50)\n    lu.assertEquals(candidate(49), 7)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_24_largest_divisor", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = largest_divisor\n    lu.assertEquals(candidate(3), 1)\n    lu.assertEquals(candidate(7), 1)\n    lu.assertEquals(candidate(10), 5)\n    lu.assertEquals(candidate(100), 50)\n    lu.assertEquals(candidate(49), 7)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_88_sort_array", "language": "lua", "prompt": "-- Given a table of non-negative integers, return a colua of the given table after sorting,\n-- you will sort the given table in ascending order if the sum( first index value, last index value) is odd,\n-- or sort it in descending order if the sum( first index value, last index value) is even.\n-- Note:\n-- * don't change the given table.\n-- Examples:\n-- >>> sort_array({})\n-- {}\n-- >>> sort_array({5})\n-- {5}\n-- >>> sort_array({2, 4, 3, 0, 1, 5})\n-- {0, 1, 2, 3, 4, 5}\n-- >>> sort_array({2, 4, 3, 0, 1, 5, 6})\n-- {6, 5, 4, 3, 2, 1, 0}\nlocal function sort_array(array)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_88_sort_array.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sort_array\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({5}), {5})\n    lu.assertEquals(candidate({2, 4, 3, 0, 1, 5}), {0, 1, 2, 3, 4, 5})\n    lu.assertEquals(candidate({2, 4, 3, 0, 1, 5, 6}), {6, 5, 4, 3, 2, 1, 0})\n    lu.assertEquals(candidate({2, 1}), {1, 2})\n    lu.assertEquals(candidate({15, 42, 87, 32, 11, 0}), {0, 11, 15, 32, 42, 87})\n    lu.assertEquals(candidate({21, 14, 23, 11}), {23, 21, 14, 11})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_88_sort_array", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sort_array\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({5}), {5})\n    lu.assertEquals(candidate({2, 4, 3, 0, 1, 5}), {0, 1, 2, 3, 4, 5})\n    lu.assertEquals(candidate({2, 4, 3, 0, 1, 5, 6}), {6, 5, 4, 3, 2, 1, 0})\n    lu.assertEquals(candidate({2, 1}), {1, 2})\n    lu.assertEquals(candidate({15, 42, 87, 32, 11, 0}), {0, 11, 15, 32, 42, 87})\n    lu.assertEquals(candidate({21, 14, 23, 11}), {23, 21, 14, 11})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_106_f", "language": "lua", "prompt": "-- Implement the function f that takes n as a parameter,\n-- and returns a table of size n, such that the value of the element at index i is the factorial of i if i is even\n-- or the sum of numbers from 1 to i otherwise.\n-- i starts from 1.\n-- the factorial of i is the multiplication of the numbers from 1 to i (1 * 2 * ... * i).\n-- Example:\n-- >>> f(5)\n-- {1, 2, 6, 24, 15}\nlocal function f(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_106_f.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = f\n    lu.assertEquals(candidate(5), {1, 2, 6, 24, 15})\n    lu.assertEquals(candidate(7), {1, 2, 6, 24, 15, 720, 28})\n    lu.assertEquals(candidate(1), {1})\n    lu.assertEquals(candidate(3), {1, 2, 6})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_106_f", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = f\n    lu.assertEquals(candidate(5), {1, 2, 6, 24, 15})\n    lu.assertEquals(candidate(7), {1, 2, 6, 24, 15, 720, 28})\n    lu.assertEquals(candidate(1), {1})\n    lu.assertEquals(candidate(3), {1, 2, 6})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_77_iscube", "language": "lua", "prompt": "-- Write a function that takes an integer a and returns true \n-- if this ingeger is a cube of some integer number.\n-- Note: you may assume the input is always valid.\n-- Examples:\n-- >>> iscube(1)\n-- true\n-- >>> iscube(2)\n-- false\n-- >>> iscube(-1)\n-- true\n-- >>> iscube(64)\n-- true\n-- >>> iscube(0)\n-- true\n-- >>> iscube(180)\n-- false\nlocal function iscube(a)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_77_iscube.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = iscube\n    lu.assertEquals(candidate(1), true)\n    lu.assertEquals(candidate(2), false)\n    lu.assertEquals(candidate(-1), true)\n    lu.assertEquals(candidate(64), true)\n    lu.assertEquals(candidate(180), false)\n    lu.assertEquals(candidate(1000), true)\n    lu.assertEquals(candidate(0), true)\n    lu.assertEquals(candidate(1729), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_77_iscube", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = iscube\n    lu.assertEquals(candidate(1), true)\n    lu.assertEquals(candidate(2), false)\n    lu.assertEquals(candidate(-1), true)\n    lu.assertEquals(candidate(64), true)\n    lu.assertEquals(candidate(180), false)\n    lu.assertEquals(candidate(1000), true)\n    lu.assertEquals(candidate(0), true)\n    lu.assertEquals(candidate(1729), false)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_93_encode", "language": "lua", "prompt": "-- Write a function that takes a message, and encodes in such a \n-- way that it swaps case of all letters, replaces all vowels in \n-- the message with the letter that appears 2 places ahead of that \n-- vowel in the english alphabet. \n-- Assume only letters. \n-- Examples:\n-- >>> encode('test')\n-- 'TGST'\n-- >>> encode('This is a message')\n-- 'tHKS KS C MGSSCGG'\nlocal function encode(message)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_93_encode.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = encode\n    lu.assertEquals(candidate('TEST'), 'tgst')\n    lu.assertEquals(candidate('Mudasir'), 'mWDCSKR')\n    lu.assertEquals(candidate('YES'), 'ygs')\n    lu.assertEquals(candidate('This is a message'), 'tHKS KS C MGSSCGG')\n    lu.assertEquals(candidate('I DoNt KnOw WhAt tO WrItE'), 'k dQnT kNqW wHcT Tq wRkTg')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_93_encode", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = encode\n    lu.assertEquals(candidate('TEST'), 'tgst')\n    lu.assertEquals(candidate('Mudasir'), 'mWDCSKR')\n    lu.assertEquals(candidate('YES'), 'ygs')\n    lu.assertEquals(candidate('This is a message'), 'tHKS KS C MGSSCGG')\n    lu.assertEquals(candidate('I DoNt KnOw WhAt tO WrItE'), 'k dQnT kNqW wHcT Tq wRkTg')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_91_is_bored", "language": "lua", "prompt": "-- You'll be given a string of words, and your task is to count the number\n-- of boredoms. A boredom is a sentence that starts with the word \"I\".\n-- Sentences are delimited by '.', '?' or '!'.\n-- For example:\n-- >>> is_bored('Hello world')\n-- 0\n-- >>> is_bored('The sky is blue. The sun is shining. I love this weather')\n-- 1\nlocal function is_bored(S)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_91_is_bored.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_bored\n    lu.assertEquals(candidate('Hello world'), 0)\n    lu.assertEquals(candidate('Is the sky blue?'), 0)\n    lu.assertEquals(candidate('I love It !'), 1)\n    lu.assertEquals(candidate('bIt'), 0)\n    lu.assertEquals(candidate('I feel good today. I will be productive. will kill It'), 2)\n    lu.assertEquals(candidate('You and I are going for a walk'), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_91_is_bored", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_bored\n    lu.assertEquals(candidate('Hello world'), 0)\n    lu.assertEquals(candidate('Is the sky blue?'), 0)\n    lu.assertEquals(candidate('I love It !'), 1)\n    lu.assertEquals(candidate('bIt'), 0)\n    lu.assertEquals(candidate('I feel good today. I will be productive. will kill It'), 2)\n    lu.assertEquals(candidate('You and I are going for a walk'), 0)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_43_pairs_sum_to_zero", "language": "lua", "prompt": "-- pairs_sum_to_zero takes a table of integers as an input.\n-- it returns true if there are two distinct elements in the table that\n-- sum to zero, and false otherwise.\n-- >>> pairs_sum_to_zero({1, 3, 5, 0})\n-- false\n-- >>> pairs_sum_to_zero({1, 3, -2, 1})\n-- false\n-- >>> pairs_sum_to_zero({1, 2, 3, 7})\n-- false\n-- >>> pairs_sum_to_zero({2, 4, -5, 3, 5, 7})\n-- true\n-- >>> pairs_sum_to_zero({1})\n-- false\nlocal function pairs_sum_to_zero(l)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_43_pairs_sum_to_zero.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = pairs_sum_to_zero\n    lu.assertEquals(candidate({1, 3, 5, 0}), false)\n    lu.assertEquals(candidate({1, 3, -2, 1}), false)\n    lu.assertEquals(candidate({1, 2, 3, 7}), false)\n    lu.assertEquals(candidate({2, 4, -5, 3, 5, 7}), true)\n    lu.assertEquals(candidate({1}), false)\n    lu.assertEquals(candidate({-3, 9, -1, 3, 2, 30}), true)\n    lu.assertEquals(candidate({-3, 9, -1, 3, 2, 31}), true)\n    lu.assertEquals(candidate({-3, 9, -1, 4, 2, 30}), false)\n    lu.assertEquals(candidate({-3, 9, -1, 4, 2, 31}), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_43_pairs_sum_to_zero", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = pairs_sum_to_zero\n    lu.assertEquals(candidate({1, 3, 5, 0}), false)\n    lu.assertEquals(candidate({1, 3, -2, 1}), false)\n    lu.assertEquals(candidate({1, 2, 3, 7}), false)\n    lu.assertEquals(candidate({2, 4, -5, 3, 5, 7}), true)\n    lu.assertEquals(candidate({1}), false)\n    lu.assertEquals(candidate({-3, 9, -1, 3, 2, 30}), true)\n    lu.assertEquals(candidate({-3, 9, -1, 3, 2, 31}), true)\n    lu.assertEquals(candidate({-3, 9, -1, 4, 2, 30}), false)\n    lu.assertEquals(candidate({-3, 9, -1, 4, 2, 31}), false)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_71_triangle_area", "language": "lua", "prompt": "-- Given the lengths of the three sides of a triangle. Return the area of\n-- the triangle rounded to 2 decimal points if the three sides form a valid triangle. \n-- Otherwise return -1\n-- Three sides make a valid triangle when the sum of any two sides is greater \n-- than the third side.\n-- Example:\n-- >>> triangle_area(3, 4, 5)\n-- 6.0\n-- >>> triangle_area(1, 2, 10)\n-- -1\nlocal function triangle_area(a, b, c)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_71_triangle_area.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = triangle_area\n    lu.assertEquals(candidate(3, 4, 5), 6.0)\n    lu.assertEquals(candidate(1, 2, 10), -1)\n    lu.assertEquals(candidate(4, 8, 5), 8.18)\n    lu.assertEquals(candidate(2, 2, 2), 1.73)\n    lu.assertEquals(candidate(1, 2, 3), -1)\n    lu.assertEquals(candidate(10, 5, 7), 16.25)\n    lu.assertEquals(candidate(2, 6, 3), -1)\n    lu.assertEquals(candidate(1, 1, 1), 0.43)\n    lu.assertEquals(candidate(2, 2, 10), -1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_71_triangle_area", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = triangle_area\n    lu.assertEquals(candidate(3, 4, 5), 6.0)\n    lu.assertEquals(candidate(1, 2, 10), -1)\n    lu.assertEquals(candidate(4, 8, 5), 8.18)\n    lu.assertEquals(candidate(2, 2, 2), 1.73)\n    lu.assertEquals(candidate(1, 2, 3), -1)\n    lu.assertEquals(candidate(10, 5, 7), 16.25)\n    lu.assertEquals(candidate(2, 6, 3), -1)\n    lu.assertEquals(candidate(1, 1, 1), 0.43)\n    lu.assertEquals(candidate(2, 2, 10), -1)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_148_bf", "language": "lua", "prompt": "-- There are eight planets in our solar system: the closerst to the Sun \n-- is Mercury, the next one is Venus, then Earth, Mars, Jupiter, Saturn, \n-- Uranus, Neptune.\n-- Write a function that takes two planet names as strings planet1 and planet2. \n-- The function should return a table containing all planets whose orbits are \n-- located between the orbit of planet1 and the orbit of planet2, sorted by \n-- the proximity to the sun. \n-- The function should return an empty table if planet1 or planet2\n-- are not correct planet names. \n-- Examples\n-- >>> bf('Jupiter', 'Neptune')\n-- {'Saturn', 'Uranus'}\n-- >>> bf('Earth', 'Mercury')\n-- 'Venus'\n-- >>> bf('Mercury', 'Uranus')\n-- {'Venus', 'Earth', 'Mars', 'Jupiter', 'Saturn'}\nlocal function bf(planet1, planet2)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_148_bf.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = bf\n    lu.assertEquals(candidate('Jupiter', 'Neptune'), {'Saturn', 'Uranus'})\n    lu.assertEquals(candidate('Earth', 'Mercury'), {'Venus'})\n    lu.assertEquals(candidate('Mercury', 'Uranus'), {'Venus', 'Earth', 'Mars', 'Jupiter', 'Saturn'})\n    lu.assertEquals(candidate('Neptune', 'Venus'), {'Earth', 'Mars', 'Jupiter', 'Saturn', 'Uranus'})\n    lu.assertEquals(candidate('Earth', 'Earth'), {})\n    lu.assertEquals(candidate('Mars', 'Earth'), {})\n    lu.assertEquals(candidate('Jupiter', 'Makemake'), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_148_bf", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = bf\n    lu.assertEquals(candidate('Jupiter', 'Neptune'), {'Saturn', 'Uranus'})\n    lu.assertEquals(candidate('Earth', 'Mercury'), {'Venus'})\n    lu.assertEquals(candidate('Mercury', 'Uranus'), {'Venus', 'Earth', 'Mars', 'Jupiter', 'Saturn'})\n    lu.assertEquals(candidate('Neptune', 'Venus'), {'Earth', 'Mars', 'Jupiter', 'Saturn', 'Uranus'})\n    lu.assertEquals(candidate('Earth', 'Earth'), {})\n    lu.assertEquals(candidate('Mars', 'Earth'), {})\n    lu.assertEquals(candidate('Jupiter', 'Makemake'), {})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_131_digits", "language": "lua", "prompt": "-- Given a positive integer n, return the product of the odd digits.\n-- Return 0 if all digits are even.\n-- For example:\n-- >>> digits(1)\n-- 1\n-- >>> digits(4)\n-- 0\n-- >>> digits(235)\n-- 15\nlocal function digits(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_131_digits.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = digits\n    lu.assertEquals(candidate(5), 5)\n    lu.assertEquals(candidate(54), 5)\n    lu.assertEquals(candidate(120), 1)\n    lu.assertEquals(candidate(5014), 5)\n    lu.assertEquals(candidate(98765), 315)\n    lu.assertEquals(candidate(5576543), 2625)\n    lu.assertEquals(candidate(2468), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_131_digits", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = digits\n    lu.assertEquals(candidate(5), 5)\n    lu.assertEquals(candidate(54), 5)\n    lu.assertEquals(candidate(120), 1)\n    lu.assertEquals(candidate(5014), 5)\n    lu.assertEquals(candidate(98765), 315)\n    lu.assertEquals(candidate(5576543), 2625)\n    lu.assertEquals(candidate(2468), 0)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_101_words_string", "language": "lua", "prompt": "-- You will be given a string of words separated by commas or spaces. Your task is\n-- to split the string into words and return a table of the words.\n-- For example:\n-- >>> words_string('Hi, my name is John')\n-- {'Hi', 'my', 'name', 'is', 'John'}\n-- >>> words_string('One, two, three, four, five, six')\n-- {'One', 'two', 'three', 'four', 'five', 'six'}\nlocal function words_string(s)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_101_words_string.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = words_string\n    lu.assertEquals(candidate('Hi, my name is John'), {'Hi', 'my', 'name', 'is', 'John'})\n    lu.assertEquals(candidate('One, two, three, four, five, six'), {'One', 'two', 'three', 'four', 'five', 'six'})\n    lu.assertEquals(candidate('Hi, my name'), {'Hi', 'my', 'name'})\n    lu.assertEquals(candidate('One,, two, three, four, five, six,'), {'One', 'two', 'three', 'four', 'five', 'six'})\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate('ahmed     , gamal'), {'ahmed', 'gamal'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_101_words_string", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = words_string\n    lu.assertEquals(candidate('Hi, my name is John'), {'Hi', 'my', 'name', 'is', 'John'})\n    lu.assertEquals(candidate('One, two, three, four, five, six'), {'One', 'two', 'three', 'four', 'five', 'six'})\n    lu.assertEquals(candidate('Hi, my name'), {'Hi', 'my', 'name'})\n    lu.assertEquals(candidate('One,, two, three, four, five, six,'), {'One', 'two', 'three', 'four', 'five', 'six'})\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate('ahmed     , gamal'), {'ahmed', 'gamal'})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_18_how_many_times", "language": "lua", "prompt": "-- Find how many times a given substring can be found in the original string. Count overlaping cases.\n-- >>> how_many_times('', 'a')\n-- 0\n-- >>> how_many_times('aaa', 'a')\n-- 3\n-- >>> how_many_times('aaaa', 'aa')\n-- 3\nlocal function how_many_times(string, substring)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_18_how_many_times.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = how_many_times\n    lu.assertEquals(candidate('', 'x'), 0)\n    lu.assertEquals(candidate('xyxyxyx', 'x'), 4)\n    lu.assertEquals(candidate('cacacacac', 'cac'), 4)\n    lu.assertEquals(candidate('john doe', 'john'), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_18_how_many_times", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = how_many_times\n    lu.assertEquals(candidate('', 'x'), 0)\n    lu.assertEquals(candidate('xyxyxyx', 'x'), 4)\n    lu.assertEquals(candidate('cacacacac', 'cac'), 4)\n    lu.assertEquals(candidate('john doe', 'john'), 1)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_137_compare_one", "language": "lua", "prompt": "-- Create a function that takes integers, floats, or strings representing\n-- real numbers, and returns the larger variable in its given variable type.\n-- Return None if the values are equal.\n-- Note: If a real number is represented as a string, the floating point might be . or ,\n-- >>> compare_one(1, 2.5)\n-- 2.5\n-- >>> compare_one(1, '2,3')\n-- '2,3'\n-- >>> compare_one('5,1', '6')\n-- '6'\n-- >>> compare_one('1', 1)\n-- None\nlocal function compare_one(a, b)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_137_compare_one.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = compare_one\n    lu.assertEquals(candidate(1, 2), 2)\n    lu.assertEquals(candidate(1, 2.5), 2.5)\n    lu.assertEquals(candidate(2, 3), 3)\n    lu.assertEquals(candidate(5, 6), 6)\n    lu.assertEquals(candidate(1, '2,3'), '2,3')\n    lu.assertEquals(candidate('5,1', '6'), '6')\n    lu.assertEquals(candidate('1', '2'), '2')\n    lu.assertEquals(candidate('1', 1), None)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_137_compare_one", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = compare_one\n    lu.assertEquals(candidate(1, 2), 2)\n    lu.assertEquals(candidate(1, 2.5), 2.5)\n    lu.assertEquals(candidate(2, 3), 3)\n    lu.assertEquals(candidate(5, 6), 6)\n    lu.assertEquals(candidate(1, '2,3'), '2,3')\n    lu.assertEquals(candidate('5,1', '6'), '6')\n    lu.assertEquals(candidate('1', '2'), '2')\n    lu.assertEquals(candidate('1', 1), None)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_51_remove_vowels", "language": "lua", "prompt": "-- remove_vowels is a function that takes string and returns string without vowels.\n-- >>> remove_vowels('')\n-- ''\n-- >>> remove_vowels('abcdef')\n-- 'bcdf'\n-- >>> remove_vowels('aaaaa')\n-- ''\n-- >>> remove_vowels('aaBAA')\n-- 'B'\n-- >>> remove_vowels('zbcd')\n-- 'zbcd'\nlocal function remove_vowels(text)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_51_remove_vowels.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = remove_vowels\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('abcdef\\nghijklm'), 'bcdf\\nghjklm')\n    lu.assertEquals(candidate('fedcba'), 'fdcb')\n    lu.assertEquals(candidate('eeeee'), '')\n    lu.assertEquals(candidate('acBAA'), 'cB')\n    lu.assertEquals(candidate('EcBOO'), 'cB')\n    lu.assertEquals(candidate('ybcd'), 'ybcd')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_51_remove_vowels", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = remove_vowels\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('abcdef\\nghijklm'), 'bcdf\\nghjklm')\n    lu.assertEquals(candidate('fedcba'), 'fdcb')\n    lu.assertEquals(candidate('eeeee'), '')\n    lu.assertEquals(candidate('acBAA'), 'cB')\n    lu.assertEquals(candidate('EcBOO'), 'cB')\n    lu.assertEquals(candidate('ybcd'), 'ybcd')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_70_strange_sort_list", "language": "lua", "prompt": "-- Given table of integers, return table in strange order.\n-- Strange sorting, is when you start with the minimum value,\n-- then maximum of the remaining integers, then minimum and so on.\n-- Examples:\n-- >>> strange_sort_list({1, 2, 3, 4})\n-- {1, 4, 2, 3}\n-- >>> strange_sort_list({5, 5, 5, 5})\n-- {5, 5, 5, 5}\n-- >>> strange_sort_list({})\n-- {}\nlocal function strange_sort_list(lst)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_70_strange_sort_list.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = strange_sort_list\n    lu.assertEquals(candidate({1, 2, 3, 4}), {1, 4, 2, 3})\n    lu.assertEquals(candidate({5, 6, 7, 8, 9}), {5, 9, 6, 8, 7})\n    lu.assertEquals(candidate({1, 2, 3, 4, 5}), {1, 5, 2, 4, 3})\n    lu.assertEquals(candidate({5, 6, 7, 8, 9, 1}), {1, 9, 5, 8, 6, 7})\n    lu.assertEquals(candidate({5, 5, 5, 5}), {5, 5, 5, 5})\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6, 7, 8}), {1, 8, 2, 7, 3, 6, 4, 5})\n    lu.assertEquals(candidate({0, 2, 2, 2, 5, 5, -5, -5}), {-5, 5, -5, 5, 0, 2, 2, 2})\n    lu.assertEquals(candidate({111111}), {111111})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_70_strange_sort_list", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = strange_sort_list\n    lu.assertEquals(candidate({1, 2, 3, 4}), {1, 4, 2, 3})\n    lu.assertEquals(candidate({5, 6, 7, 8, 9}), {5, 9, 6, 8, 7})\n    lu.assertEquals(candidate({1, 2, 3, 4, 5}), {1, 5, 2, 4, 3})\n    lu.assertEquals(candidate({5, 6, 7, 8, 9, 1}), {1, 9, 5, 8, 6, 7})\n    lu.assertEquals(candidate({5, 5, 5, 5}), {5, 5, 5, 5})\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6, 7, 8}), {1, 8, 2, 7, 3, 6, 4, 5})\n    lu.assertEquals(candidate({0, 2, 2, 2, 5, 5, -5, -5}), {-5, 5, -5, 5, 0, 2, 2, 2})\n    lu.assertEquals(candidate({111111}), {111111})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_20_find_closest_elements", "language": "lua", "prompt": "-- From a supplied table of numbers (of length at least two) select and return two that are the closest to each\n-- other and return them in order (smaller number, larger number).\n-- >>> find_closest_elements({1.0, 2.0, 3.0, 4.0, 5.0, 2.2})\n-- {2.0, 2.2}\n-- >>> find_closest_elements({1.0, 2.0, 3.0, 4.0, 5.0, 2.0})\n-- {2.0, 2.0}\nlocal function find_closest_elements(numbers)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_20_find_closest_elements.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = find_closest_elements\n    lu.assertEquals(candidate({1.0, 2.0, 3.9, 4.0, 5.0, 2.2}), {3.9, 4.0})\n    lu.assertEquals(candidate({1.0, 2.0, 5.9, 4.0, 5.0}), {5.0, 5.9})\n    lu.assertEquals(candidate({1.0, 2.0, 3.0, 4.0, 5.0, 2.2}), {2.0, 2.2})\n    lu.assertEquals(candidate({1.0, 2.0, 3.0, 4.0, 5.0, 2.0}), {2.0, 2.0})\n    lu.assertEquals(candidate({1.1, 2.2, 3.1, 4.1, 5.1}), {2.2, 3.1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_20_find_closest_elements", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = find_closest_elements\n    lu.assertEquals(candidate({1.0, 2.0, 3.9, 4.0, 5.0, 2.2}), {3.9, 4.0})\n    lu.assertEquals(candidate({1.0, 2.0, 5.9, 4.0, 5.0}), {5.0, 5.9})\n    lu.assertEquals(candidate({1.0, 2.0, 3.0, 4.0, 5.0, 2.2}), {2.0, 2.2})\n    lu.assertEquals(candidate({1.0, 2.0, 3.0, 4.0, 5.0, 2.0}), {2.0, 2.0})\n    lu.assertEquals(candidate({1.1, 2.2, 3.1, 4.1, 5.1}), {2.2, 3.1})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_76_is_simple_power", "language": "lua", "prompt": "-- Your task is to write a function that returns true if a number x is a simple\n-- power of n and false in other cases.\n-- x is a simple power of n if n**int=x\n-- For example:\n-- >>> is_simple_power(1, 4)\n-- true\n-- >>> is_simple_power(2, 2)\n-- true\n-- >>> is_simple_power(8, 2)\n-- true\n-- >>> is_simple_power(3, 2)\n-- false\n-- >>> is_simple_power(3, 1)\n-- false\n-- >>> is_simple_power(5, 3)\n-- false\nlocal function is_simple_power(x, n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_76_is_simple_power.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_simple_power\n    lu.assertEquals(candidate(16, 2), true)\n    lu.assertEquals(candidate(143214, 16), false)\n    lu.assertEquals(candidate(4, 2), true)\n    lu.assertEquals(candidate(9, 3), true)\n    lu.assertEquals(candidate(16, 4), true)\n    lu.assertEquals(candidate(24, 2), false)\n    lu.assertEquals(candidate(128, 4), false)\n    lu.assertEquals(candidate(12, 6), false)\n    lu.assertEquals(candidate(1, 1), true)\n    lu.assertEquals(candidate(1, 12), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_76_is_simple_power", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_simple_power\n    lu.assertEquals(candidate(16, 2), true)\n    lu.assertEquals(candidate(143214, 16), false)\n    lu.assertEquals(candidate(4, 2), true)\n    lu.assertEquals(candidate(9, 3), true)\n    lu.assertEquals(candidate(16, 4), true)\n    lu.assertEquals(candidate(24, 2), false)\n    lu.assertEquals(candidate(128, 4), false)\n    lu.assertEquals(candidate(12, 6), false)\n    lu.assertEquals(candidate(1, 1), true)\n    lu.assertEquals(candidate(1, 12), true)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_39_prime_fib", "language": "lua", "prompt": "-- prime_fib returns n-th number that is a Fibonacci number and it's also prime.\n-- >>> prime_fib(1)\n-- 2\n-- >>> prime_fib(2)\n-- 3\n-- >>> prime_fib(3)\n-- 5\n-- >>> prime_fib(4)\n-- 13\n-- >>> prime_fib(5)\n-- 89\nlocal function prime_fib(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_39_prime_fib.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = prime_fib\n    lu.assertEquals(candidate(1), 2)\n    lu.assertEquals(candidate(2), 3)\n    lu.assertEquals(candidate(3), 5)\n    lu.assertEquals(candidate(4), 13)\n    lu.assertEquals(candidate(5), 89)\n    lu.assertEquals(candidate(6), 233)\n    lu.assertEquals(candidate(7), 1597)\n    lu.assertEquals(candidate(8), 28657)\n    lu.assertEquals(candidate(9), 514229)\n    lu.assertEquals(candidate(10), 433494437)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_39_prime_fib", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = prime_fib\n    lu.assertEquals(candidate(1), 2)\n    lu.assertEquals(candidate(2), 3)\n    lu.assertEquals(candidate(3), 5)\n    lu.assertEquals(candidate(4), 13)\n    lu.assertEquals(candidate(5), 89)\n    lu.assertEquals(candidate(6), 233)\n    lu.assertEquals(candidate(7), 1597)\n    lu.assertEquals(candidate(8), 28657)\n    lu.assertEquals(candidate(9), 514229)\n    lu.assertEquals(candidate(10), 433494437)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_145_order_by_points", "language": "lua", "prompt": "-- Write a function which sorts the given table of integers\n-- in ascending order according to the sum of their digits.\n-- Note: if there are several items with similar sum of their digits,\n-- order them based on their index in original table.\n-- For example:\n-- >>> order_by_points({1, 11, -1, -11, -12})\n-- {-1, -11, 1, -12, 11}\n-- >>> order_by_points({})\n-- {}\nlocal function order_by_points(nums)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_145_order_by_points.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = order_by_points\n    lu.assertEquals(candidate({1, 11, -1, -11, -12}), {-1, -11, 1, -12, 11})\n    lu.assertEquals(candidate({1234, 423, 463, 145, 2, 423, 423, 53, 6, 37, 3457, 3, 56, 0, 46}), {0, 2, 3, 6, 53, 423, 423, 423, 1234, 145, 37, 46, 56, 463, 3457})\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({1, -11, -32, 43, 54, -98, 2, -3}), {-3, -32, -98, -11, 1, 2, 43, 54})\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}), {1, 10, 2, 11, 3, 4, 5, 6, 7, 8, 9})\n    lu.assertEquals(candidate({0, 6, 6, -76, -21, 23, 4}), {-76, -21, 0, 4, 23, 6, 6})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_145_order_by_points", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = order_by_points\n    lu.assertEquals(candidate({1, 11, -1, -11, -12}), {-1, -11, 1, -12, 11})\n    lu.assertEquals(candidate({1234, 423, 463, 145, 2, 423, 423, 53, 6, 37, 3457, 3, 56, 0, 46}), {0, 2, 3, 6, 53, 423, 423, 423, 1234, 145, 37, 46, 56, 463, 3457})\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({1, -11, -32, 43, 54, -98, 2, -3}), {-3, -32, -98, -11, 1, 2, 43, 54})\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}), {1, 10, 2, 11, 3, 4, 5, 6, 7, 8, 9})\n    lu.assertEquals(candidate({0, 6, 6, -76, -21, 23, 4}), {-76, -21, 0, 4, 23, 6, 6})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_0_has_close_elements", "language": "lua", "prompt": "-- Check if in given table of numbers, are any two numbers closer to each other than\n-- given threshold.\n-- >>> has_close_elements({1.0, 2.0, 3.0}, 0.5)\n-- false\n-- >>> has_close_elements({1.0, 2.8, 3.0, 4.0, 5.0, 2.0}, 0.3)\n-- true\nlocal function has_close_elements(numbers, threshold)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_0_has_close_elements.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = has_close_elements\n    lu.assertEquals(candidate({1.0, 2.0, 3.9, 4.0, 5.0, 2.2}, 0.3), true)\n    lu.assertEquals(candidate({1.0, 2.0, 3.9, 4.0, 5.0, 2.2}, 0.05), false)\n    lu.assertEquals(candidate({1.0, 2.0, 5.9, 4.0, 5.0}, 0.95), true)\n    lu.assertEquals(candidate({1.0, 2.0, 5.9, 4.0, 5.0}, 0.8), false)\n    lu.assertEquals(candidate({1.0, 2.0, 3.0, 4.0, 5.0, 2.0}, 0.1), true)\n    lu.assertEquals(candidate({1.1, 2.2, 3.1, 4.1, 5.1}, 1.0), true)\n    lu.assertEquals(candidate({1.1, 2.2, 3.1, 4.1, 5.1}, 0.5), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_0_has_close_elements", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = has_close_elements\n    lu.assertEquals(candidate({1.0, 2.0, 3.9, 4.0, 5.0, 2.2}, 0.3), true)\n    lu.assertEquals(candidate({1.0, 2.0, 3.9, 4.0, 5.0, 2.2}, 0.05), false)\n    lu.assertEquals(candidate({1.0, 2.0, 5.9, 4.0, 5.0}, 0.95), true)\n    lu.assertEquals(candidate({1.0, 2.0, 5.9, 4.0, 5.0}, 0.8), false)\n    lu.assertEquals(candidate({1.0, 2.0, 3.0, 4.0, 5.0, 2.0}, 0.1), true)\n    lu.assertEquals(candidate({1.1, 2.2, 3.1, 4.1, 5.1}, 1.0), true)\n    lu.assertEquals(candidate({1.1, 2.2, 3.1, 4.1, 5.1}, 0.5), false)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_10_make_palindrome", "language": "lua", "prompt": "-- Find the shortest palindrome that begins with a supplied string.\n-- Algorithm idea is simple:\n-- - Find the longest postfix of supplied string that is a palindrome.\n-- - Append to the end of the string reverse of a string prefix that comes before the palindromic suffix.\n-- >>> make_palindrome('')\n-- ''\n-- >>> make_palindrome('cat')\n-- 'catac'\n-- >>> make_palindrome('cata')\n-- 'catac'\nlocal function make_palindrome(string)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_10_make_palindrome.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = make_palindrome\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('x'), 'x')\n    lu.assertEquals(candidate('xyz'), 'xyzyx')\n    lu.assertEquals(candidate('xyx'), 'xyx')\n    lu.assertEquals(candidate('jerry'), 'jerryrrej')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_10_make_palindrome", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = make_palindrome\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('x'), 'x')\n    lu.assertEquals(candidate('xyz'), 'xyzyx')\n    lu.assertEquals(candidate('xyx'), 'xyx')\n    lu.assertEquals(candidate('jerry'), 'jerryrrej')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_11_string_xor", "language": "lua", "prompt": "-- Input are two strings a and b consisting only of 1s and 0s.\n-- Perform binary XOR on these inputs and return result also as a string.\n-- >>> string_xor('010', '110')\n-- '100'\nlocal function string_xor(a, b)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_11_string_xor.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = string_xor\n    lu.assertEquals(candidate('111000', '101010'), '010010')\n    lu.assertEquals(candidate('1', '1'), '0')\n    lu.assertEquals(candidate('0101', '0000'), '0101')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_11_string_xor", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = string_xor\n    lu.assertEquals(candidate('111000', '101010'), '010010')\n    lu.assertEquals(candidate('1', '1'), '0')\n    lu.assertEquals(candidate('0101', '0000'), '0101')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_139_special_factorial", "language": "lua", "prompt": "-- The Brazilian factorial is defined as:\n-- brazilian_factorial(n) = n! * (n-1)! * (n-2)! * ... * 1!\n-- where n > 0\n-- For example:\n-- >>> special_factorial(4)\n-- 288\n-- The function will receive an integer as input and should return the special\n-- factorial of this integer.\nlocal function special_factorial(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_139_special_factorial.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = special_factorial\n    lu.assertEquals(candidate(4), 288)\n    lu.assertEquals(candidate(5), 34560)\n    lu.assertEquals(candidate(7), 125411328000)\n    lu.assertEquals(candidate(1), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_139_special_factorial", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = special_factorial\n    lu.assertEquals(candidate(4), 288)\n    lu.assertEquals(candidate(5), 34560)\n    lu.assertEquals(candidate(7), 125411328000)\n    lu.assertEquals(candidate(1), 1)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_122_add_elements", "language": "lua", "prompt": "-- Given a non-empty table of integers arr and an integer k, return\n-- the sum of the elements with at most two digits from the first k elements of arr.\n-- Example:\n-- >>> add_elements({111, 21, 3, 4000, 5, 6, 7, 8, 9}, 4)\n-- 24\n-- Constraints:\n-- 1. 1 <= len(arr) <= 100\n-- 2. 1 <= k <= len(arr)\nlocal function add_elements(arr, k)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_122_add_elements.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = add_elements\n    lu.assertEquals(candidate({1, -2, -3, 41, 57, 76, 87, 88, 99}, 3), -4)\n    lu.assertEquals(candidate({111, 121, 3, 4000, 5, 6}, 2), 0)\n    lu.assertEquals(candidate({11, 21, 3, 90, 5, 6, 7, 8, 9}, 4), 125)\n    lu.assertEquals(candidate({111, 21, 3, 4000, 5, 6, 7, 8, 9}, 4), 24)\n    lu.assertEquals(candidate({1}, 1), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_122_add_elements", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = add_elements\n    lu.assertEquals(candidate({1, -2, -3, 41, 57, 76, 87, 88, 99}, 3), -4)\n    lu.assertEquals(candidate({111, 121, 3, 4000, 5, 6}, 2), 0)\n    lu.assertEquals(candidate({11, 21, 3, 90, 5, 6, 7, 8, 9}, 4), 125)\n    lu.assertEquals(candidate({111, 21, 3, 4000, 5, 6, 7, 8, 9}, 4), 24)\n    lu.assertEquals(candidate({1}, 1), 1)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_46_fib4", "language": "lua", "prompt": "-- The Fib4 number sequence is a sequence similar to the Fibbonacci sequnece that's defined as follows:\n-- fib4(0) -> 0\n-- fib4(1) -> 0\n-- fib4(2) -> 2\n-- fib4(3) -> 0\n-- fib4(n) -> fib4(n-1) + fib4(n-2) + fib4(n-3) + fib4(n-4).\n-- Please write a function to efficiently compute the n-th element of the fib4 number sequence.  Do not use recursion.\n-- >>> fib4(5)\n-- 4\n-- >>> fib4(6)\n-- 8\n-- >>> fib4(7)\n-- 14\nlocal function fib4(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_46_fib4.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fib4\n    lu.assertEquals(candidate(5), 4)\n    lu.assertEquals(candidate(8), 28)\n    lu.assertEquals(candidate(10), 104)\n    lu.assertEquals(candidate(12), 386)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_46_fib4", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fib4\n    lu.assertEquals(candidate(5), 4)\n    lu.assertEquals(candidate(8), 28)\n    lu.assertEquals(candidate(10), 104)\n    lu.assertEquals(candidate(12), 386)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_104_unique_digits", "language": "lua", "prompt": "-- Given a table of positive integers x. return a sorted table of all \n-- elements that hasn't any even digit.\n-- Note: Returned table should be sorted in increasing order.\n-- For example:\n-- >>> unique_digits({15, 33, 1422, 1})\n-- {1, 15, 33}\n-- >>> unique_digits({152, 323, 1422, 10})\n-- {}\nlocal function unique_digits(x)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_104_unique_digits.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = unique_digits\n    lu.assertEquals(candidate({15, 33, 1422, 1}), {1, 15, 33})\n    lu.assertEquals(candidate({152, 323, 1422, 10}), {})\n    lu.assertEquals(candidate({12345, 2033, 111, 151}), {111, 151})\n    lu.assertEquals(candidate({135, 103, 31}), {31, 135})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_104_unique_digits", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = unique_digits\n    lu.assertEquals(candidate({15, 33, 1422, 1}), {1, 15, 33})\n    lu.assertEquals(candidate({152, 323, 1422, 10}), {})\n    lu.assertEquals(candidate({12345, 2033, 111, 151}), {111, 151})\n    lu.assertEquals(candidate({135, 103, 31}), {31, 135})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_117_select_words", "language": "lua", "prompt": "-- Given a string s and a natural number n, you have been tasked to implement \n-- a function that returns a table of all words from string s that contain exactly \n-- n consonants, in order these words appear in the string s.\n-- If the string s is empty then the function should return an empty table.\n-- Note: you may assume the input string contains only letters and spaces.\n-- Examples:\n-- >>> select_words('Mary had a little lamb', 4)\n-- {'little'}\n-- >>> select_words('Mary had a little lamb', 3)\n-- {'Mary', 'lamb'}\n-- >>> select_words('simple white space', 2)\n-- {}\n-- >>> select_words('Hello world', 4)\n-- {'world'}\n-- >>> select_words('Uncle sam', 3)\n-- {'Uncle'}\nlocal function select_words(s, n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_117_select_words.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = select_words\n    lu.assertEquals(candidate('Mary had a little lamb', 4), {'little'})\n    lu.assertEquals(candidate('Mary had a little lamb', 3), {'Mary', 'lamb'})\n    lu.assertEquals(candidate('simple white space', 2), {})\n    lu.assertEquals(candidate('Hello world', 4), {'world'})\n    lu.assertEquals(candidate('Uncle sam', 3), {'Uncle'})\n    lu.assertEquals(candidate('', 4), {})\n    lu.assertEquals(candidate('a b c d e f', 1), {'b', 'c', 'd', 'f'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_117_select_words", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = select_words\n    lu.assertEquals(candidate('Mary had a little lamb', 4), {'little'})\n    lu.assertEquals(candidate('Mary had a little lamb', 3), {'Mary', 'lamb'})\n    lu.assertEquals(candidate('simple white space', 2), {})\n    lu.assertEquals(candidate('Hello world', 4), {'world'})\n    lu.assertEquals(candidate('Uncle sam', 3), {'Uncle'})\n    lu.assertEquals(candidate('', 4), {})\n    lu.assertEquals(candidate('a b c d e f', 1), {'b', 'c', 'd', 'f'})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_72_will_it_fly", "language": "lua", "prompt": "-- Write a function that returns true if the object q will fly, and false otherwise.\n-- The object q will fly if it's balanced (it is a palindromic table) and the sum of its elements is less than or equal the maximum possible weight w.\n-- Example:\n-- >>> will_it_fly({1, 2}, 5)\n-- false\n-- # 1+2 is less than the maximum possible weight, but it's unbalanced.\n-- >>> will_it_fly({3, 2, 3}, 1)\n-- false\n-- # it's balanced, but 3+2+3 is more than the maximum possible weight.\n-- >>> will_it_fly({3, 2, 3}, 9)\n-- true\n-- # 3+2+3 is less than the maximum possible weight, and it's balanced.\n-- >>> will_it_fly({3}, 5)\n-- true\n-- # 3 is less than the maximum possible weight, and it's balanced.\nlocal function will_it_fly(q, w)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_72_will_it_fly.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = will_it_fly\n    lu.assertEquals(candidate({3, 2, 3}, 9), true)\n    lu.assertEquals(candidate({1, 2}, 5), false)\n    lu.assertEquals(candidate({3}, 5), true)\n    lu.assertEquals(candidate({3, 2, 3}, 1), false)\n    lu.assertEquals(candidate({1, 2, 3}, 6), false)\n    lu.assertEquals(candidate({5}, 5), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_72_will_it_fly", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = will_it_fly\n    lu.assertEquals(candidate({3, 2, 3}, 9), true)\n    lu.assertEquals(candidate({1, 2}, 5), false)\n    lu.assertEquals(candidate({3}, 5), true)\n    lu.assertEquals(candidate({3, 2, 3}, 1), false)\n    lu.assertEquals(candidate({1, 2, 3}, 6), false)\n    lu.assertEquals(candidate({5}, 5), true)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_55_fib", "language": "lua", "prompt": "-- Return n-th Fibonacci number.\n-- >>> fib(10)\n-- 55\n-- >>> fib(1)\n-- 1\n-- >>> fib(8)\n-- 21\nlocal function fib(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_55_fib.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fib\n    lu.assertEquals(candidate(10), 55)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(8), 21)\n    lu.assertEquals(candidate(11), 89)\n    lu.assertEquals(candidate(12), 144)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_55_fib", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fib\n    lu.assertEquals(candidate(10), 55)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(8), 21)\n    lu.assertEquals(candidate(11), 89)\n    lu.assertEquals(candidate(12), 144)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_153_Strongest_Extension", "language": "lua", "prompt": "-- You will be given the name of a class (a string) and a table of extensions.\n-- The extensions are to be used to load additional classes to the class. The\n-- strength of the extension is as follows: Let CAP be the number of the uppercase\n-- letters in the extension's name, and let SM be the number of lowercase letters \n-- in the extension's name, the strength is given by the fraction CAP - SM. \n-- You should find the strongest extension and return a string in this \n-- format: ClassName.StrongestExtensionName.\n-- If there are two or more extensions with the same strength, you should\n-- choose the one that comes first in the table.\n-- For example, if you are given \"Slices\" as the class and a table of the\n-- extensions: ['SErviNGSliCes', 'Cheese', 'StuFfed'] then you should\n-- return 'Slices.SErviNGSliCes' since 'SErviNGSliCes' is the strongest extension \n-- (its strength is -1).\n-- Example:\n-- >>> Strongest_Extension('my_class', {'AA', 'Be', 'CC'})\n-- 'my_class.AA'\nlocal function Strongest_Extension(class_name, extensions)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_153_Strongest_Extension.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = Strongest_Extension\n    lu.assertEquals(candidate('Watashi', {'tEN', 'niNE', 'eIGHt8OKe'}), 'Watashi.eIGHt8OKe')\n    lu.assertEquals(candidate('Boku123', {'nani', 'NazeDa', 'YEs.WeCaNe', '32145tggg'}), 'Boku123.YEs.WeCaNe')\n    lu.assertEquals(candidate('__YESIMHERE', {'t', 'eMptY', 'nothing', 'zeR00', 'NuLl__', '123NoooneB321'}), '__YESIMHERE.NuLl__')\n    lu.assertEquals(candidate('K', {'Ta', 'TAR', 't234An', 'cosSo'}), 'K.TAR')\n    lu.assertEquals(candidate('__HAHA', {'Tab', '123', '781345', '-_-'}), '__HAHA.123')\n    lu.assertEquals(candidate('YameRore', {'HhAas', 'okIWILL123', 'WorkOut', 'Fails', '-_-'}), 'YameRore.okIWILL123')\n    lu.assertEquals(candidate('finNNalLLly', {'Die', 'NowW', 'Wow', 'WoW'}), 'finNNalLLly.WoW')\n    lu.assertEquals(candidate('_', {'Bb', '91245'}), '_.Bb')\n    lu.assertEquals(candidate('Sp', {'671235', 'Bb'}), 'Sp.671235')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_153_Strongest_Extension", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = Strongest_Extension\n    lu.assertEquals(candidate('Watashi', {'tEN', 'niNE', 'eIGHt8OKe'}), 'Watashi.eIGHt8OKe')\n    lu.assertEquals(candidate('Boku123', {'nani', 'NazeDa', 'YEs.WeCaNe', '32145tggg'}), 'Boku123.YEs.WeCaNe')\n    lu.assertEquals(candidate('__YESIMHERE', {'t', 'eMptY', 'nothing', 'zeR00', 'NuLl__', '123NoooneB321'}), '__YESIMHERE.NuLl__')\n    lu.assertEquals(candidate('K', {'Ta', 'TAR', 't234An', 'cosSo'}), 'K.TAR')\n    lu.assertEquals(candidate('__HAHA', {'Tab', '123', '781345', '-_-'}), '__HAHA.123')\n    lu.assertEquals(candidate('YameRore', {'HhAas', 'okIWILL123', 'WorkOut', 'Fails', '-_-'}), 'YameRore.okIWILL123')\n    lu.assertEquals(candidate('finNNalLLly', {'Die', 'NowW', 'Wow', 'WoW'}), 'finNNalLLly.WoW')\n    lu.assertEquals(candidate('_', {'Bb', '91245'}), '_.Bb')\n    lu.assertEquals(candidate('Sp', {'671235', 'Bb'}), 'Sp.671235')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_119_match_parens", "language": "lua", "prompt": "-- You are given a table of two strings, both strings consist of open\n-- parentheses '(' or close parentheses ')' only.\n-- Your job is to check if it is possible to concatenate the two strings in\n-- some order, that the resulting string will be good.\n-- A string S is considered to be good if and only if all parentheses in S\n-- are balanced. For example: the string '(())()' is good, while the string\n-- '())' is not.\n-- Return 'Yes' if there's a way to make a good string, and return 'No' otherwise.\n-- Examples:\n-- >>> match_parens({'()(', ')'})\n-- 'Yes'\n-- >>> match_parens({')', ')'})\n-- 'No'\nlocal function match_parens(lst)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_119_match_parens.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = match_parens\n    lu.assertEquals(candidate({'()(', ')'}), 'Yes')\n    lu.assertEquals(candidate({')', ')'}), 'No')\n    lu.assertEquals(candidate({'(()(())', '())())'}), 'No')\n    lu.assertEquals(candidate({')())', '(()()('}), 'Yes')\n    lu.assertEquals(candidate({'(())))', '(()())(('}), 'Yes')\n    lu.assertEquals(candidate({'()', '())'}), 'No')\n    lu.assertEquals(candidate({'(()(', '()))()'}), 'Yes')\n    lu.assertEquals(candidate({'((((', '((())'}), 'No')\n    lu.assertEquals(candidate({')(()', '(()('}), 'No')\n    lu.assertEquals(candidate({')(', ')('}), 'No')\n    lu.assertEquals(candidate({'(', ')'}), 'Yes')\n    lu.assertEquals(candidate({')', '('}), 'Yes')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_119_match_parens", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = match_parens\n    lu.assertEquals(candidate({'()(', ')'}), 'Yes')\n    lu.assertEquals(candidate({')', ')'}), 'No')\n    lu.assertEquals(candidate({'(()(())', '())())'}), 'No')\n    lu.assertEquals(candidate({')())', '(()()('}), 'Yes')\n    lu.assertEquals(candidate({'(())))', '(()())(('}), 'Yes')\n    lu.assertEquals(candidate({'()', '())'}), 'No')\n    lu.assertEquals(candidate({'(()(', '()))()'}), 'Yes')\n    lu.assertEquals(candidate({'((((', '((())'}), 'No')\n    lu.assertEquals(candidate({')(()', '(()('}), 'No')\n    lu.assertEquals(candidate({')(', ')('}), 'No')\n    lu.assertEquals(candidate({'(', ')'}), 'Yes')\n    lu.assertEquals(candidate({')', '('}), 'Yes')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_90_next_smallest", "language": "lua", "prompt": "-- You are given a table of integers.\n-- Write a function next_smallest() that returns the 2nd smallest element of the table.\n-- Return None if there is no such element.\n-- >>> next_smallest({1, 2, 3, 4, 5})\n-- 2\n-- >>> next_smallest({5, 1, 4, 3, 2})\n-- 2\n-- >>> next_smallest({})\n-- None\n-- >>> next_smallest({1, 1})\n-- None\nlocal function next_smallest(lst)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_90_next_smallest.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = next_smallest\n    lu.assertEquals(candidate({1, 2, 3, 4, 5}), 2)\n    lu.assertEquals(candidate({5, 1, 4, 3, 2}), 2)\n    lu.assertEquals(candidate({}), None)\n    lu.assertEquals(candidate({1, 1}), None)\n    lu.assertEquals(candidate({1, 1, 1, 1, 0}), 1)\n    lu.assertEquals(candidate({1, 1}), None)\n    lu.assertEquals(candidate({-35, 34, 12, -45}), -35)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_90_next_smallest", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = next_smallest\n    lu.assertEquals(candidate({1, 2, 3, 4, 5}), 2)\n    lu.assertEquals(candidate({5, 1, 4, 3, 2}), 2)\n    lu.assertEquals(candidate({}), None)\n    lu.assertEquals(candidate({1, 1}), None)\n    lu.assertEquals(candidate({1, 1, 1, 1, 0}), 1)\n    lu.assertEquals(candidate({1, 1}), None)\n    lu.assertEquals(candidate({-35, 34, 12, -45}), -35)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_92_any_int", "language": "lua", "prompt": "-- Create a function that takes 3 numbers.\n-- Returns true if one of the numbers is equal to the sum of the other two, and all numbers are integers.\n-- Returns false in any other cases.\n-- Examples\n-- >>> any_int(5, 2, 7)\n-- true\n-- >>> any_int(3, 2, 2)\n-- false\n-- >>> any_int(3, -2, 1)\n-- true\n-- >>> any_int(3.6, -2.2, 2)\n-- false\nlocal function any_int(x, y, z)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_92_any_int.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = any_int\n    lu.assertEquals(candidate(2, 3, 1), true)\n    lu.assertEquals(candidate(2.5, 2, 3), false)\n    lu.assertEquals(candidate(1.5, 5, 3.5), false)\n    lu.assertEquals(candidate(2, 6, 2), false)\n    lu.assertEquals(candidate(4, 2, 2), true)\n    lu.assertEquals(candidate(2.2, 2.2, 2.2), false)\n    lu.assertEquals(candidate(-4, 6, 2), true)\n    lu.assertEquals(candidate(2, 1, 1), true)\n    lu.assertEquals(candidate(3, 4, 7), true)\n    lu.assertEquals(candidate(3.0, 4, 7), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_92_any_int", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = any_int\n    lu.assertEquals(candidate(2, 3, 1), true)\n    lu.assertEquals(candidate(2.5, 2, 3), false)\n    lu.assertEquals(candidate(1.5, 5, 3.5), false)\n    lu.assertEquals(candidate(2, 6, 2), false)\n    lu.assertEquals(candidate(4, 2, 2), true)\n    lu.assertEquals(candidate(2.2, 2.2, 2.2), false)\n    lu.assertEquals(candidate(-4, 6, 2), true)\n    lu.assertEquals(candidate(2, 1, 1), true)\n    lu.assertEquals(candidate(3, 4, 7), true)\n    lu.assertEquals(candidate(3.0, 4, 7), false)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_2_truncate_number", "language": "lua", "prompt": "-- Given a positive floating point number, it can be decomposed into\n-- and integer part (largest integer smaller than given number) and decimals\n-- (leftover part always smaller than 1).\n-- Return the decimal part of the number.\n-- >>> truncate_number(3.5)\n-- 0.5\nlocal function truncate_number(number)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_2_truncate_number.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = truncate_number\n    lu.assertEquals(candidate(3.5), 0.5)\n    lu.assertEquals(candidate(1.25), 0.25)\n    lu.assertEquals(candidate(123.0), 0.0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_2_truncate_number", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = truncate_number\n    lu.assertEquals(candidate(3.5), 0.5)\n    lu.assertEquals(candidate(1.25), 0.25)\n    lu.assertEquals(candidate(123.0), 0.0)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_42_incr_list", "language": "lua", "prompt": "-- Return table with elements incremented by 1.\n-- >>> incr_list({1, 2, 3})\n-- {2, 3, 4}\n-- >>> incr_list({5, 3, 5, 2, 3, 3, 9, 0, 123})\n-- {6, 4, 6, 3, 4, 4, 10, 1, 124}\nlocal function incr_list(l)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_42_incr_list.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = incr_list\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({3, 2, 1}), {4, 3, 2})\n    lu.assertEquals(candidate({5, 2, 5, 2, 3, 3, 9, 0, 123}), {6, 3, 6, 3, 4, 4, 10, 1, 124})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_42_incr_list", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = incr_list\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({3, 2, 1}), {4, 3, 2})\n    lu.assertEquals(candidate({5, 2, 5, 2, 3, 3, 9, 0, 123}), {6, 3, 6, 3, 4, 4, 10, 1, 124})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_150_x_or_y", "language": "lua", "prompt": "-- A simple program which should return the value of x if n is \n-- a prime number and should return the value of y otherwise.\n-- Examples:\n-- >>> x_or_y(7, 34, 12)\n-- 34\n-- >>> x_or_y(15, 8, 5)\n-- 5\nlocal function x_or_y(n, x, y)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_150_x_or_y.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = x_or_y\n    lu.assertEquals(candidate(7, 34, 12), 34)\n    lu.assertEquals(candidate(15, 8, 5), 5)\n    lu.assertEquals(candidate(3, 33, 5212), 33)\n    lu.assertEquals(candidate(1259, 3, 52), 3)\n    lu.assertEquals(candidate(7919, -1, 12), -1)\n    lu.assertEquals(candidate(3609, 1245, 583), 583)\n    lu.assertEquals(candidate(91, 56, 129), 129)\n    lu.assertEquals(candidate(6, 34, 1234), 1234)\n    lu.assertEquals(candidate(1, 2, 0), 0)\n    lu.assertEquals(candidate(2, 2, 0), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_150_x_or_y", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = x_or_y\n    lu.assertEquals(candidate(7, 34, 12), 34)\n    lu.assertEquals(candidate(15, 8, 5), 5)\n    lu.assertEquals(candidate(3, 33, 5212), 33)\n    lu.assertEquals(candidate(1259, 3, 52), 3)\n    lu.assertEquals(candidate(7919, -1, 12), -1)\n    lu.assertEquals(candidate(3609, 1245, 583), 583)\n    lu.assertEquals(candidate(91, 56, 129), 129)\n    lu.assertEquals(candidate(6, 34, 1234), 1234)\n    lu.assertEquals(candidate(1, 2, 0), 0)\n    lu.assertEquals(candidate(2, 2, 0), 2)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_49_modp", "language": "lua", "prompt": "-- Return 2^n modulo p (be aware of numerics).\n-- >>> modp(3, 5)\n-- 3\n-- >>> modp(1101, 101)\n-- 2\n-- >>> modp(0, 101)\n-- 1\n-- >>> modp(3, 11)\n-- 8\n-- >>> modp(100, 101)\n-- 1\nlocal function modp(n, p)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_49_modp.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = modp\n    lu.assertEquals(candidate(3, 5), 3)\n    lu.assertEquals(candidate(1101, 101), 2)\n    lu.assertEquals(candidate(0, 101), 1)\n    lu.assertEquals(candidate(3, 11), 8)\n    lu.assertEquals(candidate(100, 101), 1)\n    lu.assertEquals(candidate(30, 5), 4)\n    lu.assertEquals(candidate(31, 5), 3)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_49_modp", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = modp\n    lu.assertEquals(candidate(3, 5), 3)\n    lu.assertEquals(candidate(1101, 101), 2)\n    lu.assertEquals(candidate(0, 101), 1)\n    lu.assertEquals(candidate(3, 11), 8)\n    lu.assertEquals(candidate(100, 101), 1)\n    lu.assertEquals(candidate(30, 5), 4)\n    lu.assertEquals(candidate(31, 5), 3)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_155_even_odd_count", "language": "lua", "prompt": "-- Given an integer. return a table that has the number of even and odd digits respectively.\n-- Example:\n-- >>> even_odd_count(-12)\n-- {1, 1}\n-- >>> even_odd_count(123)\n-- {1, 2}\nlocal function even_odd_count(num)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_155_even_odd_count.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = even_odd_count\n    lu.assertEquals(candidate(7), {0, 1})\n    lu.assertEquals(candidate(-78), {1, 1})\n    lu.assertEquals(candidate(3452), {2, 2})\n    lu.assertEquals(candidate(346211), {3, 3})\n    lu.assertEquals(candidate(-345821), {3, 3})\n    lu.assertEquals(candidate(-2), {1, 0})\n    lu.assertEquals(candidate(-45347), {2, 3})\n    lu.assertEquals(candidate(0), {1, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_155_even_odd_count", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = even_odd_count\n    lu.assertEquals(candidate(7), {0, 1})\n    lu.assertEquals(candidate(-78), {1, 1})\n    lu.assertEquals(candidate(3452), {2, 2})\n    lu.assertEquals(candidate(346211), {3, 3})\n    lu.assertEquals(candidate(-345821), {3, 3})\n    lu.assertEquals(candidate(-2), {1, 0})\n    lu.assertEquals(candidate(-45347), {2, 3})\n    lu.assertEquals(candidate(0), {1, 0})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_80_is_happy", "language": "lua", "prompt": "-- You are given a string s.\n-- Your task is to check if the string is haplua or not.\n-- A string is haplua if its length is at least 3 and every 3 consecutive letters are distinct\n-- For example:\n-- >>> is_happy('a')\n-- false\n-- >>> is_happy('aa')\n-- false\n-- >>> is_happy('abcd')\n-- true\n-- >>> is_happy('aabb')\n-- false\n-- >>> is_happy('adb')\n-- true\n-- >>> is_happy('xyy')\n-- false\nlocal function is_happy(s)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_80_is_happy.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_happy\n    lu.assertEquals(candidate('a'), false)\n    lu.assertEquals(candidate('aa'), false)\n    lu.assertEquals(candidate('abcd'), true)\n    lu.assertEquals(candidate('aabb'), false)\n    lu.assertEquals(candidate('adb'), true)\n    lu.assertEquals(candidate('xyy'), false)\n    lu.assertEquals(candidate('iopaxpoi'), true)\n    lu.assertEquals(candidate('iopaxioi'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_80_is_happy", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_happy\n    lu.assertEquals(candidate('a'), false)\n    lu.assertEquals(candidate('aa'), false)\n    lu.assertEquals(candidate('abcd'), true)\n    lu.assertEquals(candidate('aabb'), false)\n    lu.assertEquals(candidate('adb'), true)\n    lu.assertEquals(candidate('xyy'), false)\n    lu.assertEquals(candidate('iopaxpoi'), true)\n    lu.assertEquals(candidate('iopaxioi'), false)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_59_largest_prime_factor", "language": "lua", "prompt": "-- Return the largest prime factor of n. Assume n > 1 and is not a prime.\n-- >>> largest_prime_factor(13195)\n-- 29\n-- >>> largest_prime_factor(2048)\n-- 2\nlocal function largest_prime_factor(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_59_largest_prime_factor.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = largest_prime_factor\n    lu.assertEquals(candidate(15), 5)\n    lu.assertEquals(candidate(27), 3)\n    lu.assertEquals(candidate(63), 7)\n    lu.assertEquals(candidate(330), 11)\n    lu.assertEquals(candidate(13195), 29)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_59_largest_prime_factor", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = largest_prime_factor\n    lu.assertEquals(candidate(15), 5)\n    lu.assertEquals(candidate(27), 3)\n    lu.assertEquals(candidate(63), 7)\n    lu.assertEquals(candidate(330), 11)\n    lu.assertEquals(candidate(13195), 29)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_66_digitSum", "language": "lua", "prompt": "-- Task\n-- Write a function that takes a string as input and returns the sum of the upper characters only'\n-- ASCII codes.\n-- Examples:\n-- >>> digitSum('')\n-- 0\n-- >>> digitSum('abAB')\n-- 131\n-- >>> digitSum('abcCd')\n-- 67\n-- >>> digitSum('helloE')\n-- 69\n-- >>> digitSum('woArBld')\n-- 131\n-- >>> digitSum('aAaaaXa')\n-- 153\nlocal function digitSum(s)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_66_digitSum.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = digitSum\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('abAB'), 131)\n    lu.assertEquals(candidate('abcCd'), 67)\n    lu.assertEquals(candidate('helloE'), 69)\n    lu.assertEquals(candidate('woArBld'), 131)\n    lu.assertEquals(candidate('aAaaaXa'), 153)\n    lu.assertEquals(candidate(' How are yOu?'), 151)\n    lu.assertEquals(candidate('You arE Very Smart'), 327)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_66_digitSum", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = digitSum\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('abAB'), 131)\n    lu.assertEquals(candidate('abcCd'), 67)\n    lu.assertEquals(candidate('helloE'), 69)\n    lu.assertEquals(candidate('woArBld'), 131)\n    lu.assertEquals(candidate('aAaaaXa'), 153)\n    lu.assertEquals(candidate(' How are yOu?'), 151)\n    lu.assertEquals(candidate('You arE Very Smart'), 327)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_21_rescale_to_unit", "language": "lua", "prompt": "-- Given table of numbers (of at least two elements), apply a linear transform to that table,\n-- such that the smallest number will become 0 and the largest will become 1\n-- >>> rescale_to_unit({1.0, 2.0, 3.0, 4.0, 5.0})\n-- {0.0, 0.25, 0.5, 0.75, 1.0}\nlocal function rescale_to_unit(numbers)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_21_rescale_to_unit.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = rescale_to_unit\n    lu.assertEquals(candidate({2.0, 49.9}), {0.0, 1.0})\n    lu.assertEquals(candidate({100.0, 49.9}), {1.0, 0.0})\n    lu.assertEquals(candidate({1.0, 2.0, 3.0, 4.0, 5.0}), {0.0, 0.25, 0.5, 0.75, 1.0})\n    lu.assertEquals(candidate({2.0, 1.0, 5.0, 3.0, 4.0}), {0.25, 0.0, 1.0, 0.5, 0.75})\n    lu.assertEquals(candidate({12.0, 11.0, 15.0, 13.0, 14.0}), {0.25, 0.0, 1.0, 0.5, 0.75})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_21_rescale_to_unit", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = rescale_to_unit\n    lu.assertEquals(candidate({2.0, 49.9}), {0.0, 1.0})\n    lu.assertEquals(candidate({100.0, 49.9}), {1.0, 0.0})\n    lu.assertEquals(candidate({1.0, 2.0, 3.0, 4.0, 5.0}), {0.0, 0.25, 0.5, 0.75, 1.0})\n    lu.assertEquals(candidate({2.0, 1.0, 5.0, 3.0, 4.0}), {0.25, 0.0, 1.0, 0.5, 0.75})\n    lu.assertEquals(candidate({12.0, 11.0, 15.0, 13.0, 14.0}), {0.25, 0.0, 1.0, 0.5, 0.75})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_121_solution", "language": "lua", "prompt": "-- Given a non-empty table of integers, return the sum of all of the odd elements that are in even positions.\n-- Examples\n-- >>> solution({5, 8, 7, 1})\n-- 12\n-- >>> solution({3, 3, 3, 3, 3})\n-- 9\n-- >>> solution({30, 13, 24, 321})\n-- 0\nlocal function solution(lst)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_121_solution.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = solution\n    lu.assertEquals(candidate({5, 8, 7, 1}), 12)\n    lu.assertEquals(candidate({3, 3, 3, 3, 3}), 9)\n    lu.assertEquals(candidate({30, 13, 24, 321}), 0)\n    lu.assertEquals(candidate({5, 9}), 5)\n    lu.assertEquals(candidate({2, 4, 8}), 0)\n    lu.assertEquals(candidate({30, 13, 23, 32}), 23)\n    lu.assertEquals(candidate({3, 13, 2, 9}), 3)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_121_solution", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = solution\n    lu.assertEquals(candidate({5, 8, 7, 1}), 12)\n    lu.assertEquals(candidate({3, 3, 3, 3, 3}), 9)\n    lu.assertEquals(candidate({30, 13, 24, 321}), 0)\n    lu.assertEquals(candidate({5, 9}), 5)\n    lu.assertEquals(candidate({2, 4, 8}), 0)\n    lu.assertEquals(candidate({30, 13, 23, 32}), 23)\n    lu.assertEquals(candidate({3, 13, 2, 9}), 3)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_68_pluck", "language": "lua", "prompt": "-- \"Given a table representing a branch of a tree that has non-negative integer nodes\n-- your task is to pluck one of the nodes and return it.\n-- The plucked node should be the node with the smallest even value.\n-- If multiple nodes with the same smallest even value are found return the node that has smallest index.\n-- The plucked node should be returned in a table, [ smalest_value, its index ],\n-- If there are no even values or the given table is empty, return [].\n-- Example 1:\n-- >>> pluck({4, 2, 3})\n-- {2, 1}\n-- Explanation: 2 has the smallest even value, and 2 has the smallest index.\n-- Example 2:\n-- >>> pluck({1, 2, 3})\n-- {2, 1}\n-- Explanation: 2 has the smallest even value, and 2 has the smallest index.\n-- Example 3:\n-- >>> pluck({})\n-- {}\n-- Example 4:\n-- >>> pluck({5, 0, 3, 0, 4, 2})\n-- {0, 1}\n-- Explanation: 0 is the smallest value, but  there are two zeros,\n-- so we will choose the first zero, which has the smallest index.\n-- Constraints:\n-- * 1 <= nodes.length <= 10000\n-- * 0 <= node.value\nlocal function pluck(arr)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_68_pluck.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = pluck\n    lu.assertEquals(candidate({4, 2, 3}), {2, 1})\n    lu.assertEquals(candidate({1, 2, 3}), {2, 1})\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({5, 0, 3, 0, 4, 2}), {0, 1})\n    lu.assertEquals(candidate({1, 2, 3, 0, 5, 3}), {0, 3})\n    lu.assertEquals(candidate({5, 4, 8, 4, 8}), {4, 1})\n    lu.assertEquals(candidate({7, 6, 7, 1}), {6, 1})\n    lu.assertEquals(candidate({7, 9, 7, 1}), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_68_pluck", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = pluck\n    lu.assertEquals(candidate({4, 2, 3}), {2, 1})\n    lu.assertEquals(candidate({1, 2, 3}), {2, 1})\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({5, 0, 3, 0, 4, 2}), {0, 1})\n    lu.assertEquals(candidate({1, 2, 3, 0, 5, 3}), {0, 3})\n    lu.assertEquals(candidate({5, 4, 8, 4, 8}), {4, 1})\n    lu.assertEquals(candidate({7, 6, 7, 1}), {6, 1})\n    lu.assertEquals(candidate({7, 9, 7, 1}), {})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_147_get_max_triples", "language": "lua", "prompt": "-- You are given a positive integer n. You have to create an integer table a of length n.\n-- For each i (1 \u2264 i \u2264 n), the value of a[i] = i * i - i + 1.\n-- Return the number of triples (a[i], a[j], a[k]) of a where i < j < k, \n-- and a[i] + a[j] + a[k] is a multiple of 3.\n-- Example :\n-- >>> get_max_triples(5)\n-- 1\n-- Explanation: \n-- a = [1, 3, 7, 13, 21]\n-- The only valid triple is (1, 7, 13).\nlocal function get_max_triples(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_147_get_max_triples.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_max_triples\n    lu.assertEquals(candidate(5), 1)\n    lu.assertEquals(candidate(6), 4)\n    lu.assertEquals(candidate(10), 36)\n    lu.assertEquals(candidate(100), 53361)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_147_get_max_triples", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_max_triples\n    lu.assertEquals(candidate(5), 1)\n    lu.assertEquals(candidate(6), 4)\n    lu.assertEquals(candidate(10), 36)\n    lu.assertEquals(candidate(100), 53361)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_110_exchange", "language": "lua", "prompt": "-- In this problem, you will implement a function that takes two tables of numbers,\n-- and determines whether it is possible to perform an exchange of elements\n-- between them to make lst1 a table of only even numbers.\n-- There is no limit on the number of exchanged elements between lst1 and lst2.\n-- If it is possible to exchange elements between the lst1 and lst2 to make\n-- all the elements of lst1 to be even, return \"YES\".\n-- Otherwise, return \"NO\".\n-- For example:\n-- >>> exchange({1, 2, 3, 4}, {1, 2, 3, 4})\n-- 'YES'\n-- >>> exchange({1, 2, 3, 4}, {1, 5, 3, 4})\n-- 'NO'\n-- It is assumed that the input tables will be non-empty.\nlocal function exchange(lst1, lst2)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_110_exchange.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = exchange\n    lu.assertEquals(candidate({1, 2, 3, 4}, {1, 2, 3, 4}), 'YES')\n    lu.assertEquals(candidate({1, 2, 3, 4}, {1, 5, 3, 4}), 'NO')\n    lu.assertEquals(candidate({1, 2, 3, 4}, {2, 1, 4, 3}), 'YES')\n    lu.assertEquals(candidate({5, 7, 3}, {2, 6, 4}), 'YES')\n    lu.assertEquals(candidate({5, 7, 3}, {2, 6, 3}), 'NO')\n    lu.assertEquals(candidate({3, 2, 6, 1, 8, 9}, {3, 5, 5, 1, 1, 1}), 'NO')\n    lu.assertEquals(candidate({100, 200}, {200, 200}), 'YES')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_110_exchange", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = exchange\n    lu.assertEquals(candidate({1, 2, 3, 4}, {1, 2, 3, 4}), 'YES')\n    lu.assertEquals(candidate({1, 2, 3, 4}, {1, 5, 3, 4}), 'NO')\n    lu.assertEquals(candidate({1, 2, 3, 4}, {2, 1, 4, 3}), 'YES')\n    lu.assertEquals(candidate({5, 7, 3}, {2, 6, 4}), 'YES')\n    lu.assertEquals(candidate({5, 7, 3}, {2, 6, 3}), 'NO')\n    lu.assertEquals(candidate({3, 2, 6, 1, 8, 9}, {3, 5, 5, 1, 1, 1}), 'NO')\n    lu.assertEquals(candidate({100, 200}, {200, 200}), 'YES')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_47_median", "language": "lua", "prompt": "-- Return median of elements in the table l.\n-- >>> median({3, 1, 2, 4, 5})\n-- 3\n-- >>> median({-10, 4, 6, 1000, 10, 20})\n-- 15.0\nlocal function median(l)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_47_median.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = median\n    lu.assertEquals(candidate({3, 1, 2, 4, 5}), 3)\n    lu.assertEquals(candidate({-10, 4, 6, 1000, 10, 20}), 8.0)\n    lu.assertEquals(candidate({5}), 5)\n    lu.assertEquals(candidate({6, 5}), 5.5)\n    lu.assertEquals(candidate({8, 1, 3, 9, 9, 2, 7}), 7)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_47_median", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = median\n    lu.assertEquals(candidate({3, 1, 2, 4, 5}), 3)\n    lu.assertEquals(candidate({-10, 4, 6, 1000, 10, 20}), 8.0)\n    lu.assertEquals(candidate({5}), 5)\n    lu.assertEquals(candidate({6, 5}), 5.5)\n    lu.assertEquals(candidate({8, 1, 3, 9, 9, 2, 7}), 7)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_82_prime_length", "language": "lua", "prompt": "-- Write a function that takes a string and returns true if the string\n-- length is a prime number or false otherwise\n-- Examples\n-- >>> prime_length('Hello')\n-- true\n-- >>> prime_length('abcdcba')\n-- true\n-- >>> prime_length('kittens')\n-- true\n-- >>> prime_length('orange')\n-- false\nlocal function prime_length(string)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_82_prime_length.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = prime_length\n    lu.assertEquals(candidate('Hello'), true)\n    lu.assertEquals(candidate('abcdcba'), true)\n    lu.assertEquals(candidate('kittens'), true)\n    lu.assertEquals(candidate('orange'), false)\n    lu.assertEquals(candidate('wow'), true)\n    lu.assertEquals(candidate('world'), true)\n    lu.assertEquals(candidate('MadaM'), true)\n    lu.assertEquals(candidate('Wow'), true)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('HI'), true)\n    lu.assertEquals(candidate('go'), true)\n    lu.assertEquals(candidate('gogo'), false)\n    lu.assertEquals(candidate('aaaaaaaaaaaaaaa'), false)\n    lu.assertEquals(candidate('Madam'), true)\n    lu.assertEquals(candidate('M'), false)\n    lu.assertEquals(candidate('0'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_82_prime_length", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = prime_length\n    lu.assertEquals(candidate('Hello'), true)\n    lu.assertEquals(candidate('abcdcba'), true)\n    lu.assertEquals(candidate('kittens'), true)\n    lu.assertEquals(candidate('orange'), false)\n    lu.assertEquals(candidate('wow'), true)\n    lu.assertEquals(candidate('world'), true)\n    lu.assertEquals(candidate('MadaM'), true)\n    lu.assertEquals(candidate('Wow'), true)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('HI'), true)\n    lu.assertEquals(candidate('go'), true)\n    lu.assertEquals(candidate('gogo'), false)\n    lu.assertEquals(candidate('aaaaaaaaaaaaaaa'), false)\n    lu.assertEquals(candidate('Madam'), true)\n    lu.assertEquals(candidate('M'), false)\n    lu.assertEquals(candidate('0'), false)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_73_smallest_change", "language": "lua", "prompt": "-- Given a table arr of integers, find the minimum number of elements that\n-- need to be changed to make the table palindromic. A palindromic table is a table that\n-- is read the same backwards and forwards. In one change, you can change one element to any other element.\n-- For example:\n-- >>> smallest_change({1, 2, 3, 5, 4, 7, 9, 6})\n-- 4\n-- >>> smallest_change({1, 2, 3, 4, 3, 2, 2})\n-- 1\n-- >>> smallest_change({1, 2, 3, 2, 1})\n-- 0\nlocal function smallest_change(arr)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_73_smallest_change.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = smallest_change\n    lu.assertEquals(candidate({1, 2, 3, 5, 4, 7, 9, 6}), 4)\n    lu.assertEquals(candidate({1, 2, 3, 4, 3, 2, 2}), 1)\n    lu.assertEquals(candidate({1, 4, 2}), 1)\n    lu.assertEquals(candidate({1, 4, 4, 2}), 1)\n    lu.assertEquals(candidate({1, 2, 3, 2, 1}), 0)\n    lu.assertEquals(candidate({3, 1, 1, 3}), 0)\n    lu.assertEquals(candidate({1}), 0)\n    lu.assertEquals(candidate({0, 1}), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_73_smallest_change", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = smallest_change\n    lu.assertEquals(candidate({1, 2, 3, 5, 4, 7, 9, 6}), 4)\n    lu.assertEquals(candidate({1, 2, 3, 4, 3, 2, 2}), 1)\n    lu.assertEquals(candidate({1, 4, 2}), 1)\n    lu.assertEquals(candidate({1, 4, 4, 2}), 1)\n    lu.assertEquals(candidate({1, 2, 3, 2, 1}), 0)\n    lu.assertEquals(candidate({3, 1, 1, 3}), 0)\n    lu.assertEquals(candidate({1}), 0)\n    lu.assertEquals(candidate({0, 1}), 1)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_133_sum_squares", "language": "lua", "prompt": "-- You are given a table of numbers.\n-- You need to return the sum of squared numbers in the given table,\n-- round each element in the table to the upper int(Ceiling) first.\n-- Examples:\n-- >>> lst({1.0, 2.0, 3.0})\n-- 14\n-- >>> lst({1.0, 4.0, 9.0})\n-- 98\n-- >>> lst({1.0, 3.0, 5.0, 7.0})\n-- 84\n-- >>> lst({1.4, 4.2, 0.0})\n-- 29\n-- >>> lst({-2.4, 1.0, 1.0})\n-- 6\nlocal function sum_squares(lst)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_133_sum_squares.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sum_squares\n    lu.assertEquals(candidate({1.0, 2.0, 3.0}), 14)\n    lu.assertEquals(candidate({1.0, 2.0, 3.0}), 14)\n    lu.assertEquals(candidate({1.0, 3.0, 5.0, 7.0}), 84)\n    lu.assertEquals(candidate({1.4, 4.2, 0.0}), 29)\n    lu.assertEquals(candidate({-2.4, 1.0, 1.0}), 6)\n    lu.assertEquals(candidate({100.0, 1.0, 15.0, 2.0}), 10230)\n    lu.assertEquals(candidate({10000.0, 10000.0}), 200000000)\n    lu.assertEquals(candidate({-1.4, 4.6, 6.3}), 75)\n    lu.assertEquals(candidate({-1.4, 17.9, 18.9, 19.9}), 1086)\n    lu.assertEquals(candidate({0.0}), 0)\n    lu.assertEquals(candidate({-1.0}), 1)\n    lu.assertEquals(candidate({-1.0, 1.0, 0.0}), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_133_sum_squares", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sum_squares\n    lu.assertEquals(candidate({1.0, 2.0, 3.0}), 14)\n    lu.assertEquals(candidate({1.0, 2.0, 3.0}), 14)\n    lu.assertEquals(candidate({1.0, 3.0, 5.0, 7.0}), 84)\n    lu.assertEquals(candidate({1.4, 4.2, 0.0}), 29)\n    lu.assertEquals(candidate({-2.4, 1.0, 1.0}), 6)\n    lu.assertEquals(candidate({100.0, 1.0, 15.0, 2.0}), 10230)\n    lu.assertEquals(candidate({10000.0, 10000.0}), 200000000)\n    lu.assertEquals(candidate({-1.4, 4.6, 6.3}), 75)\n    lu.assertEquals(candidate({-1.4, 17.9, 18.9, 19.9}), 1086)\n    lu.assertEquals(candidate({0.0}), 0)\n    lu.assertEquals(candidate({-1.0}), 1)\n    lu.assertEquals(candidate({-1.0, 1.0, 0.0}), 2)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_141_file_name_check", "language": "lua", "prompt": "-- Create a function which takes a string representing a file's name, and returns\n-- 'Yes' if the the file's name is valid, and returns 'No' otherwise.\n-- A file's name is considered to be valid if and only if all the following conditions \n-- are met:\n-- - There should not be more than three digits ('0'-'9') in the file's name.\n-- - The file's name contains exactly one dot '.'\n-- - The substring before the dot should not be empty, and it starts with a letter from \n-- the latin alphapet ('a'-'z' and 'A'-'Z').\n-- - The substring after the dot should be one of these: ['txt', 'exe', 'dll']\n-- Examples:\n-- >>> file_name_check('example.txt')\n-- 'Yes'\n-- >>> file_name_check('1example.dll')\n-- 'No'\nlocal function file_name_check(file_name)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_141_file_name_check.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = file_name_check\n    lu.assertEquals(candidate('example.txt'), 'Yes')\n    lu.assertEquals(candidate('1example.dll'), 'No')\n    lu.assertEquals(candidate('s1sdf3.asd'), 'No')\n    lu.assertEquals(candidate('K.dll'), 'Yes')\n    lu.assertEquals(candidate('MY16FILE3.exe'), 'Yes')\n    lu.assertEquals(candidate('His12FILE94.exe'), 'No')\n    lu.assertEquals(candidate('_Y.txt'), 'No')\n    lu.assertEquals(candidate('?aREYA.exe'), 'No')\n    lu.assertEquals(candidate('/this_is_valid.dll'), 'No')\n    lu.assertEquals(candidate('this_is_valid.wow'), 'No')\n    lu.assertEquals(candidate('this_is_valid.txt'), 'Yes')\n    lu.assertEquals(candidate('this_is_valid.txtexe'), 'No')\n    lu.assertEquals(candidate('#this2_i4s_5valid.ten'), 'No')\n    lu.assertEquals(candidate('@this1_is6_valid.exe'), 'No')\n    lu.assertEquals(candidate('this_is_12valid.6exe4.txt'), 'No')\n    lu.assertEquals(candidate('all.exe.txt'), 'No')\n    lu.assertEquals(candidate('I563_No.exe'), 'Yes')\n    lu.assertEquals(candidate('Is3youfault.txt'), 'Yes')\n    lu.assertEquals(candidate('no_one#knows.dll'), 'Yes')\n    lu.assertEquals(candidate('1I563_Yes3.exe'), 'No')\n    lu.assertEquals(candidate('I563_Yes3.txtt'), 'No')\n    lu.assertEquals(candidate('final..txt'), 'No')\n    lu.assertEquals(candidate('final132'), 'No')\n    lu.assertEquals(candidate('_f4indsartal132.'), 'No')\n    lu.assertEquals(candidate('.txt'), 'No')\n    lu.assertEquals(candidate('s.'), 'No')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_141_file_name_check", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = file_name_check\n    lu.assertEquals(candidate('example.txt'), 'Yes')\n    lu.assertEquals(candidate('1example.dll'), 'No')\n    lu.assertEquals(candidate('s1sdf3.asd'), 'No')\n    lu.assertEquals(candidate('K.dll'), 'Yes')\n    lu.assertEquals(candidate('MY16FILE3.exe'), 'Yes')\n    lu.assertEquals(candidate('His12FILE94.exe'), 'No')\n    lu.assertEquals(candidate('_Y.txt'), 'No')\n    lu.assertEquals(candidate('?aREYA.exe'), 'No')\n    lu.assertEquals(candidate('/this_is_valid.dll'), 'No')\n    lu.assertEquals(candidate('this_is_valid.wow'), 'No')\n    lu.assertEquals(candidate('this_is_valid.txt'), 'Yes')\n    lu.assertEquals(candidate('this_is_valid.txtexe'), 'No')\n    lu.assertEquals(candidate('#this2_i4s_5valid.ten'), 'No')\n    lu.assertEquals(candidate('@this1_is6_valid.exe'), 'No')\n    lu.assertEquals(candidate('this_is_12valid.6exe4.txt'), 'No')\n    lu.assertEquals(candidate('all.exe.txt'), 'No')\n    lu.assertEquals(candidate('I563_No.exe'), 'Yes')\n    lu.assertEquals(candidate('Is3youfault.txt'), 'Yes')\n    lu.assertEquals(candidate('no_one#knows.dll'), 'Yes')\n    lu.assertEquals(candidate('1I563_Yes3.exe'), 'No')\n    lu.assertEquals(candidate('I563_Yes3.txtt'), 'No')\n    lu.assertEquals(candidate('final..txt'), 'No')\n    lu.assertEquals(candidate('final132'), 'No')\n    lu.assertEquals(candidate('_f4indsartal132.'), 'No')\n    lu.assertEquals(candidate('.txt'), 'No')\n    lu.assertEquals(candidate('s.'), 'No')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_40_triples_sum_to_zero", "language": "lua", "prompt": "-- triples_sum_to_zero takes a table of integers as an input.\n-- it returns true if there are three distinct elements in the table that\n-- sum to zero, and false otherwise.\n-- >>> triples_sum_to_zero({1, 3, 5, 0})\n-- false\n-- >>> triples_sum_to_zero({1, 3, -2, 1})\n-- true\n-- >>> triples_sum_to_zero({1, 2, 3, 7})\n-- false\n-- >>> triples_sum_to_zero({2, 4, -5, 3, 9, 7})\n-- true\n-- >>> triples_sum_to_zero({1})\n-- false\nlocal function triples_sum_to_zero(l)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_40_triples_sum_to_zero.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = triples_sum_to_zero\n    lu.assertEquals(candidate({1, 3, 5, 0}), false)\n    lu.assertEquals(candidate({1, 3, 5, -1}), false)\n    lu.assertEquals(candidate({1, 3, -2, 1}), true)\n    lu.assertEquals(candidate({1, 2, 3, 7}), false)\n    lu.assertEquals(candidate({1, 2, 5, 7}), false)\n    lu.assertEquals(candidate({2, 4, -5, 3, 9, 7}), true)\n    lu.assertEquals(candidate({1}), false)\n    lu.assertEquals(candidate({1, 3, 5, -100}), false)\n    lu.assertEquals(candidate({100, 3, 5, -100}), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_40_triples_sum_to_zero", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = triples_sum_to_zero\n    lu.assertEquals(candidate({1, 3, 5, 0}), false)\n    lu.assertEquals(candidate({1, 3, 5, -1}), false)\n    lu.assertEquals(candidate({1, 3, -2, 1}), true)\n    lu.assertEquals(candidate({1, 2, 3, 7}), false)\n    lu.assertEquals(candidate({1, 2, 5, 7}), false)\n    lu.assertEquals(candidate({2, 4, -5, 3, 9, 7}), true)\n    lu.assertEquals(candidate({1}), false)\n    lu.assertEquals(candidate({1, 3, 5, -100}), false)\n    lu.assertEquals(candidate({100, 3, 5, -100}), false)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_127_intersection", "language": "lua", "prompt": "-- You are given two intervals,\n-- where each interval is a pair of integers. For example, interval = (start, end) = (1, 2).\n-- The given intervals are closed which means that the interval (start, end)\n-- includes both start and end.\n-- For each given interval, it is assumed that its start is less or equal its end.\n-- Your task is to determine whether the length of intersection of these two \n-- intervals is a prime number.\n-- Example, the intersection of the intervals (1, 3), (2, 4) is (2, 3)\n-- which its length is 1, which not a prime number.\n-- If the length of the intersection is a prime number, return \"YES\",\n-- otherwise, return \"NO\".\n-- If the two intervals don't intersect, return \"NO\".\n-- [input/output] samples:\n-- >>> intersection({1, 2}, {2, 3})\n-- 'NO'\n-- >>> intersection({-1, 1}, {0, 4})\n-- 'NO'\n-- >>> intersection({-3, -1}, {-5, 5})\n-- 'YES'\nlocal function intersection(interval1, interval2)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_127_intersection.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = intersection\n    lu.assertEquals(candidate({1, 2}, {2, 3}), 'NO')\n    lu.assertEquals(candidate({-1, 1}, {0, 4}), 'NO')\n    lu.assertEquals(candidate({-3, -1}, {-5, 5}), 'YES')\n    lu.assertEquals(candidate({-2, 2}, {-4, 0}), 'YES')\n    lu.assertEquals(candidate({-11, 2}, {-1, -1}), 'NO')\n    lu.assertEquals(candidate({1, 2}, {3, 5}), 'NO')\n    lu.assertEquals(candidate({1, 2}, {1, 2}), 'NO')\n    lu.assertEquals(candidate({-2, -2}, {-3, -2}), 'NO')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_127_intersection", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = intersection\n    lu.assertEquals(candidate({1, 2}, {2, 3}), 'NO')\n    lu.assertEquals(candidate({-1, 1}, {0, 4}), 'NO')\n    lu.assertEquals(candidate({-3, -1}, {-5, 5}), 'YES')\n    lu.assertEquals(candidate({-2, 2}, {-4, 0}), 'YES')\n    lu.assertEquals(candidate({-11, 2}, {-1, -1}), 'NO')\n    lu.assertEquals(candidate({1, 2}, {3, 5}), 'NO')\n    lu.assertEquals(candidate({1, 2}, {1, 2}), 'NO')\n    lu.assertEquals(candidate({-2, -2}, {-3, -2}), 'NO')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_1_separate_paren_groups", "language": "lua", "prompt": "-- Input to this function is a string containing multiple groups of nested parentheses. Your goal is to\n-- separate those group into separate strings and return the table of those.\n-- Separate groups are balanced (each open brace is properly closed) and not nested within each other\n-- Ignore any spaces in the input string.\n-- >>> separate_paren_groups('( ) (( )) (( )( ))')\n-- {'()', '(())', '(()())'}\nlocal function separate_paren_groups(paren_string)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_1_separate_paren_groups.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = separate_paren_groups\n    lu.assertEquals(candidate('(()()) ((())) () ((())()())'), {'(()())', '((()))', '()', '((())()())'})\n    lu.assertEquals(candidate('() (()) ((())) (((())))'), {'()', '(())', '((()))', '(((())))'})\n    lu.assertEquals(candidate('(()(())((())))'), {'(()(())((())))'})\n    lu.assertEquals(candidate('( ) (( )) (( )( ))'), {'()', '(())', '(()())'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_1_separate_paren_groups", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = separate_paren_groups\n    lu.assertEquals(candidate('(()()) ((())) () ((())()())'), {'(()())', '((()))', '()', '((())()())'})\n    lu.assertEquals(candidate('() (()) ((())) (((())))'), {'()', '(())', '((()))', '(((())))'})\n    lu.assertEquals(candidate('(()(())((())))'), {'(()(())((())))'})\n    lu.assertEquals(candidate('( ) (( )) (( )( ))'), {'()', '(())', '(()())'})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_152_compare", "language": "lua", "prompt": "-- I think we all remember that feeling when the result of some long-awaited\n-- event is finally known. The feelings and thoughts you have at that moment are\n-- definitely worth noting down and comparing.\n-- Your task is to determine if a person correctly guessed the results of a number of matches.\n-- You are given two tables of scores and guesses of equal length, where each index shows a match. \n-- Return a table of the same length denoting how far off each guess was. If they have guessed correctly,\n-- the value is 0, and if not, the value is the absolute difference between the guess and the score.\n-- example:\n-- >>> compare({1, 2, 3, 4, 5, 1}, {1, 2, 3, 4, 2, -2})\n-- {0, 0, 0, 0, 3, 3}\n-- >>> compare({0, 5, 0, 0, 0, 4}, {4, 1, 1, 0, 0, -2})\n-- {4, 4, 1, 0, 0, 6}\nlocal function compare(game, guess)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_152_compare.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = compare\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 1}, {1, 2, 3, 4, 2, -2}), {0, 0, 0, 0, 3, 3})\n    lu.assertEquals(candidate({0, 0, 0, 0, 0, 0}, {0, 0, 0, 0, 0, 0}), {0, 0, 0, 0, 0, 0})\n    lu.assertEquals(candidate({1, 2, 3}, {-1, -2, -3}), {2, 4, 6})\n    lu.assertEquals(candidate({1, 2, 3, 5}, {-1, 2, 3, 4}), {2, 0, 0, 1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_152_compare", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = compare\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 1}, {1, 2, 3, 4, 2, -2}), {0, 0, 0, 0, 3, 3})\n    lu.assertEquals(candidate({0, 0, 0, 0, 0, 0}, {0, 0, 0, 0, 0, 0}), {0, 0, 0, 0, 0, 0})\n    lu.assertEquals(candidate({1, 2, 3}, {-1, -2, -3}), {2, 4, 6})\n    lu.assertEquals(candidate({1, 2, 3, 5}, {-1, 2, 3, 4}), {2, 0, 0, 1})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_83_starts_one_ends", "language": "lua", "prompt": "-- Given a positive integer n, return the count of the numbers of n-digit\n-- positive integers that start or end with 1.\nlocal function starts_one_ends(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_83_starts_one_ends.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = starts_one_ends\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(2), 18)\n    lu.assertEquals(candidate(3), 180)\n    lu.assertEquals(candidate(4), 1800)\n    lu.assertEquals(candidate(5), 18000)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_83_starts_one_ends", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = starts_one_ends\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(2), 18)\n    lu.assertEquals(candidate(3), 180)\n    lu.assertEquals(candidate(4), 1800)\n    lu.assertEquals(candidate(5), 18000)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_134_check_if_last_char_is_a_letter", "language": "lua", "prompt": "-- Create a function that returns true if the last character\n-- of a given string is an alphabetical character and is not\n-- a part of a word, and false otherwise.\n-- Note: \"word\" is a group of characters separated by space.\n-- Examples:\n-- >>> check_if_last_char_is_a_letter('apple pie')\n-- false\n-- >>> check_if_last_char_is_a_letter('apple pi e')\n-- true\n-- >>> check_if_last_char_is_a_letter('apple pi e ')\n-- false\n-- >>> check_if_last_char_is_a_letter('')\n-- false\nlocal function check_if_last_char_is_a_letter(txt)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_134_check_if_last_char_is_a_letter.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = check_if_last_char_is_a_letter\n    lu.assertEquals(candidate('apple'), false)\n    lu.assertEquals(candidate('apple pi e'), true)\n    lu.assertEquals(candidate('eeeee'), false)\n    lu.assertEquals(candidate('A'), true)\n    lu.assertEquals(candidate('Pumpkin pie '), false)\n    lu.assertEquals(candidate('Pumpkin pie 1'), false)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('eeeee e '), false)\n    lu.assertEquals(candidate('apple pie'), false)\n    lu.assertEquals(candidate('apple pi e '), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_134_check_if_last_char_is_a_letter", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = check_if_last_char_is_a_letter\n    lu.assertEquals(candidate('apple'), false)\n    lu.assertEquals(candidate('apple pi e'), true)\n    lu.assertEquals(candidate('eeeee'), false)\n    lu.assertEquals(candidate('A'), true)\n    lu.assertEquals(candidate('Pumpkin pie '), false)\n    lu.assertEquals(candidate('Pumpkin pie 1'), false)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('eeeee e '), false)\n    lu.assertEquals(candidate('apple pie'), false)\n    lu.assertEquals(candidate('apple pi e '), false)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_124_valid_date", "language": "lua", "prompt": "-- You have to write a function which validates a given date string and\n-- returns true if the date is valid otherwise false.\n-- The date is valid if all of the following rules are satisfied:\n-- 1. The date string is not empty.\n-- 2. The number of days is not less than 1 or higher than 31 days for months 1,3,5,7,8,10,12. And the number of days is not less than 1 or higher than 30 days for months 4,6,9,11. And, the number of days is not less than 1 or higher than 29 for the month 2.\n-- 3. The months should not be less than 1 or higher than 12.\n-- 4. The date should be in the format: mm-dd-yyyy\n-- >>> valid_date('03-11-2000')\n-- true\n-- >>> valid_date('15-01-2012')\n-- false\n-- >>> valid_date('04-0-2040')\n-- false\n-- >>> valid_date('06-04-2020')\n-- true\n-- >>> valid_date('06/04/2020')\n-- false\nlocal function valid_date(date)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_124_valid_date.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = valid_date\n    lu.assertEquals(candidate('03-11-2000'), true)\n    lu.assertEquals(candidate('15-01-2012'), false)\n    lu.assertEquals(candidate('04-0-2040'), false)\n    lu.assertEquals(candidate('06-04-2020'), true)\n    lu.assertEquals(candidate('01-01-2007'), true)\n    lu.assertEquals(candidate('03-32-2011'), false)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('04-31-3000'), false)\n    lu.assertEquals(candidate('06-06-2005'), true)\n    lu.assertEquals(candidate('21-31-2000'), false)\n    lu.assertEquals(candidate('04-12-2003'), true)\n    lu.assertEquals(candidate('04122003'), false)\n    lu.assertEquals(candidate('20030412'), false)\n    lu.assertEquals(candidate('2003-04'), false)\n    lu.assertEquals(candidate('2003-04-12'), false)\n    lu.assertEquals(candidate('04-2003'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_124_valid_date", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = valid_date\n    lu.assertEquals(candidate('03-11-2000'), true)\n    lu.assertEquals(candidate('15-01-2012'), false)\n    lu.assertEquals(candidate('04-0-2040'), false)\n    lu.assertEquals(candidate('06-04-2020'), true)\n    lu.assertEquals(candidate('01-01-2007'), true)\n    lu.assertEquals(candidate('03-32-2011'), false)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('04-31-3000'), false)\n    lu.assertEquals(candidate('06-06-2005'), true)\n    lu.assertEquals(candidate('21-31-2000'), false)\n    lu.assertEquals(candidate('04-12-2003'), true)\n    lu.assertEquals(candidate('04122003'), false)\n    lu.assertEquals(candidate('20030412'), false)\n    lu.assertEquals(candidate('2003-04'), false)\n    lu.assertEquals(candidate('2003-04-12'), false)\n    lu.assertEquals(candidate('04-2003'), false)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_108_count_nums", "language": "lua", "prompt": "-- Write a function count_nums which takes a table of integers and returns\n-- the number of elements which has a sum of digits > 0.\n-- If a number is negative, then its first signed digit will be negative:\n-- e.g. -123 has signed digits -1, 2, and 3.\n-- >>> count_nums({})\n-- 0\n-- >>> count_nums({-1, 11, -11})\n-- 1\n-- >>> count_nums({1, 1, 2})\n-- 3\nlocal function count_nums(arr)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_108_count_nums.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = count_nums\n    lu.assertEquals(candidate({}), 0)\n    lu.assertEquals(candidate({-1, -2, 0}), 0)\n    lu.assertEquals(candidate({1, 1, 2, -2, 3, 4, 5}), 6)\n    lu.assertEquals(candidate({1, 6, 9, -6, 0, 1, 5}), 5)\n    lu.assertEquals(candidate({1, 100, 98, -7, 1, -1}), 4)\n    lu.assertEquals(candidate({12, 23, 34, -45, -56, 0}), 5)\n    lu.assertEquals(candidate({0, 1}), 1)\n    lu.assertEquals(candidate({1}), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_108_count_nums", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = count_nums\n    lu.assertEquals(candidate({}), 0)\n    lu.assertEquals(candidate({-1, -2, 0}), 0)\n    lu.assertEquals(candidate({1, 1, 2, -2, 3, 4, 5}), 6)\n    lu.assertEquals(candidate({1, 6, 9, -6, 0, 1, 5}), 5)\n    lu.assertEquals(candidate({1, 100, 98, -7, 1, -1}), 4)\n    lu.assertEquals(candidate({12, 23, 34, -45, -56, 0}), 5)\n    lu.assertEquals(candidate({0, 1}), 1)\n    lu.assertEquals(candidate({1}), 1)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_86_anti_shuffle", "language": "lua", "prompt": "-- Write a function that takes a string and returns an ordered version of it.\n-- Ordered version of string, is a string where all words (separated by space)\n-- are replaced by a new word where all the characters arranged in\n-- ascending order based on ascii value.\n-- Note: You should keep the order of words and blank spaces in the sentence.\n-- For example:\n-- >>> anti_shuffle('Hi')\n-- 'Hi'\n-- >>> anti_shuffle('hello')\n-- 'ehllo'\n-- >>> anti_shuffle('Hello World!!!')\n-- 'Hello !!!Wdlor'\nlocal function anti_shuffle(s)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_86_anti_shuffle.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = anti_shuffle\n    lu.assertEquals(candidate('Hi'), 'Hi')\n    lu.assertEquals(candidate('hello'), 'ehllo')\n    lu.assertEquals(candidate('number'), 'bemnru')\n    lu.assertEquals(candidate('abcd'), 'abcd')\n    lu.assertEquals(candidate('Hello World!!!'), 'Hello !!!Wdlor')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('Hi. My name is Mister Robot. How are you?'), '.Hi My aemn is Meirst .Rboot How aer ?ouy')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_86_anti_shuffle", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = anti_shuffle\n    lu.assertEquals(candidate('Hi'), 'Hi')\n    lu.assertEquals(candidate('hello'), 'ehllo')\n    lu.assertEquals(candidate('number'), 'bemnru')\n    lu.assertEquals(candidate('abcd'), 'abcd')\n    lu.assertEquals(candidate('Hello World!!!'), 'Hello !!!Wdlor')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('Hi. My name is Mister Robot. How are you?'), '.Hi My aemn is Meirst .Rboot How aer ?ouy')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_48_is_palindrome", "language": "lua", "prompt": "-- Checks if given string is a palindrome\n-- >>> is_palindrome('')\n-- true\n-- >>> is_palindrome('aba')\n-- true\n-- >>> is_palindrome('aaaaa')\n-- true\n-- >>> is_palindrome('zbcd')\n-- false\nlocal function is_palindrome(text)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_48_is_palindrome.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_palindrome\n    lu.assertEquals(candidate(''), true)\n    lu.assertEquals(candidate('aba'), true)\n    lu.assertEquals(candidate('aaaaa'), true)\n    lu.assertEquals(candidate('zbcd'), false)\n    lu.assertEquals(candidate('xywyx'), true)\n    lu.assertEquals(candidate('xywyz'), false)\n    lu.assertEquals(candidate('xywzx'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_48_is_palindrome", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_palindrome\n    lu.assertEquals(candidate(''), true)\n    lu.assertEquals(candidate('aba'), true)\n    lu.assertEquals(candidate('aaaaa'), true)\n    lu.assertEquals(candidate('zbcd'), false)\n    lu.assertEquals(candidate('xywyx'), true)\n    lu.assertEquals(candidate('xywyz'), false)\n    lu.assertEquals(candidate('xywzx'), false)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_118_get_closest_vowel", "language": "lua", "prompt": "-- You are given a word. Your task is to find the closest vowel that stands between \n-- two consonants from the right side of the word (case sensitive).\n-- Vowels in the beginning and ending doesn't count. Return empty string if you didn't\n-- find any vowel met the above condition. \n-- You may assume that the given string contains English letter only.\n-- Example:\n-- >>> get_closest_vowel('yogurt')\n-- 'u'\n-- >>> get_closest_vowel('FULL')\n-- 'U'\n-- >>> get_closest_vowel('quick')\n-- ''\n-- >>> get_closest_vowel('ab')\n-- ''\nlocal function get_closest_vowel(word)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_118_get_closest_vowel.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_closest_vowel\n    lu.assertEquals(candidate('yogurt'), 'u')\n    lu.assertEquals(candidate('full'), 'u')\n    lu.assertEquals(candidate('easy'), '')\n    lu.assertEquals(candidate('eAsy'), '')\n    lu.assertEquals(candidate('ali'), '')\n    lu.assertEquals(candidate('bad'), 'a')\n    lu.assertEquals(candidate('most'), 'o')\n    lu.assertEquals(candidate('ab'), '')\n    lu.assertEquals(candidate('ba'), '')\n    lu.assertEquals(candidate('quick'), '')\n    lu.assertEquals(candidate('anime'), 'i')\n    lu.assertEquals(candidate('Asia'), '')\n    lu.assertEquals(candidate('Above'), 'o')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_118_get_closest_vowel", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_closest_vowel\n    lu.assertEquals(candidate('yogurt'), 'u')\n    lu.assertEquals(candidate('full'), 'u')\n    lu.assertEquals(candidate('easy'), '')\n    lu.assertEquals(candidate('eAsy'), '')\n    lu.assertEquals(candidate('ali'), '')\n    lu.assertEquals(candidate('bad'), 'a')\n    lu.assertEquals(candidate('most'), 'o')\n    lu.assertEquals(candidate('ab'), '')\n    lu.assertEquals(candidate('ba'), '')\n    lu.assertEquals(candidate('quick'), '')\n    lu.assertEquals(candidate('anime'), 'i')\n    lu.assertEquals(candidate('Asia'), '')\n    lu.assertEquals(candidate('Above'), 'o')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_31_is_prime", "language": "lua", "prompt": "-- Return true if a given number is prime, and false otherwise.\n-- >>> is_prime(6)\n-- false\n-- >>> is_prime(101)\n-- true\n-- >>> is_prime(11)\n-- true\n-- >>> is_prime(13441)\n-- true\n-- >>> is_prime(61)\n-- true\n-- >>> is_prime(4)\n-- false\n-- >>> is_prime(1)\n-- false\nlocal function is_prime(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_31_is_prime.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_prime\n    lu.assertEquals(candidate(6), false)\n    lu.assertEquals(candidate(101), true)\n    lu.assertEquals(candidate(11), true)\n    lu.assertEquals(candidate(13441), true)\n    lu.assertEquals(candidate(61), true)\n    lu.assertEquals(candidate(4), false)\n    lu.assertEquals(candidate(1), false)\n    lu.assertEquals(candidate(5), true)\n    lu.assertEquals(candidate(11), true)\n    lu.assertEquals(candidate(17), true)\n    lu.assertEquals(candidate(85), false)\n    lu.assertEquals(candidate(77), false)\n    lu.assertEquals(candidate(255379), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_31_is_prime", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_prime\n    lu.assertEquals(candidate(6), false)\n    lu.assertEquals(candidate(101), true)\n    lu.assertEquals(candidate(11), true)\n    lu.assertEquals(candidate(13441), true)\n    lu.assertEquals(candidate(61), true)\n    lu.assertEquals(candidate(4), false)\n    lu.assertEquals(candidate(1), false)\n    lu.assertEquals(candidate(5), true)\n    lu.assertEquals(candidate(11), true)\n    lu.assertEquals(candidate(17), true)\n    lu.assertEquals(candidate(85), false)\n    lu.assertEquals(candidate(77), false)\n    lu.assertEquals(candidate(255379), false)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_144_simplify", "language": "lua", "prompt": "-- Your task is to implement a function that will simplify the expression\n-- x * n. The function returns true if x * n evaluates to a whole number and false\n-- otherwise. Both x and n, are string representation of a fraction, and have the following format,\n-- <numerator>/<denominator> where both numerator and denominator are positive whole numbers.\n-- You can assume that x, and n are valid fractions, and do not have zero as denominator.\n-- >>> simplify('1/5', '5/1')\n-- true\n-- >>> simplify('1/6', '2/1')\n-- false\n-- >>> simplify('7/10', '10/2')\n-- false\nlocal function simplify(x, n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_144_simplify.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = simplify\n    lu.assertEquals(candidate('1/5', '5/1'), true)\n    lu.assertEquals(candidate('1/6', '2/1'), false)\n    lu.assertEquals(candidate('5/1', '3/1'), true)\n    lu.assertEquals(candidate('7/10', '10/2'), false)\n    lu.assertEquals(candidate('2/10', '50/10'), true)\n    lu.assertEquals(candidate('7/2', '4/2'), true)\n    lu.assertEquals(candidate('11/6', '6/1'), true)\n    lu.assertEquals(candidate('2/3', '5/2'), false)\n    lu.assertEquals(candidate('5/2', '3/5'), false)\n    lu.assertEquals(candidate('2/4', '8/4'), true)\n    lu.assertEquals(candidate('2/4', '4/2'), true)\n    lu.assertEquals(candidate('1/5', '5/1'), true)\n    lu.assertEquals(candidate('1/5', '1/5'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_144_simplify", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = simplify\n    lu.assertEquals(candidate('1/5', '5/1'), true)\n    lu.assertEquals(candidate('1/6', '2/1'), false)\n    lu.assertEquals(candidate('5/1', '3/1'), true)\n    lu.assertEquals(candidate('7/10', '10/2'), false)\n    lu.assertEquals(candidate('2/10', '50/10'), true)\n    lu.assertEquals(candidate('7/2', '4/2'), true)\n    lu.assertEquals(candidate('11/6', '6/1'), true)\n    lu.assertEquals(candidate('2/3', '5/2'), false)\n    lu.assertEquals(candidate('5/2', '3/5'), false)\n    lu.assertEquals(candidate('2/4', '8/4'), true)\n    lu.assertEquals(candidate('2/4', '4/2'), true)\n    lu.assertEquals(candidate('1/5', '5/1'), true)\n    lu.assertEquals(candidate('1/5', '1/5'), false)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_78_hex_key", "language": "lua", "prompt": "-- You have been tasked to write a function that receives \n-- a hexadecimal number as a string and counts the number of hexadecimal \n-- digits that are primes (prime number, or a prime, is a natural number \n-- greater than 1 that is not a product of two smaller natural numbers).\n-- Hexadecimal digits are 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F.\n-- Prime numbers are 2, 3, 5, 7, 11, 13, 17,...\n-- So you have to determine a number of the following digits: 2, 3, 5, 7, \n-- B (=decimal 11), D (=decimal 13).\n-- Note: you may assume the input is always correct or empty string, \n-- and symbols A,B,C,D,E,F are always uppercase.\n-- Examples:\n-- >>> hex_key('AB')\n-- 1\n-- >>> hex_key('1077E')\n-- 2\n-- >>> hex_key('ABED1A33')\n-- 4\n-- >>> hex_key('123456789ABCDEF0')\n-- 6\n-- >>> hex_key('2020')\n-- 2\nlocal function hex_key(num)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_78_hex_key.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = hex_key\n    lu.assertEquals(candidate('AB'), 1)\n    lu.assertEquals(candidate('1077E'), 2)\n    lu.assertEquals(candidate('ABED1A33'), 4)\n    lu.assertEquals(candidate('2020'), 2)\n    lu.assertEquals(candidate('123456789ABCDEF0'), 6)\n    lu.assertEquals(candidate('112233445566778899AABBCCDDEEFF00'), 12)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_78_hex_key", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = hex_key\n    lu.assertEquals(candidate('AB'), 1)\n    lu.assertEquals(candidate('1077E'), 2)\n    lu.assertEquals(candidate('ABED1A33'), 4)\n    lu.assertEquals(candidate('2020'), 2)\n    lu.assertEquals(candidate('123456789ABCDEF0'), 6)\n    lu.assertEquals(candidate('112233445566778899AABBCCDDEEFF00'), 12)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_143_words_in_sentence", "language": "lua", "prompt": "-- You are given a string representing a sentence,\n-- the sentence contains some words separated by a space,\n-- and you have to return a string that contains the words from the original sentence,\n-- whose lengths are prime numbers,\n-- the order of the words in the new string should be the same as the original one.\n-- Example 1:\n-- >>> words_in_sentence('This is a test')\n-- 'is'\n-- Example 2:\n-- >>> words_in_sentence('lets go for swimming')\n-- 'go for'\n-- Constraints:\n-- * 1 <= len(sentence) <= 100\n-- * sentence contains only letters\nlocal function words_in_sentence(sentence)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_143_words_in_sentence.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = words_in_sentence\n    lu.assertEquals(candidate('This is a test'), 'is')\n    lu.assertEquals(candidate('lets go for swimming'), 'go for')\n    lu.assertEquals(candidate('there is no place available here'), 'there is no place')\n    lu.assertEquals(candidate('Hi I am Hussein'), 'Hi am Hussein')\n    lu.assertEquals(candidate('go for it'), 'go for it')\n    lu.assertEquals(candidate('here'), '')\n    lu.assertEquals(candidate('here is'), 'is')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_143_words_in_sentence", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = words_in_sentence\n    lu.assertEquals(candidate('This is a test'), 'is')\n    lu.assertEquals(candidate('lets go for swimming'), 'go for')\n    lu.assertEquals(candidate('there is no place available here'), 'there is no place')\n    lu.assertEquals(candidate('Hi I am Hussein'), 'Hi am Hussein')\n    lu.assertEquals(candidate('go for it'), 'go for it')\n    lu.assertEquals(candidate('here'), '')\n    lu.assertEquals(candidate('here is'), 'is')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_111_histogram", "language": "lua", "prompt": "-- Given a string representing a space separated lowercase letters, return a table\n-- of the letter with the most repetition and containing the corresponding count.\n-- If several letters have the same occurrence, return all of them.\n-- Example:\n-- >>> histogram('a b c')\n-- {['a'] = 1, ['b'] = 1, ['c'] = 1}\n-- >>> histogram('a b b a')\n-- {['a'] = 2, ['b'] = 2}\n-- >>> histogram('a b c a b')\n-- {['a'] = 2, ['b'] = 2}\n-- >>> histogram('b b b b a')\n-- {['b'] = 4}\n-- >>> histogram('')\n-- {}\nlocal function histogram(test)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_111_histogram.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = histogram\n    lu.assertEquals(candidate('a b b a'), {['a'] = 2, ['b'] = 2})\n    lu.assertEquals(candidate('a b c a b'), {['a'] = 2, ['b'] = 2})\n    lu.assertEquals(candidate('a b c d g'), {['a'] = 1, ['b'] = 1, ['c'] = 1, ['d'] = 1, ['g'] = 1})\n    lu.assertEquals(candidate('r t g'), {['r'] = 1, ['t'] = 1, ['g'] = 1})\n    lu.assertEquals(candidate('b b b b a'), {['b'] = 4})\n    lu.assertEquals(candidate('r t g'), {['r'] = 1, ['t'] = 1, ['g'] = 1})\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate('a'), {['a'] = 1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_111_histogram", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = histogram\n    lu.assertEquals(candidate('a b b a'), {['a'] = 2, ['b'] = 2})\n    lu.assertEquals(candidate('a b c a b'), {['a'] = 2, ['b'] = 2})\n    lu.assertEquals(candidate('a b c d g'), {['a'] = 1, ['b'] = 1, ['c'] = 1, ['d'] = 1, ['g'] = 1})\n    lu.assertEquals(candidate('r t g'), {['r'] = 1, ['t'] = 1, ['g'] = 1})\n    lu.assertEquals(candidate('b b b b a'), {['b'] = 4})\n    lu.assertEquals(candidate('r t g'), {['r'] = 1, ['t'] = 1, ['g'] = 1})\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate('a'), {['a'] = 1})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_87_get_row", "language": "lua", "prompt": "-- You are given a 2 dimensional data, as a nested tables,\n-- which is similar to matrix, however, unlike matrices,\n-- each row may contain a different number of columns.\n-- Given lst, and integer x, find integers x in the table,\n-- and return table of tables, [(x1, y1), (x2, y2) ...] such that\n-- each table is a coordinate - (row, columns), starting with 0.\n-- Sort coordinates initially by rows in ascending order.\n-- Also, sort coordinates of the row by columns in descending order.\n-- Examples:\n-- >>> get_row({{1, 2, 3, 4, 5, 6}, {1, 2, 3, 4, 1, 6}, {1, 2, 3, 4, 5, 1}}, 1)\n-- {{0, 0}, {1, 4}, {1, 0}, {2, 5}, {2, 0}}\n-- >>> get_row({}, 1)\n-- {}\n-- >>> get_row({{}, {1}, {1, 2, 3}}, 3)\n-- {{2, 2}}\nlocal function get_row(lst, x)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_87_get_row.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_row\n    lu.assertEquals(candidate({{1, 2, 3, 4, 5, 6}, {1, 2, 3, 4, 1, 6}, {1, 2, 3, 4, 5, 1}}, 1), {{0, 0}, {1, 4}, {1, 0}, {2, 5}, {2, 0}})\n    lu.assertEquals(candidate({{1, 2, 3, 4, 5, 6}, {1, 2, 3, 4, 5, 6}, {1, 2, 3, 4, 5, 6}, {1, 2, 3, 4, 5, 6}, {1, 2, 3, 4, 5, 6}, {1, 2, 3, 4, 5, 6}}, 2), {{0, 1}, {1, 1}, {2, 1}, {3, 1}, {4, 1}, {5, 1}})\n    lu.assertEquals(candidate({{1, 2, 3, 4, 5, 6}, {1, 2, 3, 4, 5, 6}, {1, 1, 3, 4, 5, 6}, {1, 2, 1, 4, 5, 6}, {1, 2, 3, 1, 5, 6}, {1, 2, 3, 4, 1, 6}, {1, 2, 3, 4, 5, 1}}, 1), {{0, 0}, {1, 0}, {2, 1}, {2, 0}, {3, 2}, {3, 0}, {4, 3}, {4, 0}, {5, 4}, {5, 0}, {6, 5}, {6, 0}})\n    lu.assertEquals(candidate({}, 1), {})\n    lu.assertEquals(candidate({{1}}, 2), {})\n    lu.assertEquals(candidate({{}, {1}, {1, 2, 3}}, 3), {{2, 2}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_87_get_row", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_row\n    lu.assertEquals(candidate({{1, 2, 3, 4, 5, 6}, {1, 2, 3, 4, 1, 6}, {1, 2, 3, 4, 5, 1}}, 1), {{0, 0}, {1, 4}, {1, 0}, {2, 5}, {2, 0}})\n    lu.assertEquals(candidate({{1, 2, 3, 4, 5, 6}, {1, 2, 3, 4, 5, 6}, {1, 2, 3, 4, 5, 6}, {1, 2, 3, 4, 5, 6}, {1, 2, 3, 4, 5, 6}, {1, 2, 3, 4, 5, 6}}, 2), {{0, 1}, {1, 1}, {2, 1}, {3, 1}, {4, 1}, {5, 1}})\n    lu.assertEquals(candidate({{1, 2, 3, 4, 5, 6}, {1, 2, 3, 4, 5, 6}, {1, 1, 3, 4, 5, 6}, {1, 2, 1, 4, 5, 6}, {1, 2, 3, 1, 5, 6}, {1, 2, 3, 4, 1, 6}, {1, 2, 3, 4, 5, 1}}, 1), {{0, 0}, {1, 0}, {2, 1}, {2, 0}, {3, 2}, {3, 0}, {4, 3}, {4, 0}, {5, 4}, {5, 0}, {6, 5}, {6, 0}})\n    lu.assertEquals(candidate({}, 1), {})\n    lu.assertEquals(candidate({{1}}, 2), {})\n    lu.assertEquals(candidate({{}, {1}, {1, 2, 3}}, 3), {{2, 2}})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_123_get_odd_collatz", "language": "lua", "prompt": "-- Given a positive integer n, return a sorted table that has the odd numbers in collatz sequence.\n-- The Collatz conjecture is a conjecture in mathematics that concerns a sequence defined\n-- as follows: start with any positive integer n. Then each term is obtained from the \n-- previous term as follows: if the previous term is even, the next term is one half of \n-- the previous term. If the previous term is odd, the next term is 3 times the previous\n-- term plus 1. The conjecture is that no matter what value of n, the sequence will always reach 1.\n-- Note: \n-- 1. Collatz(1) is [1].\n-- 2. returned table sorted in increasing order.\n-- For example:\n-- get_odd_collatz(5) returns [1, 5] # The collatz sequence for 5 is [5, 16, 8, 4, 2, 1], so the odd numbers are only 1, and 5.\n-- >>> get_odd_collatz(5)\n-- {1, 5}\nlocal function get_odd_collatz(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_123_get_odd_collatz.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_odd_collatz\n    lu.assertEquals(candidate(14), {1, 5, 7, 11, 13, 17})\n    lu.assertEquals(candidate(5), {1, 5})\n    lu.assertEquals(candidate(12), {1, 3, 5})\n    lu.assertEquals(candidate(1), {1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_123_get_odd_collatz", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_odd_collatz\n    lu.assertEquals(candidate(14), {1, 5, 7, 11, 13, 17})\n    lu.assertEquals(candidate(5), {1, 5})\n    lu.assertEquals(candidate(12), {1, 3, 5})\n    lu.assertEquals(candidate(1), {1})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_135_can_arrange", "language": "lua", "prompt": "-- Create a function which returns the largest index of an element which\n-- is not greater than or equal to the element immediately preceding it. If\n-- no such element exists then return -1. The given table will not contain\n-- duplicate values.\n-- Examples:\n-- >>> can_arrange({1, 2, 4, 3, 5})\n-- 3\n-- >>> can_arrange({1, 2, 3})\n-- -1\nlocal function can_arrange(arr)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_135_can_arrange.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = can_arrange\n    lu.assertEquals(candidate({1, 2, 4, 3, 5}), 3)\n    lu.assertEquals(candidate({1, 2, 4, 5}), -1)\n    lu.assertEquals(candidate({1, 4, 2, 5, 6, 7, 8, 9, 10}), 2)\n    lu.assertEquals(candidate({4, 8, 5, 7, 3}), 4)\n    lu.assertEquals(candidate({}), -1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_135_can_arrange", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = can_arrange\n    lu.assertEquals(candidate({1, 2, 4, 3, 5}), 3)\n    lu.assertEquals(candidate({1, 2, 4, 5}), -1)\n    lu.assertEquals(candidate({1, 4, 2, 5, 6, 7, 8, 9, 10}), 2)\n    lu.assertEquals(candidate({4, 8, 5, 7, 3}), 4)\n    lu.assertEquals(candidate({}), -1)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_19_sort_numbers", "language": "lua", "prompt": "-- Input is a space-delimited string of numberals from 'zero' to 'nine'.\n-- Valid choices are 'zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight' and 'nine'.\n-- Return the string with numbers sorted from smallest to largest\n-- >>> sort_numbers('three one five')\n-- 'one three five'\nlocal function sort_numbers(numbers)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_19_sort_numbers.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sort_numbers\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('three'), 'three')\n    lu.assertEquals(candidate('three five nine'), 'three five nine')\n    lu.assertEquals(candidate('five zero four seven nine eight'), 'zero four five seven eight nine')\n    lu.assertEquals(candidate('six five four three two one zero'), 'zero one two three four five six')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_19_sort_numbers", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sort_numbers\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('three'), 'three')\n    lu.assertEquals(candidate('three five nine'), 'three five nine')\n    lu.assertEquals(candidate('five zero four seven nine eight'), 'zero four five seven eight nine')\n    lu.assertEquals(candidate('six five four three two one zero'), 'zero one two three four five six')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_65_circular_shift", "language": "lua", "prompt": "-- Circular shift the digits of the integer x, shift the digits right by shift\n-- and return the result as a string.\n-- If shift > number of digits, return digits reversed.\n-- >>> circular_shift(12, 1)\n-- '21'\n-- >>> circular_shift(12, 2)\n-- '12'\nlocal function circular_shift(x, shift)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_65_circular_shift.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = circular_shift\n    lu.assertEquals(candidate(100, 2), '001')\n    lu.assertEquals(candidate(12, 2), '12')\n    lu.assertEquals(candidate(97, 8), '79')\n    lu.assertEquals(candidate(12, 1), '21')\n    lu.assertEquals(candidate(11, 101), '11')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_65_circular_shift", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = circular_shift\n    lu.assertEquals(candidate(100, 2), '001')\n    lu.assertEquals(candidate(12, 2), '12')\n    lu.assertEquals(candidate(97, 8), '79')\n    lu.assertEquals(candidate(12, 1), '21')\n    lu.assertEquals(candidate(11, 101), '11')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_142_sum_squares", "language": "lua", "prompt": "-- \"\n-- This function will take a table of integers. For all entries in the table, the function shall square the integer entry if its index is a \n-- multiple of 3 and will cube the integer entry if its index is a multiple of 4 and not a multiple of 3. The function will not \n-- change the entries in the table whose indexes are not a multiple of 3 or 4. The function shall then return the sum of all entries. \n-- Examples:\n-- >>> lst\n-- {1, 2, 3}\n-- >>> lst\n-- {}\n-- >>> lst\n-- {-1, -5, 2, -1, -5}\nlocal function sum_squares(lst)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_142_sum_squares.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sum_squares\n    lu.assertEquals(candidate({1, 2, 3}), 6)\n    lu.assertEquals(candidate({1, 4, 9}), 14)\n    lu.assertEquals(candidate({}), 0)\n    lu.assertEquals(candidate({1, 1, 1, 1, 1, 1, 1, 1, 1}), 9)\n    lu.assertEquals(candidate({-1, -1, -1, -1, -1, -1, -1, -1, -1}), -3)\n    lu.assertEquals(candidate({0}), 0)\n    lu.assertEquals(candidate({-1, -5, 2, -1, -5}), -126)\n    lu.assertEquals(candidate({-56, -99, 1, 0, -2}), 3030)\n    lu.assertEquals(candidate({-1, 0, 0, 0, 0, 0, 0, 0, -1}), 0)\n    lu.assertEquals(candidate({-16, -9, -2, 36, 36, 26, -20, 25, -40, 20, -4, 12, -26, 35, 37}), -14196)\n    lu.assertEquals(candidate({-1, -3, 17, -1, -15, 13, -1, 14, -14, -12, -5, 14, -14, 6, 13, 11, 16, 16, 4, 10}), -1448)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_142_sum_squares", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sum_squares\n    lu.assertEquals(candidate({1, 2, 3}), 6)\n    lu.assertEquals(candidate({1, 4, 9}), 14)\n    lu.assertEquals(candidate({}), 0)\n    lu.assertEquals(candidate({1, 1, 1, 1, 1, 1, 1, 1, 1}), 9)\n    lu.assertEquals(candidate({-1, -1, -1, -1, -1, -1, -1, -1, -1}), -3)\n    lu.assertEquals(candidate({0}), 0)\n    lu.assertEquals(candidate({-1, -5, 2, -1, -5}), -126)\n    lu.assertEquals(candidate({-56, -99, 1, 0, -2}), 3030)\n    lu.assertEquals(candidate({-1, 0, 0, 0, 0, 0, 0, 0, -1}), 0)\n    lu.assertEquals(candidate({-16, -9, -2, 36, 36, 26, -20, 25, -40, 20, -4, 12, -26, 35, 37}), -14196)\n    lu.assertEquals(candidate({-1, -3, 17, -1, -15, 13, -1, 14, -14, -12, -5, 14, -14, 6, 13, 11, 16, 16, 4, 10}), -1448)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_94_skjkasdkd", "language": "lua", "prompt": "-- You are given a table of integers.\n-- You need to find the largest prime value and return the sum of its digits.\n-- Examples:\n-- >>> skjkasdkd({0, 3, 2, 1, 3, 5, 7, 4, 5, 5, 5, 2, 181, 32, 4, 32, 3, 2, 32, 324, 4, 3})\n-- 10\n-- >>> skjkasdkd({1, 0, 1, 8, 2, 4597, 2, 1, 3, 40, 1, 2, 1, 2, 4, 2, 5, 1})\n-- 25\n-- >>> skjkasdkd({1, 3, 1, 32, 5107, 34, 83278, 109, 163, 23, 2323, 32, 30, 1, 9, 3})\n-- 13\n-- >>> skjkasdkd({0, 724, 32, 71, 99, 32, 6, 0, 5, 91, 83, 0, 5, 6})\n-- 11\n-- >>> skjkasdkd({0, 81, 12, 3, 1, 21})\n-- 3\n-- >>> skjkasdkd({0, 8, 1, 2, 1, 7})\n-- 7\nlocal function skjkasdkd(lst)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_94_skjkasdkd.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = skjkasdkd\n    lu.assertEquals(candidate({0, 3, 2, 1, 3, 5, 7, 4, 5, 5, 5, 2, 181, 32, 4, 32, 3, 2, 32, 324, 4, 3}), 10)\n    lu.assertEquals(candidate({1, 0, 1, 8, 2, 4597, 2, 1, 3, 40, 1, 2, 1, 2, 4, 2, 5, 1}), 25)\n    lu.assertEquals(candidate({1, 3, 1, 32, 5107, 34, 83278, 109, 163, 23, 2323, 32, 30, 1, 9, 3}), 13)\n    lu.assertEquals(candidate({0, 724, 32, 71, 99, 32, 6, 0, 5, 91, 83, 0, 5, 6}), 11)\n    lu.assertEquals(candidate({0, 81, 12, 3, 1, 21}), 3)\n    lu.assertEquals(candidate({0, 8, 1, 2, 1, 7}), 7)\n    lu.assertEquals(candidate({8191}), 19)\n    lu.assertEquals(candidate({8191, 123456, 127, 7}), 19)\n    lu.assertEquals(candidate({127, 97, 8192}), 10)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_94_skjkasdkd", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = skjkasdkd\n    lu.assertEquals(candidate({0, 3, 2, 1, 3, 5, 7, 4, 5, 5, 5, 2, 181, 32, 4, 32, 3, 2, 32, 324, 4, 3}), 10)\n    lu.assertEquals(candidate({1, 0, 1, 8, 2, 4597, 2, 1, 3, 40, 1, 2, 1, 2, 4, 2, 5, 1}), 25)\n    lu.assertEquals(candidate({1, 3, 1, 32, 5107, 34, 83278, 109, 163, 23, 2323, 32, 30, 1, 9, 3}), 13)\n    lu.assertEquals(candidate({0, 724, 32, 71, 99, 32, 6, 0, 5, 91, 83, 0, 5, 6}), 11)\n    lu.assertEquals(candidate({0, 81, 12, 3, 1, 21}), 3)\n    lu.assertEquals(candidate({0, 8, 1, 2, 1, 7}), 7)\n    lu.assertEquals(candidate({8191}), 19)\n    lu.assertEquals(candidate({8191, 123456, 127, 7}), 19)\n    lu.assertEquals(candidate({127, 97, 8192}), 10)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_8_sum_product", "language": "lua", "prompt": "-- For a given table of integers, return a table consisting of a sum and a product of all the integers in a table.\n-- Empty sum should be equal to 0 and empty product should be equal to 1.\n-- >>> sum_product({})\n-- {0, 1}\n-- >>> sum_product({1, 2, 3, 4})\n-- {10, 24}\nlocal function sum_product(numbers)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_8_sum_product.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sum_product\n    lu.assertEquals(candidate({}), {0, 1})\n    lu.assertEquals(candidate({1, 1, 1}), {3, 1})\n    lu.assertEquals(candidate({100, 0}), {100, 0})\n    lu.assertEquals(candidate({3, 5, 7}), {15, 105})\n    lu.assertEquals(candidate({10}), {10, 10})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_8_sum_product", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sum_product\n    lu.assertEquals(candidate({}), {0, 1})\n    lu.assertEquals(candidate({1, 1, 1}), {3, 1})\n    lu.assertEquals(candidate({100, 0}), {100, 0})\n    lu.assertEquals(candidate({3, 5, 7}), {15, 105})\n    lu.assertEquals(candidate({10}), {10, 10})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_102_choose_num", "language": "lua", "prompt": "-- This function takes two positive numbers x and y and returns the\n-- biggest even integer number that is in the range [x, y] inclusive. If \n-- there's no such number, then the function should return -1.\n-- For example:\n-- >>> choose_num(12, 15)\n-- 14\n-- >>> choose_num(13, 12)\n-- -1\nlocal function choose_num(x, y)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_102_choose_num.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = choose_num\n    lu.assertEquals(candidate(12, 15), 14)\n    lu.assertEquals(candidate(13, 12), -1)\n    lu.assertEquals(candidate(33, 12354), 12354)\n    lu.assertEquals(candidate(5234, 5233), -1)\n    lu.assertEquals(candidate(6, 29), 28)\n    lu.assertEquals(candidate(27, 10), -1)\n    lu.assertEquals(candidate(7, 7), -1)\n    lu.assertEquals(candidate(546, 546), 546)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_102_choose_num", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = choose_num\n    lu.assertEquals(candidate(12, 15), 14)\n    lu.assertEquals(candidate(13, 12), -1)\n    lu.assertEquals(candidate(33, 12354), 12354)\n    lu.assertEquals(candidate(5234, 5233), -1)\n    lu.assertEquals(candidate(6, 29), 28)\n    lu.assertEquals(candidate(27, 10), -1)\n    lu.assertEquals(candidate(7, 7), -1)\n    lu.assertEquals(candidate(546, 546), 546)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_136_largest_smallest_integers", "language": "lua", "prompt": "-- Create a function that returns a table (a, b), where 'a' is\n-- the largest of negative integers, and 'b' is the smallest\n-- of positive integers in a table.\n-- If there is no negative or positive integers, return them as None.\n-- Examples:\n-- >>> largest_smallest_integers({2, 4, 1, 3, 5, 7})\n-- {None, 1}\n-- >>> largest_smallest_integers({})\n-- {None, None}\n-- >>> largest_smallest_integers({0})\n-- {None, None}\nlocal function largest_smallest_integers(lst)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_136_largest_smallest_integers.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = largest_smallest_integers\n    lu.assertEquals(candidate({2, 4, 1, 3, 5, 7}), {None, 1})\n    lu.assertEquals(candidate({2, 4, 1, 3, 5, 7, 0}), {None, 1})\n    lu.assertEquals(candidate({1, 3, 2, 4, 5, 6, -2}), {-2, 1})\n    lu.assertEquals(candidate({4, 5, 3, 6, 2, 7, -7}), {-7, 2})\n    lu.assertEquals(candidate({7, 3, 8, 4, 9, 2, 5, -9}), {-9, 2})\n    lu.assertEquals(candidate({}), {None, None})\n    lu.assertEquals(candidate({0}), {None, None})\n    lu.assertEquals(candidate({-1, -3, -5, -6}), {-1, None})\n    lu.assertEquals(candidate({-1, -3, -5, -6, 0}), {-1, None})\n    lu.assertEquals(candidate({-6, -4, -4, -3, 1}), {-3, 1})\n    lu.assertEquals(candidate({-6, -4, -4, -3, -100, 1}), {-3, 1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_136_largest_smallest_integers", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = largest_smallest_integers\n    lu.assertEquals(candidate({2, 4, 1, 3, 5, 7}), {None, 1})\n    lu.assertEquals(candidate({2, 4, 1, 3, 5, 7, 0}), {None, 1})\n    lu.assertEquals(candidate({1, 3, 2, 4, 5, 6, -2}), {-2, 1})\n    lu.assertEquals(candidate({4, 5, 3, 6, 2, 7, -7}), {-7, 2})\n    lu.assertEquals(candidate({7, 3, 8, 4, 9, 2, 5, -9}), {-9, 2})\n    lu.assertEquals(candidate({}), {None, None})\n    lu.assertEquals(candidate({0}), {None, None})\n    lu.assertEquals(candidate({-1, -3, -5, -6}), {-1, None})\n    lu.assertEquals(candidate({-1, -3, -5, -6, 0}), {-1, None})\n    lu.assertEquals(candidate({-6, -4, -4, -3, 1}), {-3, 1})\n    lu.assertEquals(candidate({-6, -4, -4, -3, -100, 1}), {-3, 1})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_16_count_distinct_characters", "language": "lua", "prompt": "-- Given a string, find out how many distinct characters (regardless of case) does it consist of\n-- >>> count_distinct_characters('xyzXYZ')\n-- 3\n-- >>> count_distinct_characters('Jerry')\n-- 4\nlocal function count_distinct_characters(string)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_16_count_distinct_characters.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = count_distinct_characters\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('abcde'), 5)\n    lu.assertEquals(candidate('abcdecadeCADE'), 5)\n    lu.assertEquals(candidate('aaaaAAAAaaaa'), 1)\n    lu.assertEquals(candidate('Jerry jERRY JeRRRY'), 5)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_16_count_distinct_characters", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = count_distinct_characters\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('abcde'), 5)\n    lu.assertEquals(candidate('abcdecadeCADE'), 5)\n    lu.assertEquals(candidate('aaaaAAAAaaaa'), 1)\n    lu.assertEquals(candidate('Jerry jERRY JeRRRY'), 5)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_100_make_a_pile", "language": "lua", "prompt": "-- Given a positive integer n, you have to make a pile of n levels of stones.\n-- The first level has n stones.\n-- The number of stones in the next level is:\n-- - the next odd number if n is odd.\n-- - the next even number if n is even.\n-- Return the number of stones in each level in a table, where element at index\n-- i represents the number of stones in the level (i+1).\n-- Examples:\n-- >>> make_a_pile(3)\n-- {3, 5, 7}\nlocal function make_a_pile(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_100_make_a_pile.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = make_a_pile\n    lu.assertEquals(candidate(3), {3, 5, 7})\n    lu.assertEquals(candidate(4), {4, 6, 8, 10})\n    lu.assertEquals(candidate(5), {5, 7, 9, 11, 13})\n    lu.assertEquals(candidate(6), {6, 8, 10, 12, 14, 16})\n    lu.assertEquals(candidate(8), {8, 10, 12, 14, 16, 18, 20, 22})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_100_make_a_pile", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = make_a_pile\n    lu.assertEquals(candidate(3), {3, 5, 7})\n    lu.assertEquals(candidate(4), {4, 6, 8, 10})\n    lu.assertEquals(candidate(5), {5, 7, 9, 11, 13})\n    lu.assertEquals(candidate(6), {6, 8, 10, 12, 14, 16})\n    lu.assertEquals(candidate(8), {8, 10, 12, 14, 16, 18, 20, 22})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_128_prod_signs", "language": "lua", "prompt": "-- You are given a table arr of integers and you need to return\n-- sum of magnitudes of integers multiplied by product of all signs\n-- of each number in the table, represented by 1, -1 or 0.\n-- Note: return None for empty arr.\n-- Example:\n-- >>> prod_signs({1, 2, 2, -4})\n-- 9\n-- >>> prod_signs({0, 1})\n-- 0\n-- >>> prod_signs({})\n-- None\nlocal function prod_signs(arr)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_128_prod_signs.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = prod_signs\n    lu.assertEquals(candidate({1, 2, 2, -4}), -9)\n    lu.assertEquals(candidate({0, 1}), 0)\n    lu.assertEquals(candidate({1, 1, 1, 2, 3, -1, 1}), -10)\n    lu.assertEquals(candidate({}), None)\n    lu.assertEquals(candidate({2, 4, 1, 2, -1, -1, 9}), 20)\n    lu.assertEquals(candidate({-1, 1, -1, 1}), 4)\n    lu.assertEquals(candidate({-1, 1, 1, 1}), -4)\n    lu.assertEquals(candidate({-1, 1, 1, 0}), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_128_prod_signs", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = prod_signs\n    lu.assertEquals(candidate({1, 2, 2, -4}), -9)\n    lu.assertEquals(candidate({0, 1}), 0)\n    lu.assertEquals(candidate({1, 1, 1, 2, 3, -1, 1}), -10)\n    lu.assertEquals(candidate({}), None)\n    lu.assertEquals(candidate({2, 4, 1, 2, -1, -1, 9}), 20)\n    lu.assertEquals(candidate({-1, 1, -1, 1}), 4)\n    lu.assertEquals(candidate({-1, 1, 1, 1}), -4)\n    lu.assertEquals(candidate({-1, 1, 1, 0}), 0)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_114_minSubArraySum", "language": "lua", "prompt": "-- Given a table of integers nums, find the minimum sum of any non-empty sub-table\n-- of nums.\n-- Example\n-- >>> minSubArraySum({2, 3, 4, 1, 2, 4})\n-- 1\n-- >>> minSubArraySum({-1, -2, -3})\n-- -6\nlocal function minSubArraySum(nums)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_114_minSubArraySum.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = minSubArraySum\n    lu.assertEquals(candidate({2, 3, 4, 1, 2, 4}), 1)\n    lu.assertEquals(candidate({-1, -2, -3}), -6)\n    lu.assertEquals(candidate({-1, -2, -3, 2, -10}), -14)\n    lu.assertEquals(candidate({-9999999999999999}), -9999999999999999)\n    lu.assertEquals(candidate({0, 10, 20, 1000000}), 0)\n    lu.assertEquals(candidate({-1, -2, -3, 10, -5}), -6)\n    lu.assertEquals(candidate({100, -1, -2, -3, 10, -5}), -6)\n    lu.assertEquals(candidate({10, 11, 13, 8, 3, 4}), 3)\n    lu.assertEquals(candidate({100, -33, 32, -1, 0, -2}), -33)\n    lu.assertEquals(candidate({-10}), -10)\n    lu.assertEquals(candidate({7}), 7)\n    lu.assertEquals(candidate({1, -1}), -1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_114_minSubArraySum", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = minSubArraySum\n    lu.assertEquals(candidate({2, 3, 4, 1, 2, 4}), 1)\n    lu.assertEquals(candidate({-1, -2, -3}), -6)\n    lu.assertEquals(candidate({-1, -2, -3, 2, -10}), -14)\n    lu.assertEquals(candidate({-9999999999999999}), -9999999999999999)\n    lu.assertEquals(candidate({0, 10, 20, 1000000}), 0)\n    lu.assertEquals(candidate({-1, -2, -3, 10, -5}), -6)\n    lu.assertEquals(candidate({100, -1, -2, -3, 10, -5}), -6)\n    lu.assertEquals(candidate({10, 11, 13, 8, 3, 4}), 3)\n    lu.assertEquals(candidate({100, -33, 32, -1, 0, -2}), -33)\n    lu.assertEquals(candidate({-10}), -10)\n    lu.assertEquals(candidate({7}), 7)\n    lu.assertEquals(candidate({1, -1}), -1)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_15_string_sequence", "language": "lua", "prompt": "-- Return a string containing space-delimited numbers starting from 0 upto n inclusive.\n-- >>> string_sequence(0)\n-- '0'\n-- >>> string_sequence(5)\n-- '0 1 2 3 4 5'\nlocal function string_sequence(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_15_string_sequence.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = string_sequence\n    lu.assertEquals(candidate(0), '0')\n    lu.assertEquals(candidate(3), '0 1 2 3')\n    lu.assertEquals(candidate(10), '0 1 2 3 4 5 6 7 8 9 10')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_15_string_sequence", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = string_sequence\n    lu.assertEquals(candidate(0), '0')\n    lu.assertEquals(candidate(3), '0 1 2 3')\n    lu.assertEquals(candidate(10), '0 1 2 3 4 5 6 7 8 9 10')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_154_cycpattern_check", "language": "lua", "prompt": "-- You are given 2 words. You need to return true if the second word or any of its rotations is a substring in the first word\n-- >>> cycpattern_check('abcd', 'abd')\n-- false\n-- >>> cycpattern_check('hello', 'ell')\n-- true\n-- >>> cycpattern_check('whassup', 'psus')\n-- false\n-- >>> cycpattern_check('abab', 'baa')\n-- true\n-- >>> cycpattern_check('efef', 'eeff')\n-- false\n-- >>> cycpattern_check('himenss', 'simen')\n-- true\nlocal function cycpattern_check(a, b)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_154_cycpattern_check.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = cycpattern_check\n    lu.assertEquals(candidate('xyzw', 'xyw'), false)\n    lu.assertEquals(candidate('yello', 'ell'), true)\n    lu.assertEquals(candidate('whattup', 'ptut'), false)\n    lu.assertEquals(candidate('efef', 'fee'), true)\n    lu.assertEquals(candidate('abab', 'aabb'), false)\n    lu.assertEquals(candidate('winemtt', 'tinem'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_154_cycpattern_check", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = cycpattern_check\n    lu.assertEquals(candidate('xyzw', 'xyw'), false)\n    lu.assertEquals(candidate('yello', 'ell'), true)\n    lu.assertEquals(candidate('whattup', 'ptut'), false)\n    lu.assertEquals(candidate('efef', 'fee'), true)\n    lu.assertEquals(candidate('abab', 'aabb'), false)\n    lu.assertEquals(candidate('winemtt', 'tinem'), true)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_57_monotonic", "language": "lua", "prompt": "-- Return true is table elements are monotonically increasing or decreasing.\n-- >>> monotonic({1, 2, 4, 20})\n-- true\n-- >>> monotonic({1, 20, 4, 10})\n-- false\n-- >>> monotonic({4, 1, 0, -10})\n-- true\nlocal function monotonic(l)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_57_monotonic.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = monotonic\n    lu.assertEquals(candidate({1, 2, 4, 10}), true)\n    lu.assertEquals(candidate({1, 2, 4, 20}), true)\n    lu.assertEquals(candidate({1, 20, 4, 10}), false)\n    lu.assertEquals(candidate({4, 1, 0, -10}), true)\n    lu.assertEquals(candidate({4, 1, 1, 0}), true)\n    lu.assertEquals(candidate({1, 2, 3, 2, 5, 60}), false)\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 60}), true)\n    lu.assertEquals(candidate({9, 9, 9, 9}), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_57_monotonic", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = monotonic\n    lu.assertEquals(candidate({1, 2, 4, 10}), true)\n    lu.assertEquals(candidate({1, 2, 4, 20}), true)\n    lu.assertEquals(candidate({1, 20, 4, 10}), false)\n    lu.assertEquals(candidate({4, 1, 0, -10}), true)\n    lu.assertEquals(candidate({4, 1, 1, 0}), true)\n    lu.assertEquals(candidate({1, 2, 3, 2, 5, 60}), false)\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 60}), true)\n    lu.assertEquals(candidate({9, 9, 9, 9}), true)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_12_longest", "language": "lua", "prompt": "-- Out of table of strings, return the longest one. Return the first one in case of multiple\n-- strings of the same length. Return None in case the input table is empty.\n-- >>> longest({})\n-- None\n-- >>> longest({'a', 'b', 'c'})\n-- 'a'\n-- >>> longest({'a', 'bb', 'ccc'})\n-- 'ccc'\nlocal function longest(strings)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_12_longest.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = longest\n    lu.assertEquals(candidate({}), None)\n    lu.assertEquals(candidate({'x', 'y', 'z'}), 'x')\n    lu.assertEquals(candidate({'x', 'yyy', 'zzzz', 'www', 'kkkk', 'abc'}), 'zzzz')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_12_longest", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = longest\n    lu.assertEquals(candidate({}), None)\n    lu.assertEquals(candidate({'x', 'y', 'z'}), 'x')\n    lu.assertEquals(candidate({'x', 'yyy', 'zzzz', 'www', 'kkkk', 'abc'}), 'zzzz')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_52_below_threshold", "language": "lua", "prompt": "-- Return true if all numbers in the table l are below threshold t.\n-- >>> below_threshold({1, 2, 4, 10}, 100)\n-- true\n-- >>> below_threshold({1, 20, 4, 10}, 5)\n-- false\nlocal function below_threshold(l, t)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_52_below_threshold.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = below_threshold\n    lu.assertEquals(candidate({1, 2, 4, 10}, 100), true)\n    lu.assertEquals(candidate({1, 20, 4, 10}, 5), false)\n    lu.assertEquals(candidate({1, 20, 4, 10}, 21), true)\n    lu.assertEquals(candidate({1, 20, 4, 10}, 22), true)\n    lu.assertEquals(candidate({1, 8, 4, 10}, 11), true)\n    lu.assertEquals(candidate({1, 8, 4, 10}, 10), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_52_below_threshold", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = below_threshold\n    lu.assertEquals(candidate({1, 2, 4, 10}, 100), true)\n    lu.assertEquals(candidate({1, 20, 4, 10}, 5), false)\n    lu.assertEquals(candidate({1, 20, 4, 10}, 21), true)\n    lu.assertEquals(candidate({1, 20, 4, 10}, 22), true)\n    lu.assertEquals(candidate({1, 8, 4, 10}, 11), true)\n    lu.assertEquals(candidate({1, 8, 4, 10}, 10), false)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_75_is_multiply_prime", "language": "lua", "prompt": "-- Write a function that returns true if the given number is the multiplication of 3 prime numbers\n-- and false otherwise.\n-- Knowing that (a) is less then 100. \n-- Example:\n-- >>> is_multiply_prime(30)\n-- true\n-- 30 = 2 * 3 * 5\nlocal function is_multiply_prime(a)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_75_is_multiply_prime.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_multiply_prime\n    lu.assertEquals(candidate(5), false)\n    lu.assertEquals(candidate(30), true)\n    lu.assertEquals(candidate(8), true)\n    lu.assertEquals(candidate(10), false)\n    lu.assertEquals(candidate(125), true)\n    lu.assertEquals(candidate(105), true)\n    lu.assertEquals(candidate(126), false)\n    lu.assertEquals(candidate(729), false)\n    lu.assertEquals(candidate(891), false)\n    lu.assertEquals(candidate(1001), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_75_is_multiply_prime", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_multiply_prime\n    lu.assertEquals(candidate(5), false)\n    lu.assertEquals(candidate(30), true)\n    lu.assertEquals(candidate(8), true)\n    lu.assertEquals(candidate(10), false)\n    lu.assertEquals(candidate(125), true)\n    lu.assertEquals(candidate(105), true)\n    lu.assertEquals(candidate(126), false)\n    lu.assertEquals(candidate(729), false)\n    lu.assertEquals(candidate(891), false)\n    lu.assertEquals(candidate(1001), true)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_30_get_positive", "language": "lua", "prompt": "-- Return only positive numbers in the table.\n-- >>> get_positive({-1, 2, -4, 5, 6})\n-- {2, 5, 6}\n-- >>> get_positive({5, 3, -5, 2, -3, 3, 9, 0, 123, 1, -10})\n-- {5, 3, 2, 3, 9, 123, 1}\nlocal function get_positive(l)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_30_get_positive.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_positive\n    lu.assertEquals(candidate({-1, -2, 4, 5, 6}), {4, 5, 6})\n    lu.assertEquals(candidate({5, 3, -5, 2, 3, 3, 9, 0, 123, 1, -10}), {5, 3, 2, 3, 3, 9, 123, 1})\n    lu.assertEquals(candidate({-1, -2}), {})\n    lu.assertEquals(candidate({}), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_30_get_positive", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_positive\n    lu.assertEquals(candidate({-1, -2, 4, 5, 6}), {4, 5, 6})\n    lu.assertEquals(candidate({5, 3, -5, 2, 3, 3, 9, 0, 123, 1, -10}), {5, 3, 2, 3, 3, 9, 123, 1})\n    lu.assertEquals(candidate({-1, -2}), {})\n    lu.assertEquals(candidate({}), {})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_33_sort_third", "language": "lua", "prompt": "-- This function takes a table l and returns a table l' such that\n-- l' is identical to l in the indicies that are not divisible by three, while its values at the indicies that are divisible by three are equal\n-- to the values of the corresponding indicies of l, but sorted.\n-- >>> sort_third({1, 2, 3})\n-- {1, 2, 3}\n-- >>> sort_third({5, 6, 3, 4, 8, 9, 2})\n-- {2, 6, 3, 4, 8, 9, 5}\nlocal function sort_third(l)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_33_sort_third.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sort_third\n    lu.assertEquals(candidate({5, 6, 3, 4, 8, 9, 2}), {2, 6, 3, 4, 8, 9, 5})\n    lu.assertEquals(candidate({5, 8, 3, 4, 6, 9, 2}), {2, 8, 3, 4, 6, 9, 5})\n    lu.assertEquals(candidate({5, 6, 9, 4, 8, 3, 2}), {2, 6, 9, 4, 8, 3, 5})\n    lu.assertEquals(candidate({5, 6, 3, 4, 8, 9, 2, 1}), {2, 6, 3, 4, 8, 9, 5, 1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_33_sort_third", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sort_third\n    lu.assertEquals(candidate({5, 6, 3, 4, 8, 9, 2}), {2, 6, 3, 4, 8, 9, 5})\n    lu.assertEquals(candidate({5, 8, 3, 4, 6, 9, 2}), {2, 8, 3, 4, 6, 9, 5})\n    lu.assertEquals(candidate({5, 6, 9, 4, 8, 3, 2}), {2, 6, 9, 4, 8, 3, 5})\n    lu.assertEquals(candidate({5, 6, 3, 4, 8, 9, 2, 1}), {2, 6, 3, 4, 8, 9, 5, 1})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_6_parse_nested_parens", "language": "lua", "prompt": "-- Input to this function is a string represented multiple groups for nested parentheses separated by spaces.\n-- For each of the group, output the deepest level of nesting of parentheses.\n-- E.g. (()()) has maximum two levels of nesting while ((())) has three.\n-- >>> parse_nested_parens('(()()) ((())) () ((())()())')\n-- {2, 3, 1, 3}\nlocal function parse_nested_parens(paren_string)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_6_parse_nested_parens.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_nested_parens\n    lu.assertEquals(candidate('(()()) ((())) () ((())()())'), {2, 3, 1, 3})\n    lu.assertEquals(candidate('() (()) ((())) (((())))'), {1, 2, 3, 4})\n    lu.assertEquals(candidate('(()(())((())))'), {4})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_6_parse_nested_parens", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_nested_parens\n    lu.assertEquals(candidate('(()()) ((())) () ((())()())'), {2, 3, 1, 3})\n    lu.assertEquals(candidate('() (()) ((())) (((())))'), {1, 2, 3, 4})\n    lu.assertEquals(candidate('(()(())((())))'), {4})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_45_triangle_area", "language": "lua", "prompt": "-- Given length of a side and high return area for a triangle.\n-- >>> triangle_area(5, 3)\n-- 7.5\nlocal function triangle_area(a, h)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_45_triangle_area.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = triangle_area\n    lu.assertEquals(candidate(5, 3), 7.5)\n    lu.assertEquals(candidate(2, 2), 2.0)\n    lu.assertEquals(candidate(10, 8), 40.0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_45_triangle_area", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = triangle_area\n    lu.assertEquals(candidate(5, 3), 7.5)\n    lu.assertEquals(candidate(2, 2), 2.0)\n    lu.assertEquals(candidate(10, 8), 40.0)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_97_multiply", "language": "lua", "prompt": "-- Complete the function that takes two integers and returns \n-- the product of their unit digits.\n-- Assume the input is always valid.\n-- Examples:\n-- >>> multiply(148, 412)\n-- 16\n-- >>> multiply(19, 28)\n-- 72\n-- >>> multiply(2020, 1851)\n-- 0\n-- >>> multiply(14, -15)\n-- 20\nlocal function multiply(a, b)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_97_multiply.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = multiply\n    lu.assertEquals(candidate(148, 412), 16)\n    lu.assertEquals(candidate(19, 28), 72)\n    lu.assertEquals(candidate(2020, 1851), 0)\n    lu.assertEquals(candidate(14, -15), 20)\n    lu.assertEquals(candidate(76, 67), 42)\n    lu.assertEquals(candidate(17, 27), 49)\n    lu.assertEquals(candidate(0, 1), 0)\n    lu.assertEquals(candidate(0, 0), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_97_multiply", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = multiply\n    lu.assertEquals(candidate(148, 412), 16)\n    lu.assertEquals(candidate(19, 28), 72)\n    lu.assertEquals(candidate(2020, 1851), 0)\n    lu.assertEquals(candidate(14, -15), 20)\n    lu.assertEquals(candidate(76, 67), 42)\n    lu.assertEquals(candidate(17, 27), 49)\n    lu.assertEquals(candidate(0, 1), 0)\n    lu.assertEquals(candidate(0, 0), 0)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_4_mean_absolute_deviation", "language": "lua", "prompt": "-- For a given table of input numbers, calculate Mean Absolute Deviation\n-- around the mean of this dataset.\n-- Mean Absolute Deviation is the average absolute difference between each\n-- element and a centerpoint (mean in this case):\n-- MAD = average | x - x_mean |\n-- >>> mean_absolute_deviation({1.0, 2.0, 3.0, 4.0})\n-- 1.0\nlocal function mean_absolute_deviation(numbers)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_4_mean_absolute_deviation.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = mean_absolute_deviation\n    lu.assertEquals(candidate({1.0, 2.0}), 0.5)\n    lu.assertEquals(candidate({1.0, 2.0, 3.0, 4.0}), 1.0)\n    lu.assertEquals(candidate({1.0, 2.0, 3.0, 4.0, 5.0}), 1.2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_4_mean_absolute_deviation", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = mean_absolute_deviation\n    lu.assertEquals(candidate({1.0, 2.0}), 0.5)\n    lu.assertEquals(candidate({1.0, 2.0, 3.0, 4.0}), 1.0)\n    lu.assertEquals(candidate({1.0, 2.0, 3.0, 4.0, 5.0}), 1.2)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_58_common", "language": "lua", "prompt": "-- Return sorted unique common elements for two tables.\n-- >>> common({1, 4, 3, 34, 653, 2, 5}, {5, 7, 1, 5, 9, 653, 121})\n-- {1, 5, 653}\n-- >>> common({5, 3, 2, 8}, {3, 2})\n-- {2, 3}\nlocal function common(l1, l2)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_58_common.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = common\n    lu.assertEquals(candidate({1, 4, 3, 34, 653, 2, 5}, {5, 7, 1, 5, 9, 653, 121}), {1, 5, 653})\n    lu.assertEquals(candidate({5, 3, 2, 8}, {3, 2}), {2, 3})\n    lu.assertEquals(candidate({4, 3, 2, 8}, {3, 2, 4}), {2, 3, 4})\n    lu.assertEquals(candidate({4, 3, 2, 8}, {}), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_58_common", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = common\n    lu.assertEquals(candidate({1, 4, 3, 34, 653, 2, 5}, {5, 7, 1, 5, 9, 653, 121}), {1, 5, 653})\n    lu.assertEquals(candidate({5, 3, 2, 8}, {3, 2}), {2, 3})\n    lu.assertEquals(candidate({4, 3, 2, 8}, {3, 2, 4}), {2, 3, 4})\n    lu.assertEquals(candidate({4, 3, 2, 8}, {}), {})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_156_int_to_mini_roman", "language": "lua", "prompt": "-- Given a positive integer, obtain its roman numeral equivalent as a string,\n-- and return it in lowercase.\n-- Restrictions: 1 <= num <= 1000\n-- Examples:\n-- >>> int_to_mini_roman(19)\n-- 'xix'\n-- >>> int_to_mini_roman(152)\n-- 'clii'\n-- >>> int_to_mini_roman(426)\n-- 'cdxxvi'\nlocal function int_to_mini_roman(number)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_156_int_to_mini_roman.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = int_to_mini_roman\n    lu.assertEquals(candidate(19), 'xix')\n    lu.assertEquals(candidate(152), 'clii')\n    lu.assertEquals(candidate(251), 'ccli')\n    lu.assertEquals(candidate(426), 'cdxxvi')\n    lu.assertEquals(candidate(500), 'd')\n    lu.assertEquals(candidate(1), 'i')\n    lu.assertEquals(candidate(4), 'iv')\n    lu.assertEquals(candidate(43), 'xliii')\n    lu.assertEquals(candidate(90), 'xc')\n    lu.assertEquals(candidate(94), 'xciv')\n    lu.assertEquals(candidate(532), 'dxxxii')\n    lu.assertEquals(candidate(900), 'cm')\n    lu.assertEquals(candidate(994), 'cmxciv')\n    lu.assertEquals(candidate(1000), 'm')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_156_int_to_mini_roman", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = int_to_mini_roman\n    lu.assertEquals(candidate(19), 'xix')\n    lu.assertEquals(candidate(152), 'clii')\n    lu.assertEquals(candidate(251), 'ccli')\n    lu.assertEquals(candidate(426), 'cdxxvi')\n    lu.assertEquals(candidate(500), 'd')\n    lu.assertEquals(candidate(1), 'i')\n    lu.assertEquals(candidate(4), 'iv')\n    lu.assertEquals(candidate(43), 'xliii')\n    lu.assertEquals(candidate(90), 'xc')\n    lu.assertEquals(candidate(94), 'xciv')\n    lu.assertEquals(candidate(532), 'dxxxii')\n    lu.assertEquals(candidate(900), 'cm')\n    lu.assertEquals(candidate(994), 'cmxciv')\n    lu.assertEquals(candidate(1000), 'm')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_67_fruit_distribution", "language": "lua", "prompt": "-- In this task, you will be given a string that represents a number of apples and oranges \n-- that are distributed in a basket of fruit this basket contains \n-- apples, oranges, and mango fruits. Given the string that represents the total number of \n-- the oranges and apples and an integer that represent the total number of the fruits \n-- in the basket return the number of the mango fruits in the basket.\n-- for examble:\n-- >>> fruit_distribution('5 apples and 6 oranges', 19)\n-- 8\n-- >>> fruit_distribution('0 apples and 1 oranges', 3)\n-- 2\n-- >>> fruit_distribution('2 apples and 3 oranges', 100)\n-- 95\n-- >>> fruit_distribution('100 apples and 1 oranges', 120)\n-- 19\nlocal function fruit_distribution(s, n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_67_fruit_distribution.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fruit_distribution\n    lu.assertEquals(candidate('5 apples and 6 oranges', 19), 8)\n    lu.assertEquals(candidate('5 apples and 6 oranges', 21), 10)\n    lu.assertEquals(candidate('0 apples and 1 oranges', 3), 2)\n    lu.assertEquals(candidate('1 apples and 0 oranges', 3), 2)\n    lu.assertEquals(candidate('2 apples and 3 oranges', 100), 95)\n    lu.assertEquals(candidate('2 apples and 3 oranges', 5), 0)\n    lu.assertEquals(candidate('1 apples and 100 oranges', 120), 19)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_67_fruit_distribution", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fruit_distribution\n    lu.assertEquals(candidate('5 apples and 6 oranges', 19), 8)\n    lu.assertEquals(candidate('5 apples and 6 oranges', 21), 10)\n    lu.assertEquals(candidate('0 apples and 1 oranges', 3), 2)\n    lu.assertEquals(candidate('1 apples and 0 oranges', 3), 2)\n    lu.assertEquals(candidate('2 apples and 3 oranges', 100), 95)\n    lu.assertEquals(candidate('2 apples and 3 oranges', 5), 0)\n    lu.assertEquals(candidate('1 apples and 100 oranges', 120), 19)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_112_reverse_delete", "language": "lua", "prompt": "-- Task\n-- We are given two strings s and c, you have to deleted all the characters in s that are equal to any character in c\n-- then check if the result string is palindrome.\n-- A string is called palindrome if it reads the same backward as forward.\n-- You should return a table containing the result string and true/false for the check.\n-- Example\n-- >>> reverse_delete('abcde', 'ae')\n-- {'bcd', false}\n-- >>> reverse_delete('abcdef', 'b')\n-- {'acdef', false}\n-- >>> reverse_delete('abcdedcba', 'ab')\n-- {'cdedc', true}\nlocal function reverse_delete(s, c)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_112_reverse_delete.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = reverse_delete\n    lu.assertEquals(candidate('abcde', 'ae'), {'bcd', false})\n    lu.assertEquals(candidate('abcdef', 'b'), {'acdef', false})\n    lu.assertEquals(candidate('abcdedcba', 'ab'), {'cdedc', true})\n    lu.assertEquals(candidate('dwik', 'w'), {'dik', false})\n    lu.assertEquals(candidate('a', 'a'), {'', true})\n    lu.assertEquals(candidate('abcdedcba', ''), {'abcdedcba', true})\n    lu.assertEquals(candidate('abcdedcba', 'v'), {'abcdedcba', true})\n    lu.assertEquals(candidate('vabba', 'v'), {'abba', true})\n    lu.assertEquals(candidate('mamma', 'mia'), {'', true})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_112_reverse_delete", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = reverse_delete\n    lu.assertEquals(candidate('abcde', 'ae'), {'bcd', false})\n    lu.assertEquals(candidate('abcdef', 'b'), {'acdef', false})\n    lu.assertEquals(candidate('abcdedcba', 'ab'), {'cdedc', true})\n    lu.assertEquals(candidate('dwik', 'w'), {'dik', false})\n    lu.assertEquals(candidate('a', 'a'), {'', true})\n    lu.assertEquals(candidate('abcdedcba', ''), {'abcdedcba', true})\n    lu.assertEquals(candidate('abcdedcba', 'v'), {'abcdedcba', true})\n    lu.assertEquals(candidate('vabba', 'v'), {'abba', true})\n    lu.assertEquals(candidate('mamma', 'mia'), {'', true})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_13_greatest_common_divisor", "language": "lua", "prompt": "-- Return a greatest common divisor of two integers a and b\n-- >>> greatest_common_divisor(3, 5)\n-- 1\n-- >>> greatest_common_divisor(25, 15)\n-- 5\nlocal function greatest_common_divisor(a, b)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_13_greatest_common_divisor.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = greatest_common_divisor\n    lu.assertEquals(candidate(3, 7), 1)\n    lu.assertEquals(candidate(10, 15), 5)\n    lu.assertEquals(candidate(49, 14), 7)\n    lu.assertEquals(candidate(144, 60), 12)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_13_greatest_common_divisor", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = greatest_common_divisor\n    lu.assertEquals(candidate(3, 7), 1)\n    lu.assertEquals(candidate(10, 15), 5)\n    lu.assertEquals(candidate(49, 14), 7)\n    lu.assertEquals(candidate(144, 60), 12)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_125_split_words", "language": "lua", "prompt": "-- Given a string of words, return a table of words split on whitespace, if no whitespaces exists in the text you\n-- should split on commas ',' if no commas exists you should return the number of lower-case letters with odd order in the\n-- alphabet, ord('a') = 0, ord('b') = 1, ... ord('z') = 25\n-- Examples\n-- >>> split_words('Hello world!')\n-- {'Hello', 'world!'}\n-- >>> split_words('Hello,world!')\n-- {'Hello', 'world!'}\n-- >>> split_words('abcdef')\n-- 3\nlocal function split_words(txt)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_125_split_words.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = split_words\n    lu.assertEquals(candidate('Hello world!'), {'Hello', 'world!'})\n    lu.assertEquals(candidate('Hello,world!'), {'Hello', 'world!'})\n    lu.assertEquals(candidate('Hello world,!'), {'Hello', 'world,!'})\n    lu.assertEquals(candidate('Hello,Hello,world !'), {'Hello,Hello,world', '!'})\n    lu.assertEquals(candidate('abcdef'), 3)\n    lu.assertEquals(candidate('aaabb'), 2)\n    lu.assertEquals(candidate('aaaBb'), 1)\n    lu.assertEquals(candidate(''), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_125_split_words", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = split_words\n    lu.assertEquals(candidate('Hello world!'), {'Hello', 'world!'})\n    lu.assertEquals(candidate('Hello,world!'), {'Hello', 'world!'})\n    lu.assertEquals(candidate('Hello world,!'), {'Hello', 'world,!'})\n    lu.assertEquals(candidate('Hello,Hello,world !'), {'Hello,Hello,world', '!'})\n    lu.assertEquals(candidate('abcdef'), 3)\n    lu.assertEquals(candidate('aaabb'), 2)\n    lu.assertEquals(candidate('aaaBb'), 1)\n    lu.assertEquals(candidate(''), 0)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_116_sort_array", "language": "lua", "prompt": "-- In this Kata, you have to sort a table of non-negative integers according to\n-- number of ones in their binary representation in ascending order.\n-- For similar number of ones, sort based on decimal value.\n-- It must be implemented like this:\n-- >>> sort_array({1, 5, 2, 3, 4})\n-- {1, 2, 3, 4, 5}\n-- >>> sort_array({-2, -3, -4, -5, -6})\n-- {-6, -5, -4, -3, -2}\n-- >>> sort_array({1, 0, 2, 3, 4})\n-- {0, 1, 2, 3, 4}\nlocal function sort_array(arr)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_116_sort_array.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sort_array\n    lu.assertEquals(candidate({1, 5, 2, 3, 4}), {1, 2, 4, 3, 5})\n    lu.assertEquals(candidate({-2, -3, -4, -5, -6}), {-4, -2, -6, -5, -3})\n    lu.assertEquals(candidate({1, 0, 2, 3, 4}), {0, 1, 2, 4, 3})\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({2, 5, 77, 4, 5, 3, 5, 7, 2, 3, 4}), {2, 2, 4, 4, 3, 3, 5, 5, 5, 7, 77})\n    lu.assertEquals(candidate({3, 6, 44, 12, 32, 5}), {32, 3, 5, 6, 12, 44})\n    lu.assertEquals(candidate({2, 4, 8, 16, 32}), {2, 4, 8, 16, 32})\n    lu.assertEquals(candidate({2, 4, 8, 16, 32}), {2, 4, 8, 16, 32})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_116_sort_array", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sort_array\n    lu.assertEquals(candidate({1, 5, 2, 3, 4}), {1, 2, 4, 3, 5})\n    lu.assertEquals(candidate({-2, -3, -4, -5, -6}), {-4, -2, -6, -5, -3})\n    lu.assertEquals(candidate({1, 0, 2, 3, 4}), {0, 1, 2, 4, 3})\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({2, 5, 77, 4, 5, 3, 5, 7, 2, 3, 4}), {2, 2, 4, 4, 3, 3, 5, 5, 5, 7, 77})\n    lu.assertEquals(candidate({3, 6, 44, 12, 32, 5}), {32, 3, 5, 6, 12, 44})\n    lu.assertEquals(candidate({2, 4, 8, 16, 32}), {2, 4, 8, 16, 32})\n    lu.assertEquals(candidate({2, 4, 8, 16, 32}), {2, 4, 8, 16, 32})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_28_concatenate", "language": "lua", "prompt": "-- Concatenate table of strings into a single string\n-- >>> concatenate({})\n-- ''\n-- >>> concatenate({'a', 'b', 'c'})\n-- 'abc'\nlocal function concatenate(strings)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_28_concatenate.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = concatenate\n    lu.assertEquals(candidate({}), '')\n    lu.assertEquals(candidate({'x', 'y', 'z'}), 'xyz')\n    lu.assertEquals(candidate({'x', 'y', 'z', 'w', 'k'}), 'xyzwk')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_28_concatenate", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = concatenate\n    lu.assertEquals(candidate({}), '')\n    lu.assertEquals(candidate({'x', 'y', 'z'}), 'xyz')\n    lu.assertEquals(candidate({'x', 'y', 'z', 'w', 'k'}), 'xyzwk')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_149_sorted_list_sum", "language": "lua", "prompt": "-- Write a function that accepts a table of strings as a parameter,\n-- deletes the strings that have odd lengths from it,\n-- and returns the resulted table with a sorted order,\n-- The table is always a table of strings and never a table of numbers,\n-- and it may contain duplicates.\n-- The order of the table should be ascending by length of each word, and you\n-- should return the table sorted by that rule.\n-- If two words have the same length, sort the table alphabetically.\n-- The function should return a table of strings in sorted order.\n-- You may assume that all words will have the same length.\n-- For example:\n-- >>> list_sort({'aa', 'a', 'aaa'})\n-- {'aa'}\n-- >>> list_sort({'ab', 'a', 'aaa', 'cd'})\n-- {'ab', 'cd'}\nlocal function sorted_list_sum(lst)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_149_sorted_list_sum.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sorted_list_sum\n    lu.assertEquals(candidate({'aa', 'a', 'aaa'}), {'aa'})\n    lu.assertEquals(candidate({'school', 'AI', 'asdf', 'b'}), {'AI', 'asdf', 'school'})\n    lu.assertEquals(candidate({'d', 'b', 'c', 'a'}), {})\n    lu.assertEquals(candidate({'d', 'dcba', 'abcd', 'a'}), {'abcd', 'dcba'})\n    lu.assertEquals(candidate({'AI', 'ai', 'au'}), {'AI', 'ai', 'au'})\n    lu.assertEquals(candidate({'a', 'b', 'b', 'c', 'c', 'a'}), {})\n    lu.assertEquals(candidate({'aaaa', 'bbbb', 'dd', 'cc'}), {'cc', 'dd', 'aaaa', 'bbbb'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_149_sorted_list_sum", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sorted_list_sum\n    lu.assertEquals(candidate({'aa', 'a', 'aaa'}), {'aa'})\n    lu.assertEquals(candidate({'school', 'AI', 'asdf', 'b'}), {'AI', 'asdf', 'school'})\n    lu.assertEquals(candidate({'d', 'b', 'c', 'a'}), {})\n    lu.assertEquals(candidate({'d', 'dcba', 'abcd', 'a'}), {'abcd', 'dcba'})\n    lu.assertEquals(candidate({'AI', 'ai', 'au'}), {'AI', 'ai', 'au'})\n    lu.assertEquals(candidate({'a', 'b', 'b', 'c', 'c', 'a'}), {})\n    lu.assertEquals(candidate({'aaaa', 'bbbb', 'dd', 'cc'}), {'cc', 'dd', 'aaaa', 'bbbb'})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_7_filter_by_substring", "language": "lua", "prompt": "-- Filter an input table of strings only for ones that contain given substring\n-- >>> filter_by_substring({}, 'a')\n-- {}\n-- >>> filter_by_substring({'abc', 'bacd', 'cde', 'array'}, 'a')\n-- {'abc', 'bacd', 'array'}\nlocal function filter_by_substring(strings, substring)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_7_filter_by_substring.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = filter_by_substring\n    lu.assertEquals(candidate({}, 'john'), {})\n    lu.assertEquals(candidate({'xxx', 'asd', 'xxy', 'john doe', 'xxxAAA', 'xxx'}, 'xxx'), {'xxx', 'xxxAAA', 'xxx'})\n    lu.assertEquals(candidate({'xxx', 'asd', 'aaaxxy', 'john doe', 'xxxAAA', 'xxx'}, 'xx'), {'xxx', 'aaaxxy', 'xxxAAA', 'xxx'})\n    lu.assertEquals(candidate({'grunt', 'trumpet', 'prune', 'gruesome'}, 'run'), {'grunt', 'prune'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_7_filter_by_substring", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = filter_by_substring\n    lu.assertEquals(candidate({}, 'john'), {})\n    lu.assertEquals(candidate({'xxx', 'asd', 'xxy', 'john doe', 'xxxAAA', 'xxx'}, 'xxx'), {'xxx', 'xxxAAA', 'xxx'})\n    lu.assertEquals(candidate({'xxx', 'asd', 'aaaxxy', 'john doe', 'xxxAAA', 'xxx'}, 'xx'), {'xxx', 'aaaxxy', 'xxxAAA', 'xxx'})\n    lu.assertEquals(candidate({'grunt', 'trumpet', 'prune', 'gruesome'}, 'run'), {'grunt', 'prune'})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_99_closest_integer", "language": "lua", "prompt": "-- Create a function that takes a value (string) representing a number\n-- and returns the closest integer to it. If the number is equidistant\n-- from two integers, round it away from zero.\n-- Examples\n-- >>> closest_integer('10')\n-- 10\n-- >>> closest_integer('15.3')\n-- 15\n-- Note:\n-- Rounding away from zero means that if the given number is equidistant\n-- from two integers, the one you should return is the one that is the\n-- farthest from zero. For example closest_integer(\"14.5\") should\n-- return 15 and closest_integer(\"-14.5\") should return -15.\nlocal function closest_integer(value)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_99_closest_integer.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = closest_integer\n    lu.assertEquals(candidate('10'), 10)\n    lu.assertEquals(candidate('14.5'), 15)\n    lu.assertEquals(candidate('-15.5'), -16)\n    lu.assertEquals(candidate('15.3'), 15)\n    lu.assertEquals(candidate('0'), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_99_closest_integer", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = closest_integer\n    lu.assertEquals(candidate('10'), 10)\n    lu.assertEquals(candidate('14.5'), 15)\n    lu.assertEquals(candidate('-15.5'), -16)\n    lu.assertEquals(candidate('15.3'), 15)\n    lu.assertEquals(candidate('0'), 0)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_64_vowels_count", "language": "lua", "prompt": "-- Write a function vowels_count which takes a string representing\n-- a word as input and returns the number of vowels in the string.\n-- Vowels in this case are 'a', 'e', 'i', 'o', 'u'. Here, 'y' is also a\n-- vowel, but only when it is at the end of the given word.\n-- Example:\n-- >>> vowels_count('abcde')\n-- 2\n-- >>> vowels_count('ACEDY')\n-- 3\nlocal function vowels_count(s)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_64_vowels_count.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = vowels_count\n    lu.assertEquals(candidate('abcde'), 2)\n    lu.assertEquals(candidate('Alone'), 3)\n    lu.assertEquals(candidate('key'), 2)\n    lu.assertEquals(candidate('bye'), 1)\n    lu.assertEquals(candidate('keY'), 2)\n    lu.assertEquals(candidate('bYe'), 1)\n    lu.assertEquals(candidate('ACEDY'), 3)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_64_vowels_count", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = vowels_count\n    lu.assertEquals(candidate('abcde'), 2)\n    lu.assertEquals(candidate('Alone'), 3)\n    lu.assertEquals(candidate('key'), 2)\n    lu.assertEquals(candidate('bye'), 1)\n    lu.assertEquals(candidate('keY'), 2)\n    lu.assertEquals(candidate('bYe'), 1)\n    lu.assertEquals(candidate('ACEDY'), 3)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_158_find_max", "language": "lua", "prompt": "-- Write a function that accepts a table of strings.\n-- The table contains different words. Return the word with maximum number\n-- of unique characters. If multiple strings have maximum number of unique\n-- characters, return the one which comes first in lexicographical order.\n-- >>> find_max({'name', 'of', 'string'})\n-- 'string'\n-- >>> find_max({'name', 'enam', 'game'})\n-- 'enam'\n-- >>> find_max({'aaaaaaa', 'bb', 'cc'})\n-- 'aaaaaaa'\nlocal function find_max(words)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_158_find_max.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = find_max\n    lu.assertEquals(candidate({'name', 'of', 'string'}), 'string')\n    lu.assertEquals(candidate({'name', 'enam', 'game'}), 'enam')\n    lu.assertEquals(candidate({'aaaaaaa', 'bb', 'cc'}), 'aaaaaaa')\n    lu.assertEquals(candidate({'abc', 'cba'}), 'abc')\n    lu.assertEquals(candidate({'play', 'this', 'game', 'of', 'footbott'}), 'footbott')\n    lu.assertEquals(candidate({'we', 'are', 'gonna', 'rock'}), 'gonna')\n    lu.assertEquals(candidate({'we', 'are', 'a', 'mad', 'nation'}), 'nation')\n    lu.assertEquals(candidate({'this', 'is', 'a', 'prrk'}), 'this')\n    lu.assertEquals(candidate({'b'}), 'b')\n    lu.assertEquals(candidate({'play', 'play', 'play'}), 'play')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_158_find_max", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = find_max\n    lu.assertEquals(candidate({'name', 'of', 'string'}), 'string')\n    lu.assertEquals(candidate({'name', 'enam', 'game'}), 'enam')\n    lu.assertEquals(candidate({'aaaaaaa', 'bb', 'cc'}), 'aaaaaaa')\n    lu.assertEquals(candidate({'abc', 'cba'}), 'abc')\n    lu.assertEquals(candidate({'play', 'this', 'game', 'of', 'footbott'}), 'footbott')\n    lu.assertEquals(candidate({'we', 'are', 'gonna', 'rock'}), 'gonna')\n    lu.assertEquals(candidate({'we', 'are', 'a', 'mad', 'nation'}), 'nation')\n    lu.assertEquals(candidate({'this', 'is', 'a', 'prrk'}), 'this')\n    lu.assertEquals(candidate({'b'}), 'b')\n    lu.assertEquals(candidate({'play', 'play', 'play'}), 'play')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_162_string_to_md5", "language": "lua", "prompt": "-- Given a string 'text', return its md5 hash equivalent string.\n-- If 'text' is an empty string, return None.\n-- >>> string_to_md5('Hello world')\n-- '3e25960a79dbc69b674cd4ec67a72c62'\nlocal function string_to_md5(text)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_162_string_to_md5.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = string_to_md5\n    lu.assertEquals(candidate('Hello world'), '3e25960a79dbc69b674cd4ec67a72c62')\n    lu.assertEquals(candidate(''), None)\n    lu.assertEquals(candidate('A B C'), '0ef78513b0cb8cef12743f5aeb35f888')\n    lu.assertEquals(candidate('password'), '5f4dcc3b5aa765d61d8327deb882cf99')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_162_string_to_md5", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = string_to_md5\n    lu.assertEquals(candidate('Hello world'), '3e25960a79dbc69b674cd4ec67a72c62')\n    lu.assertEquals(candidate(''), None)\n    lu.assertEquals(candidate('A B C'), '0ef78513b0cb8cef12743f5aeb35f888')\n    lu.assertEquals(candidate('password'), '5f4dcc3b5aa765d61d8327deb882cf99')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_44_change_base", "language": "lua", "prompt": "-- Change numerical base of input number x to base.\n-- return string representation after the conversion.\n-- base numbers are less than 10.\n-- >>> change_base(8, 3)\n-- '22'\n-- >>> change_base(8, 2)\n-- '1000'\n-- >>> change_base(7, 2)\n-- '111'\nlocal function change_base(x, base)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_44_change_base.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = change_base\n    lu.assertEquals(candidate(8, 3), '22')\n    lu.assertEquals(candidate(9, 3), '100')\n    lu.assertEquals(candidate(234, 2), '11101010')\n    lu.assertEquals(candidate(16, 2), '10000')\n    lu.assertEquals(candidate(8, 2), '1000')\n    lu.assertEquals(candidate(7, 2), '111')\n    lu.assertEquals(candidate(2, 3), '2')\n    lu.assertEquals(candidate(3, 4), '3')\n    lu.assertEquals(candidate(4, 5), '4')\n    lu.assertEquals(candidate(5, 6), '5')\n    lu.assertEquals(candidate(6, 7), '6')\n    lu.assertEquals(candidate(7, 8), '7')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_44_change_base", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = change_base\n    lu.assertEquals(candidate(8, 3), '22')\n    lu.assertEquals(candidate(9, 3), '100')\n    lu.assertEquals(candidate(234, 2), '11101010')\n    lu.assertEquals(candidate(16, 2), '10000')\n    lu.assertEquals(candidate(8, 2), '1000')\n    lu.assertEquals(candidate(7, 2), '111')\n    lu.assertEquals(candidate(2, 3), '2')\n    lu.assertEquals(candidate(3, 4), '3')\n    lu.assertEquals(candidate(4, 5), '4')\n    lu.assertEquals(candidate(5, 6), '5')\n    lu.assertEquals(candidate(6, 7), '6')\n    lu.assertEquals(candidate(7, 8), '7')\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_157_right_angle_triangle", "language": "lua", "prompt": "-- Given the lengths of the three sides of a triangle. Return true if the three\n-- sides form a right-angled triangle, false otherwise.\n-- A right-angled triangle is a triangle in which one angle is right angle or \n-- 90 degree.\n-- Example:\n-- >>> right_angle_triangle(3, 4, 5)\n-- true\n-- >>> right_angle_triangle(1, 2, 3)\n-- false\nlocal function right_angle_triangle(a, b, c)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_157_right_angle_triangle.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = right_angle_triangle\n    lu.assertEquals(candidate(3, 4, 5), true)\n    lu.assertEquals(candidate(1, 2, 3), false)\n    lu.assertEquals(candidate(10, 6, 8), true)\n    lu.assertEquals(candidate(2, 2, 2), false)\n    lu.assertEquals(candidate(7, 24, 25), true)\n    lu.assertEquals(candidate(10, 5, 7), false)\n    lu.assertEquals(candidate(5, 12, 13), true)\n    lu.assertEquals(candidate(15, 8, 17), true)\n    lu.assertEquals(candidate(48, 55, 73), true)\n    lu.assertEquals(candidate(1, 1, 1), false)\n    lu.assertEquals(candidate(2, 2, 10), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_157_right_angle_triangle", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = right_angle_triangle\n    lu.assertEquals(candidate(3, 4, 5), true)\n    lu.assertEquals(candidate(1, 2, 3), false)\n    lu.assertEquals(candidate(10, 6, 8), true)\n    lu.assertEquals(candidate(2, 2, 2), false)\n    lu.assertEquals(candidate(7, 24, 25), true)\n    lu.assertEquals(candidate(10, 5, 7), false)\n    lu.assertEquals(candidate(5, 12, 13), true)\n    lu.assertEquals(candidate(15, 8, 17), true)\n    lu.assertEquals(candidate(48, 55, 73), true)\n    lu.assertEquals(candidate(1, 1, 1), false)\n    lu.assertEquals(candidate(2, 2, 10), false)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_81_numerical_letter_grade", "language": "lua", "prompt": "-- It is the last week of the semester and the teacher has to give the grades\n-- to students. The teacher has been making her own algorithm for grading.\n-- The only problem is, she has lost the code she used for grading.\n-- She has given you a table of GPAs for some students and you have to write \n-- a function that can output a table of letter grades using the following table:\n-- GPA       |    Letter grade\n-- 4.0                A+\n-- > 3.7                A \n-- > 3.3                A- \n-- > 3.0                B+\n-- > 2.7                B \n-- > 2.3                B-\n-- > 2.0                C+\n-- > 1.7                C\n-- > 1.3                C-\n-- > 1.0                D+ \n-- > 0.7                D \n-- > 0.0                D-\n-- 0.0                E\n-- Example:\n-- >>> grade_equation({4.0, 3, 1.7, 2, 3.5})\n-- {'A+', 'B', 'C-', 'C', 'A-'}\nlocal function numerical_letter_grade(grades)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_81_numerical_letter_grade.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = numerical_letter_grade\n    lu.assertEquals(candidate({4.0, 3, 1.7, 2, 3.5}), {'A+', 'B', 'C-', 'C', 'A-'})\n    lu.assertEquals(candidate({1.2}), {'D+'})\n    lu.assertEquals(candidate({0.5}), {'D-'})\n    lu.assertEquals(candidate({0.0}), {'E'})\n    lu.assertEquals(candidate({1.0, 0.3, 1.5, 2.8, 3.3}), {'D', 'D-', 'C-', 'B', 'B+'})\n    lu.assertEquals(candidate({0.0, 0.7}), {'E', 'D-'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_81_numerical_letter_grade", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = numerical_letter_grade\n    lu.assertEquals(candidate({4.0, 3, 1.7, 2, 3.5}), {'A+', 'B', 'C-', 'C', 'A-'})\n    lu.assertEquals(candidate({1.2}), {'D+'})\n    lu.assertEquals(candidate({0.5}), {'D-'})\n    lu.assertEquals(candidate({0.0}), {'E'})\n    lu.assertEquals(candidate({1.0, 0.3, 1.5, 2.8, 3.3}), {'D', 'D-', 'C-', 'B', 'B+'})\n    lu.assertEquals(candidate({0.0, 0.7}), {'E', 'D-'})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_5_intersperse", "language": "lua", "prompt": "-- Insert a number 'delimeter' between every two consecutive elements of input table `numbers'\n-- >>> intersperse({}, 4)\n-- {}\n-- >>> intersperse({1, 2, 3}, 4)\n-- {1, 4, 2, 4, 3}\nlocal function intersperse(numbers, delimeter)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_5_intersperse.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = intersperse\n    lu.assertEquals(candidate({}, 7), {})\n    lu.assertEquals(candidate({5, 6, 3, 2}, 8), {5, 8, 6, 8, 3, 8, 2})\n    lu.assertEquals(candidate({2, 2, 2}, 2), {2, 2, 2, 2, 2})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_5_intersperse", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = intersperse\n    lu.assertEquals(candidate({}, 7), {})\n    lu.assertEquals(candidate({5, 6, 3, 2}, 8), {5, 8, 6, 8, 3, 8, 2})\n    lu.assertEquals(candidate({2, 2, 2}, 2), {2, 2, 2, 2, 2})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_146_specialFilter", "language": "lua", "prompt": "-- Write a function that takes a table of numbers as input and returns \n-- the number of elements in the table that are greater than 10 and both \n-- first and last digits of a number are odd (1, 3, 5, 7, 9).\n-- For example:\n-- >>> specialFilter({15, -73, 14, -15})\n-- 1\n-- >>> specialFilter({33, -2, -3, 45, 21, 109})\n-- 2\nlocal function specialFilter(nums)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_146_specialFilter.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = specialFilter\n    lu.assertEquals(candidate({5, -2, 1, -5}), 0)\n    lu.assertEquals(candidate({15, -73, 14, -15}), 1)\n    lu.assertEquals(candidate({33, -2, -3, 45, 21, 109}), 2)\n    lu.assertEquals(candidate({43, -12, 93, 125, 121, 109}), 4)\n    lu.assertEquals(candidate({71, -2, -33, 75, 21, 19}), 3)\n    lu.assertEquals(candidate({1}), 0)\n    lu.assertEquals(candidate({}), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_146_specialFilter", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = specialFilter\n    lu.assertEquals(candidate({5, -2, 1, -5}), 0)\n    lu.assertEquals(candidate({15, -73, 14, -15}), 1)\n    lu.assertEquals(candidate({33, -2, -3, 45, 21, 109}), 2)\n    lu.assertEquals(candidate({43, -12, 93, 125, 121, 109}), 4)\n    lu.assertEquals(candidate({71, -2, -33, 75, 21, 19}), 3)\n    lu.assertEquals(candidate({1}), 0)\n    lu.assertEquals(candidate({}), 0)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_60_sum_to_n", "language": "lua", "prompt": "-- sum_to_n is a function that sums numbers from 1 to n.\n-- >>> sum_to_n(30)\n-- 465\n-- >>> sum_to_n(100)\n-- 5050\n-- >>> sum_to_n(5)\n-- 15\n-- >>> sum_to_n(10)\n-- 55\n-- >>> sum_to_n(1)\n-- 1\nlocal function sum_to_n(n)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_60_sum_to_n.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sum_to_n\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(6), 21)\n    lu.assertEquals(candidate(11), 66)\n    lu.assertEquals(candidate(30), 465)\n    lu.assertEquals(candidate(100), 5050)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_60_sum_to_n", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sum_to_n\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(6), 21)\n    lu.assertEquals(candidate(11), 66)\n    lu.assertEquals(candidate(30), 465)\n    lu.assertEquals(candidate(100), 5050)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_26_remove_duplicates", "language": "lua", "prompt": "-- From a table of integers, remove all elements that occur more than once.\n-- Keep order of elements left the same as in the input.\n-- >>> remove_duplicates({1, 2, 3, 2, 4})\n-- {1, 3, 4}\nlocal function remove_duplicates(numbers)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_26_remove_duplicates.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = remove_duplicates\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({1, 2, 3, 4}), {1, 2, 3, 4})\n    lu.assertEquals(candidate({1, 2, 3, 2, 4, 3, 5}), {1, 4, 5})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_26_remove_duplicates", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = remove_duplicates\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({1, 2, 3, 4}), {1, 2, 3, 4})\n    lu.assertEquals(candidate({1, 2, 3, 2, 4, 3, 5}), {1, 4, 5})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_163_generate_integers", "language": "lua", "prompt": "-- Given two positive integers a and b, return the even digits between a\n-- and b, in ascending order.\n-- For example:\n-- >>> generate_integers(2, 8)\n-- {2, 4, 6, 8}\n-- >>> generate_integers(8, 2)\n-- {2, 4, 6, 8}\n-- >>> generate_integers(10, 14)\n-- {}\nlocal function generate_integers(a, b)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_163_generate_integers.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = generate_integers\n    lu.assertEquals(candidate(2, 10), {2, 4, 6, 8})\n    lu.assertEquals(candidate(10, 2), {2, 4, 6, 8})\n    lu.assertEquals(candidate(132, 2), {2, 4, 6, 8})\n    lu.assertEquals(candidate(17, 89), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_163_generate_integers", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = generate_integers\n    lu.assertEquals(candidate(2, 10), {2, 4, 6, 8})\n    lu.assertEquals(candidate(10, 2), {2, 4, 6, 8})\n    lu.assertEquals(candidate(132, 2), {2, 4, 6, 8})\n    lu.assertEquals(candidate(17, 89), {})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_9_rolling_max", "language": "lua", "prompt": "-- From a given table of integers, generate a table of rolling maximum element found until given moment\n-- in the sequence.\n-- >>> rolling_max({1, 2, 3, 2, 3, 4, 2})\n-- {1, 2, 3, 3, 3, 4, 4}\nlocal function rolling_max(numbers)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_9_rolling_max.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = rolling_max\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({1, 2, 3, 4}), {1, 2, 3, 4})\n    lu.assertEquals(candidate({4, 3, 2, 1}), {4, 4, 4, 4})\n    lu.assertEquals(candidate({3, 2, 3, 100, 3}), {3, 3, 3, 100, 100})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_9_rolling_max", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = rolling_max\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({1, 2, 3, 4}), {1, 2, 3, 4})\n    lu.assertEquals(candidate({4, 3, 2, 1}), {4, 4, 4, 4})\n    lu.assertEquals(candidate({3, 2, 3, 100, 3}), {3, 3, 3, 100, 100})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_3_below_zero", "language": "lua", "prompt": "-- You're given a table of deposit and withdrawal operations on a bank account that starts with\n-- zero balance. Your task is to detect if at any point the balance of account fallls below zero, and\n-- at that point function should return true. Otherwise it should return false.\n-- >>> below_zero({1, 2, 3})\n-- false\n-- >>> below_zero({1, 2, -4, 5})\n-- true\nlocal function below_zero(operations)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_3_below_zero.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = below_zero\n    lu.assertEquals(candidate({}), false)\n    lu.assertEquals(candidate({1, 2, -3, 1, 2, -3}), false)\n    lu.assertEquals(candidate({1, 2, -4, 5, 6}), true)\n    lu.assertEquals(candidate({1, -1, 2, -2, 5, -5, 4, -4}), false)\n    lu.assertEquals(candidate({1, -1, 2, -2, 5, -5, 4, -5}), true)\n    lu.assertEquals(candidate({1, -2, 2, -2, 5, -5, 4, -4}), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_3_below_zero", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = below_zero\n    lu.assertEquals(candidate({}), false)\n    lu.assertEquals(candidate({1, 2, -3, 1, 2, -3}), false)\n    lu.assertEquals(candidate({1, 2, -4, 5, 6}), true)\n    lu.assertEquals(candidate({1, -1, 2, -2, 5, -5, 4, -4}), false)\n    lu.assertEquals(candidate({1, -1, 2, -2, 5, -5, 4, -5}), true)\n    lu.assertEquals(candidate({1, -2, 2, -2, 5, -5, 4, -4}), true)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_69_search", "language": "lua", "prompt": "-- You are given a non-empty table of positive integers. Return the greatest integer that is greater than \n-- zero, and has a frequency greater than or equal to the value of the integer itself. \n-- The frequency of an integer is the number of times it appears in the table.\n-- If no such a value exist, return -1.\n-- Examples:\n-- >>> search({4, 1, 2, 2, 3, 1})\n-- 2\n-- >>> search({1, 2, 2, 3, 3, 3, 4, 4, 4})\n-- 3\n-- >>> search({5, 5, 4, 4, 4})\n-- -1\nlocal function search(lst)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_69_search.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = search\n    lu.assertEquals(candidate({5, 5, 5, 5, 1}), 1)\n    lu.assertEquals(candidate({4, 1, 4, 1, 4, 4}), 4)\n    lu.assertEquals(candidate({3, 3}), -1)\n    lu.assertEquals(candidate({8, 8, 8, 8, 8, 8, 8, 8}), 8)\n    lu.assertEquals(candidate({2, 3, 3, 2, 2}), 2)\n    lu.assertEquals(candidate({2, 7, 8, 8, 4, 8, 7, 3, 9, 6, 5, 10, 4, 3, 6, 7, 1, 7, 4, 10, 8, 1}), 1)\n    lu.assertEquals(candidate({3, 2, 8, 2}), 2)\n    lu.assertEquals(candidate({6, 7, 1, 8, 8, 10, 5, 8, 5, 3, 10}), 1)\n    lu.assertEquals(candidate({8, 8, 3, 6, 5, 6, 4}), -1)\n    lu.assertEquals(candidate({6, 9, 6, 7, 1, 4, 7, 1, 8, 8, 9, 8, 10, 10, 8, 4, 10, 4, 10, 1, 2, 9, 5, 7, 9}), 1)\n    lu.assertEquals(candidate({1, 9, 10, 1, 3}), 1)\n    lu.assertEquals(candidate({6, 9, 7, 5, 8, 7, 5, 3, 7, 5, 10, 10, 3, 6, 10, 2, 8, 6, 5, 4, 9, 5, 3, 10}), 5)\n    lu.assertEquals(candidate({1}), 1)\n    lu.assertEquals(candidate({8, 8, 10, 6, 4, 3, 5, 8, 2, 4, 2, 8, 4, 6, 10, 4, 2, 1, 10, 2, 1, 1, 5}), 4)\n    lu.assertEquals(candidate({2, 10, 4, 8, 2, 10, 5, 1, 2, 9, 5, 5, 6, 3, 8, 6, 4, 10}), 2)\n    lu.assertEquals(candidate({1, 6, 10, 1, 6, 9, 10, 8, 6, 8, 7, 3}), 1)\n    lu.assertEquals(candidate({9, 2, 4, 1, 5, 1, 5, 2, 5, 7, 7, 7, 3, 10, 1, 5, 4, 2, 8, 4, 1, 9, 10, 7, 10, 2, 8, 10, 9, 4}), 4)\n    lu.assertEquals(candidate({2, 6, 4, 2, 8, 7, 5, 6, 4, 10, 4, 6, 3, 7, 8, 8, 3, 1, 4, 2, 2, 10, 7}), 4)\n    lu.assertEquals(candidate({9, 8, 6, 10, 2, 6, 10, 2, 7, 8, 10, 3, 8, 2, 6, 2, 3, 1}), 2)\n    lu.assertEquals(candidate({5, 5, 3, 9, 5, 6, 3, 2, 8, 5, 6, 10, 10, 6, 8, 4, 10, 7, 7, 10, 8}), -1)\n    lu.assertEquals(candidate({10}), -1)\n    lu.assertEquals(candidate({9, 7, 7, 2, 4, 7, 2, 10, 9, 7, 5, 7, 2}), 2)\n    lu.assertEquals(candidate({5, 4, 10, 2, 1, 1, 10, 3, 6, 1, 8}), 1)\n    lu.assertEquals(candidate({7, 9, 9, 9, 3, 4, 1, 5, 9, 1, 2, 1, 1, 10, 7, 5, 6, 7, 6, 7, 7, 6}), 1)\n    lu.assertEquals(candidate({3, 10, 10, 9, 2}), -1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_69_search", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = search\n    lu.assertEquals(candidate({5, 5, 5, 5, 1}), 1)\n    lu.assertEquals(candidate({4, 1, 4, 1, 4, 4}), 4)\n    lu.assertEquals(candidate({3, 3}), -1)\n    lu.assertEquals(candidate({8, 8, 8, 8, 8, 8, 8, 8}), 8)\n    lu.assertEquals(candidate({2, 3, 3, 2, 2}), 2)\n    lu.assertEquals(candidate({2, 7, 8, 8, 4, 8, 7, 3, 9, 6, 5, 10, 4, 3, 6, 7, 1, 7, 4, 10, 8, 1}), 1)\n    lu.assertEquals(candidate({3, 2, 8, 2}), 2)\n    lu.assertEquals(candidate({6, 7, 1, 8, 8, 10, 5, 8, 5, 3, 10}), 1)\n    lu.assertEquals(candidate({8, 8, 3, 6, 5, 6, 4}), -1)\n    lu.assertEquals(candidate({6, 9, 6, 7, 1, 4, 7, 1, 8, 8, 9, 8, 10, 10, 8, 4, 10, 4, 10, 1, 2, 9, 5, 7, 9}), 1)\n    lu.assertEquals(candidate({1, 9, 10, 1, 3}), 1)\n    lu.assertEquals(candidate({6, 9, 7, 5, 8, 7, 5, 3, 7, 5, 10, 10, 3, 6, 10, 2, 8, 6, 5, 4, 9, 5, 3, 10}), 5)\n    lu.assertEquals(candidate({1}), 1)\n    lu.assertEquals(candidate({8, 8, 10, 6, 4, 3, 5, 8, 2, 4, 2, 8, 4, 6, 10, 4, 2, 1, 10, 2, 1, 1, 5}), 4)\n    lu.assertEquals(candidate({2, 10, 4, 8, 2, 10, 5, 1, 2, 9, 5, 5, 6, 3, 8, 6, 4, 10}), 2)\n    lu.assertEquals(candidate({1, 6, 10, 1, 6, 9, 10, 8, 6, 8, 7, 3}), 1)\n    lu.assertEquals(candidate({9, 2, 4, 1, 5, 1, 5, 2, 5, 7, 7, 7, 3, 10, 1, 5, 4, 2, 8, 4, 1, 9, 10, 7, 10, 2, 8, 10, 9, 4}), 4)\n    lu.assertEquals(candidate({2, 6, 4, 2, 8, 7, 5, 6, 4, 10, 4, 6, 3, 7, 8, 8, 3, 1, 4, 2, 2, 10, 7}), 4)\n    lu.assertEquals(candidate({9, 8, 6, 10, 2, 6, 10, 2, 7, 8, 10, 3, 8, 2, 6, 2, 3, 1}), 2)\n    lu.assertEquals(candidate({5, 5, 3, 9, 5, 6, 3, 2, 8, 5, 6, 10, 10, 6, 8, 4, 10, 7, 7, 10, 8}), -1)\n    lu.assertEquals(candidate({10}), -1)\n    lu.assertEquals(candidate({9, 7, 7, 2, 4, 7, 2, 10, 9, 7, 5, 7, 2}), 2)\n    lu.assertEquals(candidate({5, 4, 10, 2, 1, 1, 10, 3, 6, 1, 8}), 1)\n    lu.assertEquals(candidate({7, 9, 9, 9, 3, 4, 1, 5, 9, 1, 2, 1, 1, 10, 7, 5, 6, 7, 6, 7, 7, 6}), 1)\n    lu.assertEquals(candidate({3, 10, 10, 9, 2}), -1)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_61_correct_bracketing", "language": "lua", "prompt": "-- brackets is a string of \"(\" and \")\".\n-- return true if every opening bracket has a corresponding closing bracket.\n-- >>> correct_bracketing('(')\n-- false\n-- >>> correct_bracketing('()')\n-- true\n-- >>> correct_bracketing('(()())')\n-- true\n-- >>> correct_bracketing(')(()')\n-- false\nlocal function correct_bracketing(brackets)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_61_correct_bracketing.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = correct_bracketing\n    lu.assertEquals(candidate('()'), true)\n    lu.assertEquals(candidate('(()())'), true)\n    lu.assertEquals(candidate('()()(()())()'), true)\n    lu.assertEquals(candidate('()()((()()())())(()()(()))'), true)\n    lu.assertEquals(candidate('((()())))'), false)\n    lu.assertEquals(candidate(')(()'), false)\n    lu.assertEquals(candidate('('), false)\n    lu.assertEquals(candidate('(((('), false)\n    lu.assertEquals(candidate(')'), false)\n    lu.assertEquals(candidate('(()'), false)\n    lu.assertEquals(candidate('()()(()())())(()'), false)\n    lu.assertEquals(candidate('()()(()())()))()'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_61_correct_bracketing", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = correct_bracketing\n    lu.assertEquals(candidate('()'), true)\n    lu.assertEquals(candidate('(()())'), true)\n    lu.assertEquals(candidate('()()(()())()'), true)\n    lu.assertEquals(candidate('()()((()()())())(()()(()))'), true)\n    lu.assertEquals(candidate('((()())))'), false)\n    lu.assertEquals(candidate(')(()'), false)\n    lu.assertEquals(candidate('('), false)\n    lu.assertEquals(candidate('(((('), false)\n    lu.assertEquals(candidate(')'), false)\n    lu.assertEquals(candidate('(()'), false)\n    lu.assertEquals(candidate('()()(()())())(()'), false)\n    lu.assertEquals(candidate('()()(()())()))()'), false)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_37_sort_even", "language": "lua", "prompt": "-- This function takes a table l and returns a table l' such that\n-- l' is identical to l in the odd indicies, while its values at the even indicies are equal\n-- to the values of the even indicies of l, but sorted.\n-- >>> sort_even({1, 2, 3})\n-- {1, 2, 3}\n-- >>> sort_even({5, 6, 3, 4})\n-- {3, 6, 5, 4}\nlocal function sort_even(l)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_37_sort_even.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sort_even\n    lu.assertEquals(candidate({1, 2, 3}), {1, 2, 3})\n    lu.assertEquals(candidate({5, 3, -5, 2, -3, 3, 9, 0, 123, 1, -10}), {-10, 3, -5, 2, -3, 3, 5, 0, 9, 1, 123})\n    lu.assertEquals(candidate({5, 8, -12, 4, 23, 2, 3, 11, 12, -10}), {-12, 8, 3, 4, 5, 2, 12, 11, 23, -10})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_37_sort_even", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sort_even\n    lu.assertEquals(candidate({1, 2, 3}), {1, 2, 3})\n    lu.assertEquals(candidate({5, 3, -5, 2, -3, 3, 9, 0, 123, 1, -10}), {-10, 3, -5, 2, -3, 3, 5, 0, 9, 1, 123})\n    lu.assertEquals(candidate({5, 8, -12, 4, 23, 2, 3, 11, 12, -10}), {-12, 8, 3, 4, 5, 2, 12, 11, 23, -10})\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_54_same_chars", "language": "lua", "prompt": "-- Check if two words have the same characters.\n-- >>> same_chars('eabcdzzzz', 'dddzzzzzzzddeddabc')\n-- true\n-- >>> same_chars('abcd', 'dddddddabc')\n-- true\n-- >>> same_chars('dddddddabc', 'abcd')\n-- true\n-- >>> same_chars('eabcd', 'dddddddabc')\n-- false\n-- >>> same_chars('abcd', 'dddddddabce')\n-- false\n-- >>> same_chars('eabcdzzzz', 'dddzzzzzzzddddabc')\n-- false\nlocal function same_chars(s0, s1)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_54_same_chars.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = same_chars\n    lu.assertEquals(candidate('eabcdzzzz', 'dddzzzzzzzddeddabc'), true)\n    lu.assertEquals(candidate('abcd', 'dddddddabc'), true)\n    lu.assertEquals(candidate('dddddddabc', 'abcd'), true)\n    lu.assertEquals(candidate('eabcd', 'dddddddabc'), false)\n    lu.assertEquals(candidate('abcd', 'dddddddabcf'), false)\n    lu.assertEquals(candidate('eabcdzzzz', 'dddzzzzzzzddddabc'), false)\n    lu.assertEquals(candidate('aabb', 'aaccc'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_54_same_chars", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = same_chars\n    lu.assertEquals(candidate('eabcdzzzz', 'dddzzzzzzzddeddabc'), true)\n    lu.assertEquals(candidate('abcd', 'dddddddabc'), true)\n    lu.assertEquals(candidate('dddddddabc', 'abcd'), true)\n    lu.assertEquals(candidate('eabcd', 'dddddddabc'), false)\n    lu.assertEquals(candidate('abcd', 'dddddddabcf'), false)\n    lu.assertEquals(candidate('eabcdzzzz', 'dddzzzzzzzddddabc'), false)\n    lu.assertEquals(candidate('aabb', 'aaccc'), false)\nend\n\nos.exit(lu.LuaUnit.run())"}
{"name": "HumanEval_56_correct_bracketing", "language": "lua", "prompt": "-- brackets is a string of \"<\" and \">\".\n-- return true if every opening bracket has a corresponding closing bracket.\n-- >>> correct_bracketing('<')\n-- false\n-- >>> correct_bracketing('<>')\n-- true\n-- >>> correct_bracketing('<<><>>')\n-- true\n-- >>> correct_bracketing('><<>')\n-- false\nlocal function correct_bracketing(brackets)\n", "doctests": "transform", "original": "/home/arjun/repos/nuprl/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_56_correct_bracketing.py", "prompt_terminology": "reworded", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = correct_bracketing\n    lu.assertEquals(candidate('<>'), true)\n    lu.assertEquals(candidate('<<><>>'), true)\n    lu.assertEquals(candidate('<><><<><>><>'), true)\n    lu.assertEquals(candidate('<><><<<><><>><>><<><><<>>>'), true)\n    lu.assertEquals(candidate('<<<><>>>>'), false)\n    lu.assertEquals(candidate('><<>'), false)\n    lu.assertEquals(candidate('<'), false)\n    lu.assertEquals(candidate('<<<<'), false)\n    lu.assertEquals(candidate('>'), false)\n    lu.assertEquals(candidate('<<>'), false)\n    lu.assertEquals(candidate('<><><<><>><>><<>'), false)\n    lu.assertEquals(candidate('<><><<><>><>>><>'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"], "task_id": "HumanEval_56_correct_bracketing", "test": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = correct_bracketing\n    lu.assertEquals(candidate('<>'), true)\n    lu.assertEquals(candidate('<<><>>'), true)\n    lu.assertEquals(candidate('<><><<><>><>'), true)\n    lu.assertEquals(candidate('<><><<<><><>><>><<><><<>>>'), true)\n    lu.assertEquals(candidate('<<<><>>>>'), false)\n    lu.assertEquals(candidate('><<>'), false)\n    lu.assertEquals(candidate('<'), false)\n    lu.assertEquals(candidate('<<<<'), false)\n    lu.assertEquals(candidate('>'), false)\n    lu.assertEquals(candidate('<<>'), false)\n    lu.assertEquals(candidate('<><><<><>><>><<>'), false)\n    lu.assertEquals(candidate('<><><<><>><>>><>'), false)\nend\n\nos.exit(lu.LuaUnit.run())"}
